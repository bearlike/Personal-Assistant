{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Meeseeks Docs","text":"<p>Meeseeks is a personal assistant that breaks a request into small actions, runs the right tools, and replies with a clean summary. This doc gives a quick product view and how the parts fit together. Use the links below for setup and deep dives.</p> <ul> <li>Getting started</li> <li>Components</li> <li>API reference</li> </ul>"},{"location":"#features-quick-view","title":"Features (quick view)","text":"<ul> <li>Plan -&gt; act -&gt; observe loop to keep work grounded in tool results.</li> <li>Multiple interfaces (chat UI, REST API, Home Assistant, terminal CLI) backed by one core engine.</li> <li>Tool registry for local tools plus optional MCP tools.</li> <li>Session transcripts with lightweight compaction for long runs.</li> <li>Context-aware memory (recent turns + summary) with optional context selection near budget.</li> <li>Step-level reflection after tool execution to validate outcomes.</li> <li>Permission gate with approval callbacks plus lightweight hooks around tool execution.</li> <li>Optional components (Langfuse, Home Assistant) auto-disable when not configured or when failures occur.</li> </ul>"},{"location":"#subprojects-and-how-they-fit","title":"Subprojects and how they fit","text":"<ul> <li><code>core/</code>: orchestration loop, schemas, session storage, compaction, tool registry.</li> <li><code>tools/</code>: tool implementations and integrations.</li> <li><code>meeseeks-api/</code>: Flask API that exposes the assistant over HTTP.</li> <li><code>meeseeks-chat/</code>: Streamlit UI for interactive chat.</li> <li><code>meeseeks-cli/</code>: Terminal CLI for interactive sessions.</li> <li><code>meeseeks_ha_conversation/</code>: Home Assistant integration that routes voice requests to the API.</li> <li><code>prompts/</code>: planner prompt and examples.</li> </ul>"},{"location":"#architecture-in-a-glance","title":"Architecture in a glance","text":"<ul> <li>The UI or API sends a user request into the core orchestrator.</li> <li>The orchestrator builds a short action plan, runs tools, and replans if needed.</li> <li>Tool results and summaries are stored in a session transcript for continuity.</li> </ul> <pre><code>flowchart LR\n  User --&gt; Chat\n  User --&gt; API\n  HA --&gt; API\n  User --&gt; CLI\n  Chat --&gt; Core\n  API --&gt; Core\n  CLI --&gt; Core\n  Core --&gt; Tools\n  Tools --&gt; HomeAssistant\n  Tools --&gt; MCP\n  Core --&gt; SessionStore\n</code></pre>"},{"location":"#installation-local","title":"Installation (local)","text":"<p>See getting-started.md for full setup (env, MCP, configs, and how to run each interface).</p>"},{"location":"#cli-quick-commands","title":"CLI quick commands","text":"<ul> <li><code>/help</code> show commands</li> <li><code>/models</code> pick a model from your API</li> <li><code>/mcp</code> list MCP servers/tools (use <code>/mcp select</code> to filter)</li> <li><code>/mcp init</code> scaffold an MCP config file</li> <li><code>/summarize</code> compact the session</li> <li><code>/new</code> start a fresh session</li> <li><code>/automatic</code> auto-approve tool actions for the session</li> <li><code>/quit</code> exit the CLI</li> </ul>"},{"location":"#deployment-docker","title":"Deployment (Docker)","text":"<p>See getting-started.md for Docker setup and environment requirements.</p>"},{"location":"components/","title":"Components","text":"<p>This repository is a monorepo. Each component lives in its own folder:</p> <ul> <li><code>core/</code>: orchestration loop, schemas, session storage, compaction, tool registry.</li> <li><code>tools/</code>: tool implementations and integration glue.</li> <li><code>meeseeks-api/</code>: Flask API that exposes the assistant over HTTP.</li> <li><code>meeseeks-chat/</code>: Streamlit UI for interactive chat.</li> <li><code>meeseeks-cli/</code>: terminal CLI for interactive sessions.</li> <li><code>meeseeks_ha_conversation/</code>: Home Assistant integration that routes voice requests to the API.</li> <li><code>prompts/</code>: planner prompt and examples.</li> </ul> <p>Note: the API/Chat/CLI folders use hyphens in their names, which makes them invalid Python module names. MkDocs + mkdocstrings can only render inline docstrings for importable modules, so those folders will not show API docs until we add a package shim or rename them.</p>"},{"location":"getting-started/","title":"Getting Started","text":"<p>This guide walks through local setup, environment configuration, MCP setup, and how to run each interface.</p>"},{"location":"getting-started/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.11+</li> <li>Poetry</li> <li>Docker (optional, for container runs)</li> </ul>"},{"location":"getting-started/#install-dependencies","title":"Install dependencies","text":"<pre><code>poetry install\n</code></pre>"},{"location":"getting-started/#environment-setup","title":"Environment setup","text":"<ol> <li>Copy <code>.env.example</code> to <code>.env</code>.</li> <li>Set at least:</li> <li><code>OPENAI_API_KEY</code> (or your compatible provider key)</li> <li><code>OPENAI_API_BASE</code> (if you are using a local or custom API base)</li> <li><code>DEFAULT_MODEL</code> (or <code>ACTION_PLAN_MODEL</code>)</li> <li>Optional runtime paths:</li> <li><code>MESEEKS_SESSION_DIR</code> for session transcript storage</li> <li><code>MESEEKS_TOOL_MANIFEST</code> if you want a custom tool list (disables MCP auto-discovery)</li> </ol>"},{"location":"getting-started/#mcp-setup-auto-discovery","title":"MCP setup (auto-discovery)","text":"<p>MCP tools are auto-discovered from a server config file. 1. Copy <code>configs/mcp.example.json</code> to <code>configs/mcp.json</code>. 2. Set the MCP server <code>url</code> and any <code>headers</code> needed for auth. 3. Set <code>MESEEKS_MCP_CONFIG=./configs/mcp.json</code> in <code>.env</code>. 4. Start any interface once; a tool manifest is auto-generated and cached under <code>~/.meeseeks/</code>.</p> <p>Notes: - If you override the manifest, include <code>talk_to_user_tool</code> so the assistant can still reply. - MCP tool names must match the server's advertised tool list.</p>"},{"location":"getting-started/#optional-components","title":"Optional components","text":"<ul> <li>Langfuse: set <code>LANGFUSE_PUBLIC_KEY</code> + <code>LANGFUSE_SECRET_KEY</code> (or disable with <code>LANGFUSE_ENABLED=0</code>).</li> <li>Home Assistant: set <code>HA_URL</code> + <code>HA_TOKEN</code> (or disable with <code>MESEEKS_HOME_ASSISTANT_ENABLED=0</code>).</li> </ul>"},{"location":"getting-started/#run-interfaces-local","title":"Run interfaces (local)","text":"<ul> <li>API: <code>python meeseeks-api/backend.py</code></li> <li>Chat UI: <code>streamlit run meeseeks-chat/chat_master.py</code></li> <li>CLI: <code>python meeseeks-cli/cli_master.py</code></li> <li>Home Assistant integration: install <code>meeseeks_ha_conversation/</code> as a custom component and point it at the API.</li> </ul>"},{"location":"getting-started/#docker-optional","title":"Docker (optional)","text":"<ul> <li>Build images using the provided Dockerfiles for API/chat.</li> <li>Provide the same <code>.env</code> values as local.</li> <li>Persist <code>MESEEKS_SESSION_DIR</code> if you want transcripts across restarts.</li> </ul>"},{"location":"getting-started/#docs-optional","title":"Docs (optional)","text":"<p>If you want to build the docs locally:</p> <pre><code>pip install -r requirements-docs.txt\nexport PYTHONPATH=\"$PWD\"\nmkdocs serve\n</code></pre>"},{"location":"reference/","title":"API Reference","text":"<p>This page is generated from inline docstrings via mkdocstrings.</p>"},{"location":"reference/#core","title":"Core","text":""},{"location":"reference/#core.classes","title":"<code>core.classes</code>","text":"<p>Core data models and tool abstractions for Meeseeks orchestration.</p>"},{"location":"reference/#core.classes.AbstractTool","title":"<code>AbstractTool</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for tools, providing common features and methods.</p> Source code in <code>core/classes.py</code> <pre><code>class AbstractTool(abc.ABC):\n    \"\"\"Abstract base class for tools, providing common features and methods.\"\"\"\n\n    def _setup_cache_dir(self, name: str) -&gt; str:\n        \"\"\"Set up and return the cache directory path.\n\n        Args:\n            name: Tool name used to construct the cache path.\n\n        Returns:\n            Absolute path to the cache directory.\n\n        Raises:\n            ValueError: If CACHE_DIR is not configured.\n        \"\"\"\n        root_cache_dir = os.getenv(\"CACHE_DIR\")\n        if not root_cache_dir:\n            raise ValueError(\"CACHE_DIR environment variable is not set.\")\n        cache_path = os.path.join(\n            root_cache_dir, \"..\", \".cache\", f\"{name.lower().replace(' ', '_')}_tool\")\n        os.makedirs(cache_path, exist_ok=True)\n        return os.path.abspath(cache_path)\n\n    def __init__(\n        self,\n        name: str,\n        description: str,\n        model_name: str | None = None,\n        temperature: float = 0.3,\n        use_llm: bool = True,\n    ) -&gt; None:\n        \"\"\"Initialize the tool with optional model configuration.\n\n        Args:\n            name: Tool display name.\n            description: Short description of tool behavior.\n            model_name: Optional model override for the tool.\n            temperature: Sampling temperature for the model.\n            use_llm: Whether to initialize an LLM client for the tool.\n\n        Raises:\n            ValueError: If CACHE_DIR is not configured.\n        \"\"\"\n        self.model_name = cast(\n            str,\n            model_name\n            or os.getenv(\"TOOL_MODEL\")\n            or os.getenv(\"DEFAULT_MODEL\", \"gpt-3.5-turbo\"),\n        )\n        self.name = name\n        self.description = description\n        self.use_llm = use_llm\n        self._id = f\"{name.lower().replace(' ', '_')}_tool\"\n        session_id = f\"{self._id}-tool-id-{get_unique_timestamp()}\"\n        logging.info(f\"Tool created &lt;name={name}; session_id={session_id};&gt;\")\n        self.langfuse_handler = build_langfuse_handler(\n            user_id=f\"meeseeks-{name}\",\n            session_id=session_id,\n            trace_name=f\"meeseeks-{self._id}\",\n            version=os.getenv(\"VERSION\", \"Not Specified\"),\n            release=os.getenv(\"ENVMODE\", \"Not Specified\"),\n        )\n        self.model = None\n        if self.use_llm:\n            self.model = build_chat_model(\n                model_name=self.model_name,\n                temperature=temperature,\n                openai_api_base=os.getenv(\"OPENAI_API_BASE\"),\n            )\n        root_cache_dir = os.getenv(\"CACHE_DIR\", None)\n        if root_cache_dir is None:\n            raise ValueError(\"CACHE_DIR environment variable is not set.\")\n\n        cache_dir = os.path.join(root_cache_dir, \"..\", \".cache\", self._id)\n        self.cache_dir = os.path.abspath(cache_dir)\n        logging.debug(\"{} cache directory is {}.\", self._id, self.cache_dir)\n\n    def _save_json(self, data: object, filename: str) -&gt; None:\n        \"\"\"Save a dictionary to a JSON file.\n\n        Args:\n            data: Serializable payload to store.\n            filename: Output filename under the cache directory.\n\n        Raises:\n            OSError: If the file cannot be written.\n        \"\"\"\n        if not os.path.exists(self.cache_dir):\n            os.makedirs(self.cache_dir)\n        filename = os.path.join(self.cache_dir, filename)\n        with open(filename, \"w\", encoding=\"utf-8\") as f:\n            json.dump(data, f, indent=4)\n        logging.info(f\"Data saved to {filename}.\")\n\n    def _load_rag_json(self, filename: str) -&gt; list[Document]:\n        \"\"\"Load a dictionary from a JSON file.\n\n        Args:\n            filename: JSON filename under the cache directory.\n\n        Returns:\n            List of loaded Documents.\n\n        Raises:\n            OSError: If the file cannot be read.\n        \"\"\"\n        logging.debug(\"RAG directory is {}.\", self.cache_dir)\n        logging.info(f\"Loading `{filename}` as JSON.\")\n        filename = os.path.join(self.cache_dir, filename)\n        filename = os.path.abspath(filename)\n        loader = JSONLoader(\n            file_path=filename,\n            jq_schema='.',\n            text_content=False)\n        data = loader.load()\n        return data\n\n    def _load_rag_documents(self, filenames: list[str]) -&gt; list[Document]:\n        \"\"\"Load and concatenate multiple JSON files into RAG documents.\n\n        Args:\n            filenames: List of JSON files to load.\n\n        Returns:\n            Combined list of Documents for RAG ingestion.\n        \"\"\"\n        rag_documents: list[Document] = []\n        for rag_file in filenames:\n            data = self._load_rag_json(rag_file)\n            rag_documents.extend(data)\n        return rag_documents\n\n    def set_state(self, action_step: ActionStep | None = None) -&gt; MockSpeaker:\n        \"\"\"Perform a state-changing action.\n\n        Args:\n            action_step: Action step containing the action arguments.\n\n        Returns:\n            MockSpeaker response for the action.\n        \"\"\"\n        MockSpeaker = get_mock_speaker()\n        return MockSpeaker(content=\"Not implemented yet.\")\n\n    def get_state(self, action_step: ActionStep | None = None) -&gt; MockSpeaker:\n        \"\"\"Perform a read-only action.\n\n        Args:\n            action_step: Action step containing the query arguments.\n\n        Returns:\n            MockSpeaker response for the action.\n        \"\"\"\n        MockSpeaker = get_mock_speaker()\n        return MockSpeaker(content=\"Not implemented yet.\")\n\n    def run(self, action_step: ActionStep) -&gt; MockSpeaker:\n        \"\"\"Execute the action based on the action type.\n\n        Args:\n            action_step: ActionStep object with action details.\n\n        Returns:\n            MockSpeaker response for the action.\n\n        Raises:\n            ValueError: If the action type is unsupported.\n        \"\"\"\n        if action_step.action_type == \"set\":\n            return self.set_state(action_step)\n        if action_step.action_type == \"get\":\n            return self.get_state(action_step)\n        raise ValueError(f\"Invalid action type: {action_step.action_type}\")\n</code></pre>"},{"location":"reference/#core.classes.AbstractTool.__init__","title":"<code>__init__(name: str, description: str, model_name: str | None = None, temperature: float = 0.3, use_llm: bool = True) -&gt; None</code>","text":"<p>Initialize the tool with optional model configuration.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Tool display name.</p> required <code>description</code> <code>str</code> <p>Short description of tool behavior.</p> required <code>model_name</code> <code>str | None</code> <p>Optional model override for the tool.</p> <code>None</code> <code>temperature</code> <code>float</code> <p>Sampling temperature for the model.</p> <code>0.3</code> <code>use_llm</code> <code>bool</code> <p>Whether to initialize an LLM client for the tool.</p> <code>True</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If CACHE_DIR is not configured.</p> Source code in <code>core/classes.py</code> <pre><code>def __init__(\n    self,\n    name: str,\n    description: str,\n    model_name: str | None = None,\n    temperature: float = 0.3,\n    use_llm: bool = True,\n) -&gt; None:\n    \"\"\"Initialize the tool with optional model configuration.\n\n    Args:\n        name: Tool display name.\n        description: Short description of tool behavior.\n        model_name: Optional model override for the tool.\n        temperature: Sampling temperature for the model.\n        use_llm: Whether to initialize an LLM client for the tool.\n\n    Raises:\n        ValueError: If CACHE_DIR is not configured.\n    \"\"\"\n    self.model_name = cast(\n        str,\n        model_name\n        or os.getenv(\"TOOL_MODEL\")\n        or os.getenv(\"DEFAULT_MODEL\", \"gpt-3.5-turbo\"),\n    )\n    self.name = name\n    self.description = description\n    self.use_llm = use_llm\n    self._id = f\"{name.lower().replace(' ', '_')}_tool\"\n    session_id = f\"{self._id}-tool-id-{get_unique_timestamp()}\"\n    logging.info(f\"Tool created &lt;name={name}; session_id={session_id};&gt;\")\n    self.langfuse_handler = build_langfuse_handler(\n        user_id=f\"meeseeks-{name}\",\n        session_id=session_id,\n        trace_name=f\"meeseeks-{self._id}\",\n        version=os.getenv(\"VERSION\", \"Not Specified\"),\n        release=os.getenv(\"ENVMODE\", \"Not Specified\"),\n    )\n    self.model = None\n    if self.use_llm:\n        self.model = build_chat_model(\n            model_name=self.model_name,\n            temperature=temperature,\n            openai_api_base=os.getenv(\"OPENAI_API_BASE\"),\n        )\n    root_cache_dir = os.getenv(\"CACHE_DIR\", None)\n    if root_cache_dir is None:\n        raise ValueError(\"CACHE_DIR environment variable is not set.\")\n\n    cache_dir = os.path.join(root_cache_dir, \"..\", \".cache\", self._id)\n    self.cache_dir = os.path.abspath(cache_dir)\n    logging.debug(\"{} cache directory is {}.\", self._id, self.cache_dir)\n</code></pre>"},{"location":"reference/#core.classes.AbstractTool.get_state","title":"<code>get_state(action_step: ActionStep | None = None) -&gt; MockSpeaker</code>","text":"<p>Perform a read-only action.</p> <p>Parameters:</p> Name Type Description Default <code>action_step</code> <code>ActionStep | None</code> <p>Action step containing the query arguments.</p> <code>None</code> <p>Returns:</p> Type Description <code>MockSpeaker</code> <p>MockSpeaker response for the action.</p> Source code in <code>core/classes.py</code> <pre><code>def get_state(self, action_step: ActionStep | None = None) -&gt; MockSpeaker:\n    \"\"\"Perform a read-only action.\n\n    Args:\n        action_step: Action step containing the query arguments.\n\n    Returns:\n        MockSpeaker response for the action.\n    \"\"\"\n    MockSpeaker = get_mock_speaker()\n    return MockSpeaker(content=\"Not implemented yet.\")\n</code></pre>"},{"location":"reference/#core.classes.AbstractTool.run","title":"<code>run(action_step: ActionStep) -&gt; MockSpeaker</code>","text":"<p>Execute the action based on the action type.</p> <p>Parameters:</p> Name Type Description Default <code>action_step</code> <code>ActionStep</code> <p>ActionStep object with action details.</p> required <p>Returns:</p> Type Description <code>MockSpeaker</code> <p>MockSpeaker response for the action.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the action type is unsupported.</p> Source code in <code>core/classes.py</code> <pre><code>def run(self, action_step: ActionStep) -&gt; MockSpeaker:\n    \"\"\"Execute the action based on the action type.\n\n    Args:\n        action_step: ActionStep object with action details.\n\n    Returns:\n        MockSpeaker response for the action.\n\n    Raises:\n        ValueError: If the action type is unsupported.\n    \"\"\"\n    if action_step.action_type == \"set\":\n        return self.set_state(action_step)\n    if action_step.action_type == \"get\":\n        return self.get_state(action_step)\n    raise ValueError(f\"Invalid action type: {action_step.action_type}\")\n</code></pre>"},{"location":"reference/#core.classes.AbstractTool.set_state","title":"<code>set_state(action_step: ActionStep | None = None) -&gt; MockSpeaker</code>","text":"<p>Perform a state-changing action.</p> <p>Parameters:</p> Name Type Description Default <code>action_step</code> <code>ActionStep | None</code> <p>Action step containing the action arguments.</p> <code>None</code> <p>Returns:</p> Type Description <code>MockSpeaker</code> <p>MockSpeaker response for the action.</p> Source code in <code>core/classes.py</code> <pre><code>def set_state(self, action_step: ActionStep | None = None) -&gt; MockSpeaker:\n    \"\"\"Perform a state-changing action.\n\n    Args:\n        action_step: Action step containing the action arguments.\n\n    Returns:\n        MockSpeaker response for the action.\n    \"\"\"\n    MockSpeaker = get_mock_speaker()\n    return MockSpeaker(content=\"Not implemented yet.\")\n</code></pre>"},{"location":"reference/#core.classes.ActionStep","title":"<code>ActionStep</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Defines an action step within a task queue with validation.</p> <p>Attributes:</p> Name Type Description <code>title</code> <code>str | None</code> <p>Short task header for the step.</p> <code>objective</code> <code>str | None</code> <p>Brief objective describing the intent of the step.</p> <code>execution_checklist</code> <code>list[str]</code> <p>Small checklist of execution hints.</p> <code>expected_output</code> <code>str | None</code> <p>Optional description of the expected outcome.</p> <code>action_consumer</code> <code>str</code> <p>Tool identifier that should execute the action.</p> <code>action_type</code> <code>str</code> <p>Action category, typically \"get\" or \"set\".</p> <code>action_argument</code> <code>str | dict[str, Any]</code> <p>Natural language argument for the tool.</p> <code>result</code> <code>MockSpeaker | None</code> <p>Optional tool result payload.</p> Source code in <code>core/classes.py</code> <pre><code>class ActionStep(BaseModel):\n    \"\"\"Defines an action step within a task queue with validation.\n\n    Attributes:\n        title: Short task header for the step.\n        objective: Brief objective describing the intent of the step.\n        execution_checklist: Small checklist of execution hints.\n        expected_output: Optional description of the expected outcome.\n        action_consumer: Tool identifier that should execute the action.\n        action_type: Action category, typically \"get\" or \"set\".\n        action_argument: Natural language argument for the tool.\n        result: Optional tool result payload.\n    \"\"\"\n    title: str | None = Field(\n        default=None,\n        description=\"Short header summarizing the task for this step.\",\n    )\n    objective: str | None = Field(\n        default=None,\n        description=\"Brief objective explaining why this step is needed.\",\n    )\n    execution_checklist: list[str] = Field(\n        default_factory=list,\n        description=\"Short checklist of execution details for this step.\",\n    )\n    expected_output: str | None = Field(\n        default=None,\n        description=\"Optional description of what success looks like.\",\n    )\n    action_consumer: str = Field(\n        description=(\n            \"Specify the tool_id that should execute the action. \"\n            \"Use only tool IDs listed under Available tools.\"\n        )\n    )\n    action_type: str = Field(\n        description=\"Specify either 'get' or 'set' to indicate the action type.\"\n    )\n    action_argument: str | dict[str, Any] = Field(\n        description=(\n            \"Provide details for the action. If 'task', specify the task to perform. \"\n            \"If 'talk', include the message to speak to the user.\"\n        )\n    )\n    result: MockSpeaker | None = Field(\n        alias=\"_result\",\n        default=None,\n        description='Private field to persist the action status and other data.'\n    )\n</code></pre>"},{"location":"reference/#core.classes.OrchestrationState","title":"<code>OrchestrationState</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Track state for the orchestration loop.</p> <p>Attributes:</p> Name Type Description <code>goal</code> <code>str</code> <p>User goal for the session.</p> <code>session_id</code> <code>str | None</code> <p>Unique session identifier.</p> <code>plan</code> <code>list[ActionStep]</code> <p>Current action plan.</p> <code>tool_results</code> <code>list[str]</code> <p>Result strings from executed tools.</p> <code>open_questions</code> <code>list[str]</code> <p>Outstanding questions for the user.</p> <code>done</code> <code>bool</code> <p>Whether orchestration is finished.</p> <code>done_reason</code> <code>str | None</code> <p>Reason for completion.</p> <code>summary</code> <code>str | None</code> <p>Optional session summary string.</p> Source code in <code>core/classes.py</code> <pre><code>class OrchestrationState(BaseModel):\n    \"\"\"Track state for the orchestration loop.\n\n    Attributes:\n        goal: User goal for the session.\n        session_id: Unique session identifier.\n        plan: Current action plan.\n        tool_results: Result strings from executed tools.\n        open_questions: Outstanding questions for the user.\n        done: Whether orchestration is finished.\n        done_reason: Reason for completion.\n        summary: Optional session summary string.\n    \"\"\"\n    goal: str\n    session_id: str | None = None\n    plan: list[ActionStep] = Field(default_factory=list)\n    tool_results: list[str] = Field(default_factory=list)\n    open_questions: list[str] = Field(default_factory=list)\n    done: bool = False\n    done_reason: str | None = None\n    summary: str | None = None\n</code></pre>"},{"location":"reference/#core.classes.TaskQueue","title":"<code>TaskQueue</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Manages a queue of actions to be performed, tracking their results.</p> <p>Attributes:</p> Name Type Description <code>human_message</code> <code>str | None</code> <p>Original user message for the task queue.</p> <code>action_steps</code> <code>list[ActionStep]</code> <p>Ordered list of action steps to execute.</p> <code>task_result</code> <code>str | None</code> <p>Aggregated result of the task queue.</p> Source code in <code>core/classes.py</code> <pre><code>class TaskQueue(BaseModel):\n    \"\"\"Manages a queue of actions to be performed, tracking their results.\n\n    Attributes:\n        human_message: Original user message for the task queue.\n        action_steps: Ordered list of action steps to execute.\n        task_result: Aggregated result of the task queue.\n    \"\"\"\n    human_message: str | None = Field(\n        alias=\"_human_message\",\n        default=None,\n        description='Human message associated with the task queue.'\n    )\n    action_steps: list[ActionStep] = Field(default_factory=list)\n    task_result: str | None = Field(\n        alias=\"_task_result\",\n        default=None,\n        description='Store the result for the entire task queue'\n    )\n\n    @validator(\"action_steps\", allow_reuse=True)\n    # pylint: disable=E0213,W0613\n    def validate_actions(cls, field: list[ActionStep]) -&gt; list[ActionStep]:\n        \"\"\"Normalize and validate action steps within a task queue.\n\n        Args:\n            field: Action steps to normalize and validate.\n\n        Returns:\n            Normalized list of action steps.\n        \"\"\"\n        for action in field:\n            # Normalize once and store it\n            action.action_consumer = action.action_consumer.lower()\n            action.action_type = action.action_type.lower()\n            error_msg_list = []\n\n            # Check if action_consumer is valid\n            if action.action_consumer not in AVAILABLE_TOOLS:\n                error_msg_list.append(\n                    f\"`{action.action_consumer}` is not a valid Assistant consumer.\")\n\n            # Check if action_type is valid\n            if action.action_type not in [\"get\", \"set\"]:\n                error_msg = f\"`{action.action_type}` is not a valid action type.\"\n                error_msg_list.append(error_msg)\n\n            # Specific checks for \"talk_to_user\" consumer\n            if action.action_consumer == \"talk_to_user_tool\" and \\\n                    action.action_type == \"get\":\n                error_msg = f\"`{action.action_consumer}` does not support 'get' action type.\"\n                error_msg_list.append(error_msg)\n\n            # Check for None argument\n            if action.action_argument is None:\n                error_msg_list.append(\"Action argument cannot be None.\")\n\n            # Handle errors if any\n            if error_msg_list:\n                error_msg = \"\\n\".join(error_msg_list)\n                for msg in error_msg_list:\n                    logging.error(msg)  # Log\n\n        return field\n</code></pre>"},{"location":"reference/#core.classes.TaskQueue.validate_actions","title":"<code>validate_actions(field: list[ActionStep]) -&gt; list[ActionStep]</code>","text":"<p>Normalize and validate action steps within a task queue.</p> <p>Parameters:</p> Name Type Description Default <code>field</code> <code>list[ActionStep]</code> <p>Action steps to normalize and validate.</p> required <p>Returns:</p> Type Description <code>list[ActionStep]</code> <p>Normalized list of action steps.</p> Source code in <code>core/classes.py</code> <pre><code>@validator(\"action_steps\", allow_reuse=True)\n# pylint: disable=E0213,W0613\ndef validate_actions(cls, field: list[ActionStep]) -&gt; list[ActionStep]:\n    \"\"\"Normalize and validate action steps within a task queue.\n\n    Args:\n        field: Action steps to normalize and validate.\n\n    Returns:\n        Normalized list of action steps.\n    \"\"\"\n    for action in field:\n        # Normalize once and store it\n        action.action_consumer = action.action_consumer.lower()\n        action.action_type = action.action_type.lower()\n        error_msg_list = []\n\n        # Check if action_consumer is valid\n        if action.action_consumer not in AVAILABLE_TOOLS:\n            error_msg_list.append(\n                f\"`{action.action_consumer}` is not a valid Assistant consumer.\")\n\n        # Check if action_type is valid\n        if action.action_type not in [\"get\", \"set\"]:\n            error_msg = f\"`{action.action_type}` is not a valid action type.\"\n            error_msg_list.append(error_msg)\n\n        # Specific checks for \"talk_to_user\" consumer\n        if action.action_consumer == \"talk_to_user_tool\" and \\\n                action.action_type == \"get\":\n            error_msg = f\"`{action.action_consumer}` does not support 'get' action type.\"\n            error_msg_list.append(error_msg)\n\n        # Check for None argument\n        if action.action_argument is None:\n            error_msg_list.append(\"Action argument cannot be None.\")\n\n        # Handle errors if any\n        if error_msg_list:\n            error_msg = \"\\n\".join(error_msg_list)\n            for msg in error_msg_list:\n                logging.error(msg)  # Log\n\n    return field\n</code></pre>"},{"location":"reference/#core.classes.create_task_queue","title":"<code>create_task_queue(action_data: list[ActionStepPayload] | None = None, is_example: bool = True) -&gt; TaskQueue</code>","text":"<p>Create a TaskQueue object from serialized action data.</p> <p>Parameters:</p> Name Type Description Default <code>action_data</code> <code>list[ActionStepPayload] | None</code> <p>List of action step payloads.</p> <code>None</code> <code>is_example</code> <code>bool</code> <p>Whether to drop the human_message field.</p> <code>True</code> <p>Returns:</p> Type Description <code>TaskQueue</code> <p>TaskQueue populated with the action steps.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If action_data is None.</p> Source code in <code>core/classes.py</code> <pre><code>def create_task_queue(\n    action_data: list[ActionStepPayload] | None = None,\n    is_example: bool = True,\n) -&gt; TaskQueue:\n    \"\"\"Create a TaskQueue object from serialized action data.\n\n    Args:\n        action_data: List of action step payloads.\n        is_example: Whether to drop the human_message field.\n\n    Returns:\n        TaskQueue populated with the action steps.\n\n    Raises:\n        ValueError: If action_data is None.\n    \"\"\"\n    if action_data is None:\n        raise ValueError(\"Action data cannot be None.\")\n\n    # Convert the input data to ActionStep objects\n    action_steps = [ActionStep(**action) for action in action_data]\n    # Create a TaskQueue object with the action steps\n    task_queue = TaskQueue(action_steps=action_steps)\n    if is_example:\n        del task_queue.human_message\n    return task_queue\n</code></pre>"},{"location":"reference/#core.classes.get_task_master_examples","title":"<code>get_task_master_examples(example_id: int = 0, available_tools: Sequence[str] | None = None) -&gt; str</code>","text":"<p>Get serialized example task queue data.</p> <p>Parameters:</p> Name Type Description Default <code>example_id</code> <code>int</code> <p>Index of the example to return.</p> <code>0</code> <code>available_tools</code> <code>Sequence[str] | None</code> <p>Optional tool IDs to shape the examples.</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>JSON-serialized task queue string.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If example_id is out of range.</p> Source code in <code>core/classes.py</code> <pre><code>def get_task_master_examples(\n    example_id: int = 0,\n    available_tools: Sequence[str] | None = None,\n) -&gt; str:\n    \"\"\"Get serialized example task queue data.\n\n    Args:\n        example_id: Index of the example to return.\n        available_tools: Optional tool IDs to shape the examples.\n\n    Returns:\n        JSON-serialized task queue string.\n\n    Raises:\n        ValueError: If example_id is out of range.\n    \"\"\"\n    if available_tools is None:\n        available_tools = AVAILABLE_TOOLS\n    include_home_assistant = \"home_assistant_tool\" in available_tools\n    if include_home_assistant:\n        examples: list[list[ActionStepPayload]] = [\n            [\n                {\n                    \"title\": \"Turn on strip lights\",\n                    \"objective\": \"Activate the strip lights via Home Assistant.\",\n                    \"execution_checklist\": [\n                        \"Use Home Assistant set action\",\n                        \"Target strip lights\",\n                    ],\n                    \"expected_output\": \"Strip lights are powered on.\",\n                    \"action_consumer\": \"home_assistant_tool\",\n                    \"action_type\": \"set\",\n                    \"action_argument\": \"Power on the strip lights.\",\n                },\n                {\n                    \"title\": \"Turn on heater\",\n                    \"objective\": \"Activate the heater via Home Assistant.\",\n                    \"execution_checklist\": [\n                        \"Use Home Assistant set action\",\n                        \"Target heater\",\n                    ],\n                    \"expected_output\": \"Heater is powered on.\",\n                    \"action_consumer\": \"home_assistant_tool\",\n                    \"action_type\": \"set\",\n                    \"action_argument\": \"Power on the Heater.\",\n                },\n                {\n                    \"title\": \"Confirm actions to user\",\n                    \"objective\": \"Let the user know the devices are being powered on.\",\n                    \"execution_checklist\": [\n                        \"Use talk_to_user_tool\",\n                        \"Confirm both devices\",\n                    ],\n                    \"expected_output\": \"User receives confirmation.\",\n                    \"action_consumer\": \"talk_to_user_tool\",\n                    \"action_type\": \"set\",\n                    \"action_argument\": (\n                        \"Got it, boss! I'm using Home Assistant to power on the strip lights \"\n                        \"and the heater.\"\n                    ),\n                },\n            ],\n            [\n                {\n                    \"title\": \"Check weather\",\n                    \"objective\": \"Retrieve today's weather from Home Assistant.\",\n                    \"execution_checklist\": [\n                        \"Use Home Assistant get action\",\n                        \"Ask for today's weather\",\n                    ],\n                    \"expected_output\": \"Weather details are returned.\",\n                    \"action_consumer\": \"home_assistant_tool\",\n                    \"action_type\": \"get\",\n                    \"action_argument\": \"Get today's weather.\",\n                },\n            ]\n        ]\n    else:\n        examples = [\n            [\n                {\n                    \"title\": \"Greet user\",\n                    \"objective\": \"Open the conversation and ask how to help.\",\n                    \"execution_checklist\": [\"Use talk_to_user_tool\"],\n                    \"expected_output\": \"User is prompted for next task.\",\n                    \"action_consumer\": \"talk_to_user_tool\",\n                    \"action_type\": \"set\",\n                    \"action_argument\": \"Got it, boss! How can I help you today?\",\n                },\n            ],\n            [\n                {\n                    \"title\": \"Request next task\",\n                    \"objective\": \"Ask the user for their next request.\",\n                    \"execution_checklist\": [\"Use talk_to_user_tool\"],\n                    \"expected_output\": \"User provides a follow-up request.\",\n                    \"action_consumer\": \"talk_to_user_tool\",\n                    \"action_type\": \"set\",\n                    \"action_argument\": \"Happy to help. What should I take care of next?\",\n                },\n            ],\n        ]\n    if example_id not in range(0, len(examples)):\n        raise ValueError(f\"Invalid example ID: {example_id}\")\n\n    return create_task_queue(action_data=examples[example_id], is_example=True).json()\n</code></pre>"},{"location":"reference/#core.classes.set_available_tools","title":"<code>set_available_tools(tool_ids: list[str]) -&gt; None</code>","text":"<p>Update the global tool list for ActionStep validation.</p> <p>Parameters:</p> Name Type Description Default <code>tool_ids</code> <code>list[str]</code> <p>List of tool identifiers to allow.</p> required Source code in <code>core/classes.py</code> <pre><code>def set_available_tools(tool_ids: list[str]) -&gt; None:\n    \"\"\"Update the global tool list for ActionStep validation.\n\n    Args:\n        tool_ids: List of tool identifiers to allow.\n    \"\"\"\n    global AVAILABLE_TOOLS\n    AVAILABLE_TOOLS = tool_ids\n</code></pre>"},{"location":"reference/#core.common","title":"<code>core.common</code>","text":"<p>Common helpers shared across the assistant runtime.</p>"},{"location":"reference/#core.common.MockSpeaker","title":"<code>MockSpeaker</code>","text":"<p>               Bases: <code>NamedTuple</code></p> <p>Simple mock response container used across tools and tests.</p> <p>Attributes:</p> Name Type Description <code>content</code> <code>str</code> <p>Text content returned by a tool.</p> Source code in <code>core/common.py</code> <pre><code>class MockSpeaker(NamedTuple):\n    \"\"\"Simple mock response container used across tools and tests.\n\n    Attributes:\n        content: Text content returned by a tool.\n    \"\"\"\n    content: str\n</code></pre>"},{"location":"reference/#core.common.format_action_argument","title":"<code>format_action_argument(argument: Any) -&gt; str</code>","text":"<p>Format an action argument for logs and prompts.</p> <p>Parameters:</p> Name Type Description Default <code>argument</code> <code>Any</code> <p>Action argument payload.</p> required <p>Returns:</p> Type Description <code>str</code> <p>String representation suitable for display.</p> Source code in <code>core/common.py</code> <pre><code>def format_action_argument(argument: Any) -&gt; str:\n    \"\"\"Format an action argument for logs and prompts.\n\n    Args:\n        argument: Action argument payload.\n\n    Returns:\n        String representation suitable for display.\n    \"\"\"\n    if isinstance(argument, dict):\n        return json.dumps(argument, ensure_ascii=True)\n    return str(argument)\n</code></pre>"},{"location":"reference/#core.common.get_logger","title":"<code>get_logger(name: str | None = None)</code>","text":"<p>Get the logger for the module.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str | None</code> <p>Name of the logger, defaults to name.</p> <code>None</code> <p>Returns:</p> Type Description <p>Logger configured with colored output.</p> Source code in <code>core/common.py</code> <pre><code>def get_logger(name: str | None = None):\n    \"\"\"Get the logger for the module.\n\n    Args:\n        name: Name of the logger, defaults to __name__.\n\n    Returns:\n        Logger configured with colored output.\n    \"\"\"\n    _configure_logging()\n    if not name:\n        name = __name__\n    return loguru_logger.bind(name=name)\n</code></pre>"},{"location":"reference/#core.common.get_mock_speaker","title":"<code>get_mock_speaker() -&gt; type[MockSpeaker]</code>","text":"<p>Return a mock speaker for testing.</p> <p>Returns:</p> Type Description <code>type[MockSpeaker]</code> <p>MockSpeaker class for constructing responses.</p> Source code in <code>core/common.py</code> <pre><code>def get_mock_speaker() -&gt; type[MockSpeaker]:\n    \"\"\"Return a mock speaker for testing.\n\n    Returns:\n        MockSpeaker class for constructing responses.\n    \"\"\"\n    return MockSpeaker\n</code></pre>"},{"location":"reference/#core.common.get_system_prompt","title":"<code>get_system_prompt(name: str = 'action-planner') -&gt; str</code>","text":"<p>Get the system prompt for the task queue.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Prompt file name without extension.</p> <code>'action-planner'</code> <p>Returns:</p> Type Description <code>str</code> <p>System prompt string.</p> <p>Raises:</p> Type Description <code>OSError</code> <p>If the prompt file cannot be read.</p> Source code in <code>core/common.py</code> <pre><code>def get_system_prompt(name: str = \"action-planner\") -&gt; str:\n    \"\"\"Get the system prompt for the task queue.\n\n    Args:\n        name: Prompt file name without extension.\n\n    Returns:\n        System prompt string.\n\n    Raises:\n        OSError: If the prompt file cannot be read.\n    \"\"\"\n    logging = get_logger(name=\"core.common.get_system_prompt\")\n    system_prompt_path = os.path.join(\n        os.path.dirname(__file__), \"..\", \"prompts\", f\"{name}.txt\")\n    with open(system_prompt_path, encoding=\"utf-8\") as system_prompt_file:\n        system_prompt = system_prompt_file.read()\n    logging.debug(\"Getting system prompt from `{}`\", system_prompt_path)\n    del logging\n    return system_prompt.strip()\n</code></pre>"},{"location":"reference/#core.common.get_unique_timestamp","title":"<code>get_unique_timestamp() -&gt; int</code>","text":"<p>Get a unique timestamp for the task queue.</p> <p>Returns:</p> Type Description <code>int</code> <p>Integer timestamp suitable for unique IDs.</p> Source code in <code>core/common.py</code> <pre><code>def get_unique_timestamp() -&gt; int:\n    \"\"\"Get a unique timestamp for the task queue.\n\n    Returns:\n        Integer timestamp suitable for unique IDs.\n    \"\"\"\n    # Get the number of seconds since epoch (Jan 1, 1970) as a float\n    current_timestamp = int(time.time())\n    # Convert it to string for uniqueness and consistency\n    unique_timestamp = str(current_timestamp)\n    # Return the integer version of this string timestamp\n    return int(''.join(str(x) for x in map(int, unique_timestamp)))\n</code></pre>"},{"location":"reference/#core.common.ha_render_system_prompt","title":"<code>ha_render_system_prompt(all_entities: Any | None = None, env: str = 'prompts', name: str = 'homeassistant-set-state') -&gt; str</code>","text":"<p>Render the Home Assistant Jinja2 system prompt.</p> <p>Parameters:</p> Name Type Description Default <code>all_entities</code> <code>Any | None</code> <p>Optional entity list for template substitution.</p> <code>None</code> <code>env</code> <code>str</code> <p>Template root directory name.</p> <code>'prompts'</code> <code>name</code> <code>str</code> <p>Template file name without extension.</p> <code>'homeassistant-set-state'</code> <p>Returns:</p> Type Description <code>str</code> <p>Rendered system prompt string.</p> Source code in <code>core/common.py</code> <pre><code>def ha_render_system_prompt(\n    all_entities: Any | None = None,\n    env: str = \"prompts\",\n    name: str = \"homeassistant-set-state\",\n) -&gt; str:\n    \"\"\"Render the Home Assistant Jinja2 system prompt.\n\n    Args:\n        all_entities: Optional entity list for template substitution.\n        env: Template root directory name.\n        name: Template file name without extension.\n\n    Returns:\n        Rendered system prompt string.\n    \"\"\"\n    if all_entities is not None:\n        all_entities = str(all_entities).strip()\n    logging = get_logger(name=\"core.common.render_system_prompt\")\n\n    template_root = os.path.join(__name__, \"..\", \"..\", \"prompts\")\n    template_root = os.path.abspath(template_root)\n    logging.debug(\"Compiling {} from {}.\", name, template_root)\n    # TODO: Catch and log TemplateNotFound when necessary.\n    template_env = Environment(loader=FileSystemLoader(template_root))\n    template = template_env.get_template(f\"{name}.txt\")\n    logging.debug(\"Render system prompt for `{}`\", name)\n    del logging\n\n    return template.render(ALL_ENTITIES=all_entities)\n</code></pre>"},{"location":"reference/#core.common.num_tokens_from_string","title":"<code>num_tokens_from_string(string: str, encoding_name: str = 'cl100k_base') -&gt; int</code>","text":"<p>Get the number of tokens in a string using a specific model.</p> <p>Parameters:</p> Name Type Description Default <code>string</code> <code>str</code> <p>Text to tokenize.</p> required <code>encoding_name</code> <code>str</code> <p>Encoding name used for tokenization.</p> <code>'cl100k_base'</code> <p>Returns:</p> Type Description <code>int</code> <p>Number of tokens for the string.</p> Source code in <code>core/common.py</code> <pre><code>def num_tokens_from_string(\n        string: str, encoding_name: str = \"cl100k_base\") -&gt; int:\n    \"\"\"Get the number of tokens in a string using a specific model.\n\n    Args:\n        string: Text to tokenize.\n        encoding_name: Encoding name used for tokenization.\n\n    Returns:\n        Number of tokens for the string.\n    \"\"\"\n    # TODO: Add support for dynamic model selection\n    encoding = tiktoken.get_encoding(encoding_name)\n    num_tokens = len(encoding.encode(string))\n    return num_tokens\n</code></pre>"},{"location":"reference/#core.compaction","title":"<code>core.compaction</code>","text":"<p>Transcript compaction utilities.</p>"},{"location":"reference/#core.compaction.should_compact","title":"<code>should_compact(events: Iterable[EventRecord], threshold: int = 50) -&gt; bool</code>","text":"<p>Return True when the event list meets the compaction threshold.</p> <p>Parameters:</p> Name Type Description Default <code>events</code> <code>Iterable[EventRecord]</code> <p>Iterable of event records to count.</p> required <code>threshold</code> <code>int</code> <p>Minimum number of events that triggers compaction.</p> <code>50</code> <p>Returns:</p> Type Description <code>bool</code> <p>True when compaction should run.</p> Source code in <code>core/compaction.py</code> <pre><code>def should_compact(events: Iterable[EventRecord], threshold: int = 50) -&gt; bool:\n    \"\"\"Return True when the event list meets the compaction threshold.\n\n    Args:\n        events: Iterable of event records to count.\n        threshold: Minimum number of events that triggers compaction.\n\n    Returns:\n        True when compaction should run.\n    \"\"\"\n    return len(list(events)) &gt;= threshold\n</code></pre>"},{"location":"reference/#core.compaction.summarize_events","title":"<code>summarize_events(events: Iterable[EventRecord], max_items: int = 20) -&gt; str</code>","text":"<p>Generate a lightweight summary of recent events.</p> <p>Parameters:</p> Name Type Description Default <code>events</code> <code>Iterable[EventRecord]</code> <p>Iterable of event records to summarize.</p> required <code>max_items</code> <code>int</code> <p>Maximum number of recent events to include.</p> <code>20</code> <p>Returns:</p> Type Description <code>str</code> <p>Concise summary string of recent events.</p> Source code in <code>core/compaction.py</code> <pre><code>def summarize_events(events: Iterable[EventRecord], max_items: int = 20) -&gt; str:\n    \"\"\"Generate a lightweight summary of recent events.\n\n    Args:\n        events: Iterable of event records to summarize.\n        max_items: Maximum number of recent events to include.\n\n    Returns:\n        Concise summary string of recent events.\n    \"\"\"\n    snippets: list[str] = []\n    for event in list(events)[-max_items:]:\n        event_type = event.get(\"type\", \"event\")\n        payload_value: object = event.get(\"payload\", \"\")\n        if isinstance(payload_value, dict):\n            payload_data = dict(payload_value)\n            payload_value = payload_data.get(\"text\") or payload_data.get(\"message\") or str(\n                payload_data\n            )\n        if payload_value:\n            snippets.append(f\"{event_type}: {payload_value}\")\n        else:\n            snippets.append(f\"{event_type}.\")\n    return \" | \".join(snippets).strip()\n</code></pre>"},{"location":"reference/#core.components","title":"<code>core.components</code>","text":"<p>Helpers for optional components and observability integration.</p>"},{"location":"reference/#core.components.ComponentStatus","title":"<code>ComponentStatus</code>  <code>dataclass</code>","text":"<p>Describe whether a component is enabled and why.</p> Source code in <code>core/components.py</code> <pre><code>@dataclass(frozen=True)\nclass ComponentStatus:\n    \"\"\"Describe whether a component is enabled and why.\"\"\"\n\n    name: str\n    enabled: bool\n    reason: str | None = None\n    metadata: dict[str, Any] = field(default_factory=dict)\n</code></pre>"},{"location":"reference/#core.components.build_langfuse_handler","title":"<code>build_langfuse_handler(*, user_id: str, session_id: str, trace_name: str, version: str, release: str) -&gt; LangfuseCallbackHandler | None</code>","text":"<p>Create a Langfuse callback handler when configured.</p> Source code in <code>core/components.py</code> <pre><code>def build_langfuse_handler(\n    *,\n    user_id: str,\n    session_id: str,\n    trace_name: str,\n    version: str,\n    release: str,\n) -&gt; LangfuseCallbackHandler | None:\n    \"\"\"Create a Langfuse callback handler when configured.\"\"\"\n    status = resolve_langfuse_status()\n    if not status.enabled:\n        logging.debug(\"Langfuse disabled: {}\", status.reason)\n        return None\n\n    from langfuse.callback import CallbackHandler\n\n    try:\n        return CallbackHandler(\n            user_id=user_id,\n            session_id=session_id,\n            trace_name=trace_name,\n            version=version,\n            release=release,\n        )\n    except Exception as exc:  # pragma: no cover - defensive\n        logging.warning(\"Langfuse initialization failed: {}\", exc)\n        return None\n</code></pre>"},{"location":"reference/#core.components.format_component_status","title":"<code>format_component_status(statuses: Iterable[ComponentStatus]) -&gt; str</code>","text":"<p>Format component statuses for inclusion in prompts.</p> Source code in <code>core/components.py</code> <pre><code>def format_component_status(statuses: Iterable[ComponentStatus]) -&gt; str:\n    \"\"\"Format component statuses for inclusion in prompts.\"\"\"\n    lines: list[str] = []\n    for status in statuses:\n        state = \"enabled\" if status.enabled else \"disabled\"\n        reason = f\" ({status.reason})\" if status.reason else \"\"\n        lines.append(f\"- {status.name}: {state}{reason}\")\n    return \"\\n\".join(lines)\n</code></pre>"},{"location":"reference/#core.components.resolve_home_assistant_status","title":"<code>resolve_home_assistant_status() -&gt; ComponentStatus</code>","text":"<p>Determine whether the Home Assistant tool is configured.</p> Source code in <code>core/components.py</code> <pre><code>def resolve_home_assistant_status() -&gt; ComponentStatus:\n    \"\"\"Determine whether the Home Assistant tool is configured.\"\"\"\n    enabled_flag = os.getenv(\"MESEEKS_HOME_ASSISTANT_ENABLED\")\n    if _env_falsey(enabled_flag):\n        return ComponentStatus(\n            name=\"home_assistant_tool\",\n            enabled=False,\n            reason=\"disabled via MESEEKS_HOME_ASSISTANT_ENABLED\",\n        )\n    base_url = os.getenv(\"HA_URL\")\n    token = os.getenv(\"HA_TOKEN\")\n    if not base_url or not token:\n        return ComponentStatus(\n            name=\"home_assistant_tool\",\n            enabled=False,\n            reason=\"missing HA_URL/HA_TOKEN\",\n            metadata={\"required_env\": [\"HA_URL\", \"HA_TOKEN\"]},\n        )\n    return ComponentStatus(name=\"home_assistant_tool\", enabled=True)\n</code></pre>"},{"location":"reference/#core.components.resolve_langfuse_status","title":"<code>resolve_langfuse_status() -&gt; ComponentStatus</code>","text":"<p>Determine whether Langfuse callbacks are available and configured.</p> Source code in <code>core/components.py</code> <pre><code>def resolve_langfuse_status() -&gt; ComponentStatus:\n    \"\"\"Determine whether Langfuse callbacks are available and configured.\"\"\"\n    enabled_flag = os.getenv(\"LANGFUSE_ENABLED\")\n    if _env_falsey(enabled_flag):\n        return ComponentStatus(\n            name=\"langfuse\",\n            enabled=False,\n            reason=\"disabled via LANGFUSE_ENABLED\",\n        )\n    try:\n        from langfuse.callback import CallbackHandler  # noqa: F401\n    except ImportError:\n        return ComponentStatus(\n            name=\"langfuse\",\n            enabled=False,\n            reason=\"langfuse not installed\",\n        )\n\n    public_key = os.getenv(\"LANGFUSE_PUBLIC_KEY\")\n    secret_key = os.getenv(\"LANGFUSE_SECRET_KEY\")\n    if not public_key or not secret_key:\n        return ComponentStatus(\n            name=\"langfuse\",\n            enabled=False,\n            reason=\"missing LANGFUSE_PUBLIC_KEY/LANGFUSE_SECRET_KEY\",\n            metadata={\"required_env\": [\"LANGFUSE_PUBLIC_KEY\", \"LANGFUSE_SECRET_KEY\"]},\n        )\n    return ComponentStatus(name=\"langfuse\", enabled=True)\n</code></pre>"},{"location":"reference/#core.hooks","title":"<code>core.hooks</code>","text":"<p>Hook manager for orchestration lifecycle events.</p>"},{"location":"reference/#core.hooks.HookManager","title":"<code>HookManager</code>  <code>dataclass</code>","text":"<p>Container for hook callbacks used during orchestration.</p> Source code in <code>core/hooks.py</code> <pre><code>@dataclass\nclass HookManager:\n    \"\"\"Container for hook callbacks used during orchestration.\"\"\"\n    pre_tool_use: list[Callable[[ActionStep], ActionStep]] = field(\n        default_factory=list\n    )\n    post_tool_use: list[Callable[[ActionStep, MockSpeaker], MockSpeaker]] = field(\n        default_factory=list\n    )\n    permission_request: list[\n        Callable[[ActionStep, PermissionDecision], PermissionDecision]\n    ] = field(default_factory=list)\n    pre_compact: list[Callable[[list[EventRecord]], list[EventRecord]]] = field(\n        default_factory=list\n    )\n\n    def run_pre_tool_use(self, action_step: ActionStep) -&gt; ActionStep:\n        \"\"\"Apply pre-tool hooks to an action step.\n\n        Args:\n            action_step: Action step to process.\n\n        Returns:\n            Updated action step after hooks run.\n        \"\"\"\n        for hook in self.pre_tool_use:\n            action_step = hook(action_step)\n        return action_step\n\n    def run_post_tool_use(\n        self, action_step: ActionStep, result: MockSpeaker\n    ) -&gt; MockSpeaker:\n        \"\"\"Apply post-tool hooks to a tool result.\n\n        Args:\n            action_step: Action step that was executed.\n            result: Result returned by the tool.\n\n        Returns:\n            Updated result after hooks run.\n        \"\"\"\n        for hook in self.post_tool_use:\n            result = hook(action_step, result)\n        return result\n\n    def run_permission_request(\n        self, action_step: ActionStep, decision: PermissionDecision\n    ) -&gt; PermissionDecision:\n        \"\"\"Apply permission hooks to a decision outcome.\n\n        Args:\n            action_step: Action step under review.\n            decision: Current decision to modify.\n\n        Returns:\n            Updated permission decision after hooks run.\n        \"\"\"\n        for hook in self.permission_request:\n            decision = hook(action_step, decision)\n        return decision\n\n    def run_pre_compact(self, events: Iterable[EventRecord]) -&gt; list[EventRecord]:\n        \"\"\"Apply compaction hooks to events prior to summarization.\n\n        Args:\n            events: Iterable of event records.\n\n        Returns:\n            List of event records after hooks run.\n        \"\"\"\n        event_list: list[EventRecord] = list(events)\n        for hook in self.pre_compact:\n            event_list = hook(event_list)\n        return event_list\n</code></pre>"},{"location":"reference/#core.hooks.HookManager.run_permission_request","title":"<code>run_permission_request(action_step: ActionStep, decision: PermissionDecision) -&gt; PermissionDecision</code>","text":"<p>Apply permission hooks to a decision outcome.</p> <p>Parameters:</p> Name Type Description Default <code>action_step</code> <code>ActionStep</code> <p>Action step under review.</p> required <code>decision</code> <code>PermissionDecision</code> <p>Current decision to modify.</p> required <p>Returns:</p> Type Description <code>PermissionDecision</code> <p>Updated permission decision after hooks run.</p> Source code in <code>core/hooks.py</code> <pre><code>def run_permission_request(\n    self, action_step: ActionStep, decision: PermissionDecision\n) -&gt; PermissionDecision:\n    \"\"\"Apply permission hooks to a decision outcome.\n\n    Args:\n        action_step: Action step under review.\n        decision: Current decision to modify.\n\n    Returns:\n        Updated permission decision after hooks run.\n    \"\"\"\n    for hook in self.permission_request:\n        decision = hook(action_step, decision)\n    return decision\n</code></pre>"},{"location":"reference/#core.hooks.HookManager.run_post_tool_use","title":"<code>run_post_tool_use(action_step: ActionStep, result: MockSpeaker) -&gt; MockSpeaker</code>","text":"<p>Apply post-tool hooks to a tool result.</p> <p>Parameters:</p> Name Type Description Default <code>action_step</code> <code>ActionStep</code> <p>Action step that was executed.</p> required <code>result</code> <code>MockSpeaker</code> <p>Result returned by the tool.</p> required <p>Returns:</p> Type Description <code>MockSpeaker</code> <p>Updated result after hooks run.</p> Source code in <code>core/hooks.py</code> <pre><code>def run_post_tool_use(\n    self, action_step: ActionStep, result: MockSpeaker\n) -&gt; MockSpeaker:\n    \"\"\"Apply post-tool hooks to a tool result.\n\n    Args:\n        action_step: Action step that was executed.\n        result: Result returned by the tool.\n\n    Returns:\n        Updated result after hooks run.\n    \"\"\"\n    for hook in self.post_tool_use:\n        result = hook(action_step, result)\n    return result\n</code></pre>"},{"location":"reference/#core.hooks.HookManager.run_pre_compact","title":"<code>run_pre_compact(events: Iterable[EventRecord]) -&gt; list[EventRecord]</code>","text":"<p>Apply compaction hooks to events prior to summarization.</p> <p>Parameters:</p> Name Type Description Default <code>events</code> <code>Iterable[EventRecord]</code> <p>Iterable of event records.</p> required <p>Returns:</p> Type Description <code>list[EventRecord]</code> <p>List of event records after hooks run.</p> Source code in <code>core/hooks.py</code> <pre><code>def run_pre_compact(self, events: Iterable[EventRecord]) -&gt; list[EventRecord]:\n    \"\"\"Apply compaction hooks to events prior to summarization.\n\n    Args:\n        events: Iterable of event records.\n\n    Returns:\n        List of event records after hooks run.\n    \"\"\"\n    event_list: list[EventRecord] = list(events)\n    for hook in self.pre_compact:\n        event_list = hook(event_list)\n    return event_list\n</code></pre>"},{"location":"reference/#core.hooks.HookManager.run_pre_tool_use","title":"<code>run_pre_tool_use(action_step: ActionStep) -&gt; ActionStep</code>","text":"<p>Apply pre-tool hooks to an action step.</p> <p>Parameters:</p> Name Type Description Default <code>action_step</code> <code>ActionStep</code> <p>Action step to process.</p> required <p>Returns:</p> Type Description <code>ActionStep</code> <p>Updated action step after hooks run.</p> Source code in <code>core/hooks.py</code> <pre><code>def run_pre_tool_use(self, action_step: ActionStep) -&gt; ActionStep:\n    \"\"\"Apply pre-tool hooks to an action step.\n\n    Args:\n        action_step: Action step to process.\n\n    Returns:\n        Updated action step after hooks run.\n    \"\"\"\n    for hook in self.pre_tool_use:\n        action_step = hook(action_step)\n    return action_step\n</code></pre>"},{"location":"reference/#core.hooks.default_hook_manager","title":"<code>default_hook_manager() -&gt; HookManager</code>","text":"<p>Create a hook manager with no custom hooks registered.</p> <p>Returns:</p> Type Description <code>HookManager</code> <p>Empty HookManager instance.</p> Source code in <code>core/hooks.py</code> <pre><code>def default_hook_manager() -&gt; HookManager:\n    \"\"\"Create a hook manager with no custom hooks registered.\n\n    Returns:\n        Empty HookManager instance.\n    \"\"\"\n    return HookManager()\n</code></pre>"},{"location":"reference/#core.llm","title":"<code>core.llm</code>","text":"<p>Model configuration helpers for ChatOpenAI.</p>"},{"location":"reference/#core.llm.allows_temperature","title":"<code>allows_temperature(model_name: str | None, reasoning_effort: str | None) -&gt; bool</code>","text":"<p>Return True when temperature can be sent for the model/effect combo.</p> Source code in <code>core/llm.py</code> <pre><code>def allows_temperature(model_name: str | None, reasoning_effort: str | None) -&gt; bool:\n    \"\"\"Return True when temperature can be sent for the model/effect combo.\"\"\"\n    if not model_name:\n        return True\n    normalized = model_name.lower()\n    if not normalized.startswith(\"gpt-5\"):\n        return True\n    if normalized.startswith((\"gpt-5.1\", \"gpt-5.2\")):\n        return reasoning_effort == \"none\"\n    return False\n</code></pre>"},{"location":"reference/#core.llm.build_chat_model","title":"<code>build_chat_model(model_name: str, temperature: float, *, openai_api_base: str | None = None) -&gt; Any</code>","text":"<p>Build a ChatOpenAI model with reasoning-effort compatibility.</p> Source code in <code>core/llm.py</code> <pre><code>def build_chat_model(\n    model_name: str,\n    temperature: float,\n    *,\n    openai_api_base: str | None = None,\n) -&gt; Any:\n    \"\"\"Build a ChatOpenAI model with reasoning-effort compatibility.\"\"\"\n    try:\n        from langchain_openai import ChatOpenAI\n    except ImportError as exc:  # pragma: no cover - dependency guard\n        raise ImportError(\"langchain-openai is required to build ChatOpenAI\") from exc\n\n    reasoning_effort = resolve_reasoning_effort(model_name)\n    allow_temp = allows_temperature(model_name, reasoning_effort)\n    if not allow_temp:\n        logging.info(\n            \"Omitting temperature for model '{}' with reasoning_effort '{}'.\",\n            model_name,\n            reasoning_effort,\n        )\n        temperature_value: float | None = None\n    else:\n        temperature_value = temperature\n\n    model_kwargs: dict[str, Any] = {}\n    if reasoning_effort is not None:\n        model_kwargs[\"reasoning_effort\"] = reasoning_effort\n\n    kwargs: dict[str, Any] = {\n        \"base_url\": openai_api_base,\n        \"model\": model_name,\n    }\n    if temperature_value is not None:\n        kwargs[\"temperature\"] = temperature_value\n    if model_kwargs:\n        kwargs[\"model_kwargs\"] = model_kwargs\n\n    return ChatOpenAI(**kwargs)\n</code></pre>"},{"location":"reference/#core.llm.model_supports_reasoning_effort","title":"<code>model_supports_reasoning_effort(model_name: str | None) -&gt; bool</code>","text":"<p>Return True if the model is known to support reasoning_effort.</p> Source code in <code>core/llm.py</code> <pre><code>def model_supports_reasoning_effort(model_name: str | None) -&gt; bool:\n    \"\"\"Return True if the model is known to support reasoning_effort.\"\"\"\n    if not model_name:\n        return False\n    normalized = model_name.lower()\n    allowlist = _parse_model_list_env(\"MESEEKS_REASONING_EFFORT_MODELS\")\n    if _matches_model_list(normalized, allowlist):\n        return True\n    return normalized.startswith(\"gpt-5\")\n</code></pre>"},{"location":"reference/#core.llm.resolve_reasoning_effort","title":"<code>resolve_reasoning_effort(model_name: str | None) -&gt; str | None</code>","text":"<p>Resolve the reasoning effort to use for a model.</p> Source code in <code>core/llm.py</code> <pre><code>def resolve_reasoning_effort(model_name: str | None) -&gt; str | None:\n    \"\"\"Resolve the reasoning effort to use for a model.\"\"\"\n    env_value = os.getenv(\"MESEEKS_REASONING_EFFORT\")\n    if env_value:\n        return env_value.strip().lower()\n    if not model_supports_reasoning_effort(model_name):\n        return None\n    normalized = (model_name or \"\").lower()\n    if \"gpt-5-pro\" in normalized:\n        return \"high\"\n    return \"medium\"\n</code></pre>"},{"location":"reference/#core.permissions","title":"<code>core.permissions</code>","text":"<p>Permission policies for tool execution.</p>"},{"location":"reference/#core.permissions.PermissionDecision","title":"<code>PermissionDecision</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Possible outcomes for a permission check.</p> Source code in <code>core/permissions.py</code> <pre><code>class PermissionDecision(str, Enum):\n    \"\"\"Possible outcomes for a permission check.\"\"\"\n    ALLOW = \"allow\"\n    DENY = \"deny\"\n    ASK = \"ask\"\n</code></pre>"},{"location":"reference/#core.permissions.PermissionPolicy","title":"<code>PermissionPolicy</code>","text":"<p>Evaluate permission rules for action steps.</p> Source code in <code>core/permissions.py</code> <pre><code>class PermissionPolicy:\n    \"\"\"Evaluate permission rules for action steps.\"\"\"\n    def __init__(\n        self,\n        rules: list[PermissionRule] | None = None,\n        default_by_action: dict[str, PermissionDecision] | None = None,\n        default_decision: PermissionDecision = PermissionDecision.ASK,\n    ) -&gt; None:\n        \"\"\"Initialize the permission policy.\n\n        Args:\n            rules: Optional list of explicit permission rules.\n            default_by_action: Optional defaults keyed by action type.\n            default_decision: Default decision when no rule matches.\n        \"\"\"\n        self._rules = rules or []\n        self._default_by_action = default_by_action or {}\n        self._default_decision = default_decision\n\n    def decide(self, action_step: ActionStep) -&gt; PermissionDecision:\n        \"\"\"Return the permission decision for an action step.\n\n        Args:\n            action_step: Action step to evaluate.\n\n        Returns:\n            PermissionDecision based on the configured rules.\n        \"\"\"\n        for rule in self._rules:\n            if rule.matches(action_step):\n                return rule.decision\n        action_decision = self._default_by_action.get(action_step.action_type)\n        if action_decision is not None:\n            return action_decision\n        return self._default_decision\n</code></pre>"},{"location":"reference/#core.permissions.PermissionPolicy.__init__","title":"<code>__init__(rules: list[PermissionRule] | None = None, default_by_action: dict[str, PermissionDecision] | None = None, default_decision: PermissionDecision = PermissionDecision.ASK) -&gt; None</code>","text":"<p>Initialize the permission policy.</p> <p>Parameters:</p> Name Type Description Default <code>rules</code> <code>list[PermissionRule] | None</code> <p>Optional list of explicit permission rules.</p> <code>None</code> <code>default_by_action</code> <code>dict[str, PermissionDecision] | None</code> <p>Optional defaults keyed by action type.</p> <code>None</code> <code>default_decision</code> <code>PermissionDecision</code> <p>Default decision when no rule matches.</p> <code>ASK</code> Source code in <code>core/permissions.py</code> <pre><code>def __init__(\n    self,\n    rules: list[PermissionRule] | None = None,\n    default_by_action: dict[str, PermissionDecision] | None = None,\n    default_decision: PermissionDecision = PermissionDecision.ASK,\n) -&gt; None:\n    \"\"\"Initialize the permission policy.\n\n    Args:\n        rules: Optional list of explicit permission rules.\n        default_by_action: Optional defaults keyed by action type.\n        default_decision: Default decision when no rule matches.\n    \"\"\"\n    self._rules = rules or []\n    self._default_by_action = default_by_action or {}\n    self._default_decision = default_decision\n</code></pre>"},{"location":"reference/#core.permissions.PermissionPolicy.decide","title":"<code>decide(action_step: ActionStep) -&gt; PermissionDecision</code>","text":"<p>Return the permission decision for an action step.</p> <p>Parameters:</p> Name Type Description Default <code>action_step</code> <code>ActionStep</code> <p>Action step to evaluate.</p> required <p>Returns:</p> Type Description <code>PermissionDecision</code> <p>PermissionDecision based on the configured rules.</p> Source code in <code>core/permissions.py</code> <pre><code>def decide(self, action_step: ActionStep) -&gt; PermissionDecision:\n    \"\"\"Return the permission decision for an action step.\n\n    Args:\n        action_step: Action step to evaluate.\n\n    Returns:\n        PermissionDecision based on the configured rules.\n    \"\"\"\n    for rule in self._rules:\n        if rule.matches(action_step):\n            return rule.decision\n    action_decision = self._default_by_action.get(action_step.action_type)\n    if action_decision is not None:\n        return action_decision\n    return self._default_decision\n</code></pre>"},{"location":"reference/#core.permissions.PermissionRule","title":"<code>PermissionRule</code>  <code>dataclass</code>","text":"<p>Rule describing a tool/action permission decision.</p> Source code in <code>core/permissions.py</code> <pre><code>@dataclass(frozen=True)\nclass PermissionRule:\n    \"\"\"Rule describing a tool/action permission decision.\"\"\"\n    tool_id: str = \"*\"\n    action_type: str = \"*\"\n    decision: PermissionDecision = PermissionDecision.ASK\n\n    def matches(self, action_step: ActionStep) -&gt; bool:\n        \"\"\"Return True when the action step matches the rule pattern.\n\n        Args:\n            action_step: Action step to evaluate against the rule.\n\n        Returns:\n            True when the rule matches the action step.\n        \"\"\"\n        return fnmatch(action_step.action_consumer, self.tool_id) and fnmatch(\n            action_step.action_type, self.action_type\n        )\n</code></pre>"},{"location":"reference/#core.permissions.PermissionRule.matches","title":"<code>matches(action_step: ActionStep) -&gt; bool</code>","text":"<p>Return True when the action step matches the rule pattern.</p> <p>Parameters:</p> Name Type Description Default <code>action_step</code> <code>ActionStep</code> <p>Action step to evaluate against the rule.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True when the rule matches the action step.</p> Source code in <code>core/permissions.py</code> <pre><code>def matches(self, action_step: ActionStep) -&gt; bool:\n    \"\"\"Return True when the action step matches the rule pattern.\n\n    Args:\n        action_step: Action step to evaluate against the rule.\n\n    Returns:\n        True when the rule matches the action step.\n    \"\"\"\n    return fnmatch(action_step.action_consumer, self.tool_id) and fnmatch(\n        action_step.action_type, self.action_type\n    )\n</code></pre>"},{"location":"reference/#core.permissions.approval_callback_from_env","title":"<code>approval_callback_from_env() -&gt; Callable[[ActionStep], bool] | None</code>","text":"<p>Return an approval callback based on environment configuration.</p> <p>Returns:</p> Type Description <code>Callable[[ActionStep], bool] | None</code> <p>Callable that approves/denies actions or None to indicate no callback.</p> Source code in <code>core/permissions.py</code> <pre><code>def approval_callback_from_env() -&gt; Callable[[ActionStep], bool] | None:\n    \"\"\"Return an approval callback based on environment configuration.\n\n    Returns:\n        Callable that approves/denies actions or None to indicate no callback.\n    \"\"\"\n    mode = os.getenv(\"MESEEKS_APPROVAL_MODE\", \"\").strip().lower()\n    if mode in {\"allow\", \"auto\", \"approve\", \"yes\"}:\n        return lambda _: True\n    if mode in {\"deny\", \"never\", \"no\"}:\n        return lambda _: False\n    return None\n</code></pre>"},{"location":"reference/#core.permissions.auto_approve","title":"<code>auto_approve(_: ActionStep) -&gt; bool</code>","text":"<p>Approval callback that always approves.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True for all inputs.</p> Source code in <code>core/permissions.py</code> <pre><code>def auto_approve(_: ActionStep) -&gt; bool:\n    \"\"\"Approval callback that always approves.\n\n    Returns:\n        True for all inputs.\n    \"\"\"\n    return True\n</code></pre>"},{"location":"reference/#core.permissions.auto_deny","title":"<code>auto_deny(_: ActionStep) -&gt; bool</code>","text":"<p>Approval callback that always denies.</p> <p>Returns:</p> Type Description <code>bool</code> <p>False for all inputs.</p> Source code in <code>core/permissions.py</code> <pre><code>def auto_deny(_: ActionStep) -&gt; bool:\n    \"\"\"Approval callback that always denies.\n\n    Returns:\n        False for all inputs.\n    \"\"\"\n    return False\n</code></pre>"},{"location":"reference/#core.permissions.load_permission_policy","title":"<code>load_permission_policy(path: str | None = None) -&gt; PermissionPolicy</code>","text":"<p>Load permission policy configuration from disk or defaults.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | None</code> <p>Optional explicit policy path. Defaults to env var when omitted.</p> <code>None</code> <p>Returns:</p> Type Description <code>PermissionPolicy</code> <p>Loaded PermissionPolicy or default policy on error.</p> Source code in <code>core/permissions.py</code> <pre><code>def load_permission_policy(path: str | None = None) -&gt; PermissionPolicy:\n    \"\"\"Load permission policy configuration from disk or defaults.\n\n    Args:\n        path: Optional explicit policy path. Defaults to env var when omitted.\n\n    Returns:\n        Loaded PermissionPolicy or default policy on error.\n    \"\"\"\n    if path is None:\n        path = os.getenv(\"MESEEKS_PERMISSION_POLICY\")\n    if not path:\n        return _default_policy()\n    if not os.path.exists(path):\n        logging.warning(\"Permission policy file not found: {}\", path)\n        return _default_policy()\n    try:\n        payload = _load_policy_data(path)\n    except (json.JSONDecodeError, OSError, tomllib.TOMLDecodeError) as exc:\n        logging.warning(\"Failed to load permission policy: {}\", exc)\n        return _default_policy()\n\n    rules: list[PermissionRule] = []\n    for rule_data in payload.get(\"rules\", []):\n        decision = _parse_decision(rule_data.get(\"decision\"))\n        if decision is None:\n            continue\n        rules.append(\n            PermissionRule(\n                tool_id=str(rule_data.get(\"tool_id\", \"*\")),\n                action_type=str(rule_data.get(\"action_type\", \"*\")),\n                decision=decision,\n            )\n        )\n\n    default_by_action: dict[str, PermissionDecision] = {}\n    for key, value in payload.get(\"default_by_action\", {}).items():\n        parsed = _parse_decision(str(value))\n        if parsed is not None:\n            default_by_action[str(key)] = parsed\n\n    default_decision = _parse_decision(payload.get(\"default_decision\"))\n    if default_decision is None:\n        default_decision = PermissionDecision.ASK\n\n    return PermissionPolicy(\n        rules=rules,\n        default_by_action=default_by_action,\n        default_decision=default_decision,\n    )\n</code></pre>"},{"location":"reference/#core.session_store","title":"<code>core.session_store</code>","text":"<p>Session transcript storage and management.</p>"},{"location":"reference/#core.session_store.SessionPaths","title":"<code>SessionPaths</code>  <code>dataclass</code>","text":"<p>Resolved filesystem paths for a session.</p> <p>Attributes:</p> Name Type Description <code>root</code> <code>str</code> <p>Root directory for session storage.</p> <code>session_id</code> <code>str</code> <p>Unique session identifier.</p> Source code in <code>core/session_store.py</code> <pre><code>@dataclass(frozen=True)\nclass SessionPaths:\n    \"\"\"Resolved filesystem paths for a session.\n\n    Attributes:\n        root: Root directory for session storage.\n        session_id: Unique session identifier.\n    \"\"\"\n    root: str\n    session_id: str\n\n    @property\n    def session_dir(self) -&gt; str:\n        \"\"\"Directory for session artifacts.\n\n        Returns:\n            Absolute directory path for the session.\n        \"\"\"\n        return os.path.join(self.root, self.session_id)\n\n    @property\n    def transcript_path(self) -&gt; str:\n        \"\"\"Path to the JSONL transcript file.\n\n        Returns:\n            Absolute path to the transcript file.\n        \"\"\"\n        return os.path.join(self.session_dir, \"transcript.jsonl\")\n\n    @property\n    def summary_path(self) -&gt; str:\n        \"\"\"Path to the summary JSON file.\n\n        Returns:\n            Absolute path to the summary file.\n        \"\"\"\n        return os.path.join(self.session_dir, \"summary.json\")\n</code></pre>"},{"location":"reference/#core.session_store.SessionPaths.session_dir","title":"<code>session_dir: str</code>  <code>property</code>","text":"<p>Directory for session artifacts.</p> <p>Returns:</p> Type Description <code>str</code> <p>Absolute directory path for the session.</p>"},{"location":"reference/#core.session_store.SessionPaths.summary_path","title":"<code>summary_path: str</code>  <code>property</code>","text":"<p>Path to the summary JSON file.</p> <p>Returns:</p> Type Description <code>str</code> <p>Absolute path to the summary file.</p>"},{"location":"reference/#core.session_store.SessionPaths.transcript_path","title":"<code>transcript_path: str</code>  <code>property</code>","text":"<p>Path to the JSONL transcript file.</p> <p>Returns:</p> Type Description <code>str</code> <p>Absolute path to the transcript file.</p>"},{"location":"reference/#core.session_store.SessionStore","title":"<code>SessionStore</code>","text":"<p>Filesystem-backed storage for session transcripts and summaries.</p> Source code in <code>core/session_store.py</code> <pre><code>class SessionStore:\n    \"\"\"Filesystem-backed storage for session transcripts and summaries.\"\"\"\n    def __init__(self, root_dir: str | None = None) -&gt; None:\n        \"\"\"Initialize the store and ensure the root directory exists.\n\n        Args:\n            root_dir: Optional root directory override.\n        \"\"\"\n        if root_dir is None:\n            root_dir = os.getenv(\"MESEEKS_SESSION_DIR\", \"./data/sessions\")\n        self.root_dir = os.path.abspath(root_dir)\n        os.makedirs(self.root_dir, exist_ok=True)\n\n    def _index_path(self) -&gt; str:\n        \"\"\"Return the path for the session index file.\n\n        Returns:\n            Absolute path to index.json.\n        \"\"\"\n        return os.path.join(self.root_dir, \"index.json\")\n\n    def _load_index(self) -&gt; dict[str, dict[str, str]]:\n        \"\"\"Load the session index from disk, or return a default structure.\n\n        Returns:\n            Index data with tag mappings.\n        \"\"\"\n        index_path = self._index_path()\n        if not os.path.exists(index_path):\n            return {\"tags\": {}}\n        with open(index_path, encoding=\"utf-8\") as handle:\n            return json.load(handle)\n\n    def _save_index(self, data: dict[str, dict[str, str]]) -&gt; None:\n        \"\"\"Persist the session index to disk.\n\n        Args:\n            data: Index payload to serialize.\n        \"\"\"\n        with open(self._index_path(), \"w\", encoding=\"utf-8\") as handle:\n            json.dump(data, handle, indent=2)\n\n    def create_session(self) -&gt; str:\n        \"\"\"Create a new session directory and return its identifier.\n\n        Returns:\n            Newly generated session identifier.\n        \"\"\"\n        session_id = uuid.uuid4().hex\n        paths = self._paths(session_id)\n        os.makedirs(paths.session_dir, exist_ok=True)\n        return session_id\n\n    def _paths(self, session_id: str) -&gt; SessionPaths:\n        \"\"\"Build filesystem paths for a session.\n\n        Args:\n            session_id: Session identifier to resolve.\n\n        Returns:\n            SessionPaths with resolved filesystem locations.\n        \"\"\"\n        return SessionPaths(root=self.root_dir, session_id=session_id)\n\n    def append_event(self, session_id: str, event: Event) -&gt; None:\n        \"\"\"Append a single event record to the session transcript.\n\n        Args:\n            session_id: Session identifier to append to.\n            event: Event payload to persist.\n\n        Raises:\n            OSError: If writing to disk fails.\n        \"\"\"\n        paths = self._paths(session_id)\n        os.makedirs(paths.session_dir, exist_ok=True)\n        payload: EventRecord = {\"ts\": _utc_now(), **event}\n        with open(paths.transcript_path, \"a\", encoding=\"utf-8\") as handle:\n            handle.write(json.dumps(payload) + \"\\n\")\n\n    def load_transcript(self, session_id: str) -&gt; list[EventRecord]:\n        \"\"\"Load all transcript events for a session.\n\n        Args:\n            session_id: Session identifier to load.\n\n        Returns:\n            List of event records in chronological order.\n        \"\"\"\n        paths = self._paths(session_id)\n        if not os.path.exists(paths.transcript_path):\n            return []\n        events: list[EventRecord] = []\n        with open(paths.transcript_path, encoding=\"utf-8\") as handle:\n            for line in handle:\n                line = line.strip()\n                if not line:\n                    continue\n                try:\n                    events.append(json.loads(line))\n                except json.JSONDecodeError:\n                    logging.warning(\"Skipping malformed transcript line.\")\n        return events\n\n    def load_recent_events(\n        self,\n        session_id: str,\n        limit: int = 8,\n        include_types: set[str] | None = None,\n    ) -&gt; list[EventRecord]:\n        \"\"\"Load the most recent events, optionally filtered by type.\n\n        Args:\n            session_id: Session identifier to load.\n            limit: Maximum number of events to return.\n            include_types: Optional set of event types to include.\n\n        Returns:\n            List of recent event records.\n        \"\"\"\n        events = self.load_transcript(session_id)\n        if include_types:\n            events = [event for event in events if event.get(\"type\") in include_types]\n        if limit &lt;= 0:\n            return []\n        return events[-limit:]\n\n    def save_summary(self, session_id: str, summary: str) -&gt; None:\n        \"\"\"Persist a summary for a session.\n\n        Args:\n            session_id: Session identifier to update.\n            summary: Summary text to store.\n\n        Raises:\n            OSError: If writing to disk fails.\n        \"\"\"\n        paths = self._paths(session_id)\n        os.makedirs(paths.session_dir, exist_ok=True)\n        with open(paths.summary_path, \"w\", encoding=\"utf-8\") as handle:\n            json.dump({\"summary\": summary, \"updated_at\": _utc_now()}, handle, indent=2)\n\n    def load_summary(self, session_id: str) -&gt; str | None:\n        \"\"\"Load a previously saved summary, if present.\n\n        Args:\n            session_id: Session identifier to load.\n\n        Returns:\n            Summary text if stored; otherwise None.\n        \"\"\"\n        paths = self._paths(session_id)\n        if not os.path.exists(paths.summary_path):\n            return None\n        with open(paths.summary_path, encoding=\"utf-8\") as handle:\n            data = json.load(handle)\n        return data.get(\"summary\")\n\n    def list_sessions(self) -&gt; list[str]:\n        \"\"\"List all session IDs present in the root directory.\n\n        Returns:\n            Sorted list of session identifiers.\n        \"\"\"\n        if not os.path.exists(self.root_dir):\n            return []\n        return sorted(\n            name\n            for name in os.listdir(self.root_dir)\n            if os.path.isdir(os.path.join(self.root_dir, name))\n        )\n\n    def fork_session(self, source_session_id: str) -&gt; str:\n        \"\"\"Create a new session by copying events and summary from another.\n\n        Args:\n            source_session_id: Session identifier to clone.\n\n        Returns:\n            Identifier of the newly created session.\n        \"\"\"\n        events = self.load_transcript(source_session_id)\n        summary = self.load_summary(source_session_id)\n        new_session_id = self.create_session()\n        for event in events:\n            self.append_event(new_session_id, event)\n        if summary:\n            self.save_summary(new_session_id, summary)\n        return new_session_id\n\n    def tag_session(self, session_id: str, tag: str) -&gt; None:\n        \"\"\"Associate a tag with a session ID for quick lookup.\n\n        Args:\n            session_id: Session identifier to tag.\n            tag: Friendly tag name.\n        \"\"\"\n        index = self._load_index()\n        index.setdefault(\"tags\", {})[tag] = session_id\n        self._save_index(index)\n\n    def resolve_tag(self, tag: str) -&gt; str | None:\n        \"\"\"Resolve a tag to a session ID, if present.\n\n        Args:\n            tag: Friendly tag name to resolve.\n\n        Returns:\n            Session identifier if found; otherwise None.\n        \"\"\"\n        index = self._load_index()\n        return index.get(\"tags\", {}).get(tag)\n\n    def list_tags(self) -&gt; dict[str, str]:\n        \"\"\"Return a mapping of tags to session IDs.\n\n        Returns:\n            Dictionary mapping tags to session identifiers.\n        \"\"\"\n        index = self._load_index()\n        return dict(index.get(\"tags\", {}))\n</code></pre>"},{"location":"reference/#core.session_store.SessionStore.__init__","title":"<code>__init__(root_dir: str | None = None) -&gt; None</code>","text":"<p>Initialize the store and ensure the root directory exists.</p> <p>Parameters:</p> Name Type Description Default <code>root_dir</code> <code>str | None</code> <p>Optional root directory override.</p> <code>None</code> Source code in <code>core/session_store.py</code> <pre><code>def __init__(self, root_dir: str | None = None) -&gt; None:\n    \"\"\"Initialize the store and ensure the root directory exists.\n\n    Args:\n        root_dir: Optional root directory override.\n    \"\"\"\n    if root_dir is None:\n        root_dir = os.getenv(\"MESEEKS_SESSION_DIR\", \"./data/sessions\")\n    self.root_dir = os.path.abspath(root_dir)\n    os.makedirs(self.root_dir, exist_ok=True)\n</code></pre>"},{"location":"reference/#core.session_store.SessionStore.append_event","title":"<code>append_event(session_id: str, event: Event) -&gt; None</code>","text":"<p>Append a single event record to the session transcript.</p> <p>Parameters:</p> Name Type Description Default <code>session_id</code> <code>str</code> <p>Session identifier to append to.</p> required <code>event</code> <code>Event</code> <p>Event payload to persist.</p> required <p>Raises:</p> Type Description <code>OSError</code> <p>If writing to disk fails.</p> Source code in <code>core/session_store.py</code> <pre><code>def append_event(self, session_id: str, event: Event) -&gt; None:\n    \"\"\"Append a single event record to the session transcript.\n\n    Args:\n        session_id: Session identifier to append to.\n        event: Event payload to persist.\n\n    Raises:\n        OSError: If writing to disk fails.\n    \"\"\"\n    paths = self._paths(session_id)\n    os.makedirs(paths.session_dir, exist_ok=True)\n    payload: EventRecord = {\"ts\": _utc_now(), **event}\n    with open(paths.transcript_path, \"a\", encoding=\"utf-8\") as handle:\n        handle.write(json.dumps(payload) + \"\\n\")\n</code></pre>"},{"location":"reference/#core.session_store.SessionStore.create_session","title":"<code>create_session() -&gt; str</code>","text":"<p>Create a new session directory and return its identifier.</p> <p>Returns:</p> Type Description <code>str</code> <p>Newly generated session identifier.</p> Source code in <code>core/session_store.py</code> <pre><code>def create_session(self) -&gt; str:\n    \"\"\"Create a new session directory and return its identifier.\n\n    Returns:\n        Newly generated session identifier.\n    \"\"\"\n    session_id = uuid.uuid4().hex\n    paths = self._paths(session_id)\n    os.makedirs(paths.session_dir, exist_ok=True)\n    return session_id\n</code></pre>"},{"location":"reference/#core.session_store.SessionStore.fork_session","title":"<code>fork_session(source_session_id: str) -&gt; str</code>","text":"<p>Create a new session by copying events and summary from another.</p> <p>Parameters:</p> Name Type Description Default <code>source_session_id</code> <code>str</code> <p>Session identifier to clone.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Identifier of the newly created session.</p> Source code in <code>core/session_store.py</code> <pre><code>def fork_session(self, source_session_id: str) -&gt; str:\n    \"\"\"Create a new session by copying events and summary from another.\n\n    Args:\n        source_session_id: Session identifier to clone.\n\n    Returns:\n        Identifier of the newly created session.\n    \"\"\"\n    events = self.load_transcript(source_session_id)\n    summary = self.load_summary(source_session_id)\n    new_session_id = self.create_session()\n    for event in events:\n        self.append_event(new_session_id, event)\n    if summary:\n        self.save_summary(new_session_id, summary)\n    return new_session_id\n</code></pre>"},{"location":"reference/#core.session_store.SessionStore.list_sessions","title":"<code>list_sessions() -&gt; list[str]</code>","text":"<p>List all session IDs present in the root directory.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>Sorted list of session identifiers.</p> Source code in <code>core/session_store.py</code> <pre><code>def list_sessions(self) -&gt; list[str]:\n    \"\"\"List all session IDs present in the root directory.\n\n    Returns:\n        Sorted list of session identifiers.\n    \"\"\"\n    if not os.path.exists(self.root_dir):\n        return []\n    return sorted(\n        name\n        for name in os.listdir(self.root_dir)\n        if os.path.isdir(os.path.join(self.root_dir, name))\n    )\n</code></pre>"},{"location":"reference/#core.session_store.SessionStore.list_tags","title":"<code>list_tags() -&gt; dict[str, str]</code>","text":"<p>Return a mapping of tags to session IDs.</p> <p>Returns:</p> Type Description <code>dict[str, str]</code> <p>Dictionary mapping tags to session identifiers.</p> Source code in <code>core/session_store.py</code> <pre><code>def list_tags(self) -&gt; dict[str, str]:\n    \"\"\"Return a mapping of tags to session IDs.\n\n    Returns:\n        Dictionary mapping tags to session identifiers.\n    \"\"\"\n    index = self._load_index()\n    return dict(index.get(\"tags\", {}))\n</code></pre>"},{"location":"reference/#core.session_store.SessionStore.load_recent_events","title":"<code>load_recent_events(session_id: str, limit: int = 8, include_types: set[str] | None = None) -&gt; list[EventRecord]</code>","text":"<p>Load the most recent events, optionally filtered by type.</p> <p>Parameters:</p> Name Type Description Default <code>session_id</code> <code>str</code> <p>Session identifier to load.</p> required <code>limit</code> <code>int</code> <p>Maximum number of events to return.</p> <code>8</code> <code>include_types</code> <code>set[str] | None</code> <p>Optional set of event types to include.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[EventRecord]</code> <p>List of recent event records.</p> Source code in <code>core/session_store.py</code> <pre><code>def load_recent_events(\n    self,\n    session_id: str,\n    limit: int = 8,\n    include_types: set[str] | None = None,\n) -&gt; list[EventRecord]:\n    \"\"\"Load the most recent events, optionally filtered by type.\n\n    Args:\n        session_id: Session identifier to load.\n        limit: Maximum number of events to return.\n        include_types: Optional set of event types to include.\n\n    Returns:\n        List of recent event records.\n    \"\"\"\n    events = self.load_transcript(session_id)\n    if include_types:\n        events = [event for event in events if event.get(\"type\") in include_types]\n    if limit &lt;= 0:\n        return []\n    return events[-limit:]\n</code></pre>"},{"location":"reference/#core.session_store.SessionStore.load_summary","title":"<code>load_summary(session_id: str) -&gt; str | None</code>","text":"<p>Load a previously saved summary, if present.</p> <p>Parameters:</p> Name Type Description Default <code>session_id</code> <code>str</code> <p>Session identifier to load.</p> required <p>Returns:</p> Type Description <code>str | None</code> <p>Summary text if stored; otherwise None.</p> Source code in <code>core/session_store.py</code> <pre><code>def load_summary(self, session_id: str) -&gt; str | None:\n    \"\"\"Load a previously saved summary, if present.\n\n    Args:\n        session_id: Session identifier to load.\n\n    Returns:\n        Summary text if stored; otherwise None.\n    \"\"\"\n    paths = self._paths(session_id)\n    if not os.path.exists(paths.summary_path):\n        return None\n    with open(paths.summary_path, encoding=\"utf-8\") as handle:\n        data = json.load(handle)\n    return data.get(\"summary\")\n</code></pre>"},{"location":"reference/#core.session_store.SessionStore.load_transcript","title":"<code>load_transcript(session_id: str) -&gt; list[EventRecord]</code>","text":"<p>Load all transcript events for a session.</p> <p>Parameters:</p> Name Type Description Default <code>session_id</code> <code>str</code> <p>Session identifier to load.</p> required <p>Returns:</p> Type Description <code>list[EventRecord]</code> <p>List of event records in chronological order.</p> Source code in <code>core/session_store.py</code> <pre><code>def load_transcript(self, session_id: str) -&gt; list[EventRecord]:\n    \"\"\"Load all transcript events for a session.\n\n    Args:\n        session_id: Session identifier to load.\n\n    Returns:\n        List of event records in chronological order.\n    \"\"\"\n    paths = self._paths(session_id)\n    if not os.path.exists(paths.transcript_path):\n        return []\n    events: list[EventRecord] = []\n    with open(paths.transcript_path, encoding=\"utf-8\") as handle:\n        for line in handle:\n            line = line.strip()\n            if not line:\n                continue\n            try:\n                events.append(json.loads(line))\n            except json.JSONDecodeError:\n                logging.warning(\"Skipping malformed transcript line.\")\n    return events\n</code></pre>"},{"location":"reference/#core.session_store.SessionStore.resolve_tag","title":"<code>resolve_tag(tag: str) -&gt; str | None</code>","text":"<p>Resolve a tag to a session ID, if present.</p> <p>Parameters:</p> Name Type Description Default <code>tag</code> <code>str</code> <p>Friendly tag name to resolve.</p> required <p>Returns:</p> Type Description <code>str | None</code> <p>Session identifier if found; otherwise None.</p> Source code in <code>core/session_store.py</code> <pre><code>def resolve_tag(self, tag: str) -&gt; str | None:\n    \"\"\"Resolve a tag to a session ID, if present.\n\n    Args:\n        tag: Friendly tag name to resolve.\n\n    Returns:\n        Session identifier if found; otherwise None.\n    \"\"\"\n    index = self._load_index()\n    return index.get(\"tags\", {}).get(tag)\n</code></pre>"},{"location":"reference/#core.session_store.SessionStore.save_summary","title":"<code>save_summary(session_id: str, summary: str) -&gt; None</code>","text":"<p>Persist a summary for a session.</p> <p>Parameters:</p> Name Type Description Default <code>session_id</code> <code>str</code> <p>Session identifier to update.</p> required <code>summary</code> <code>str</code> <p>Summary text to store.</p> required <p>Raises:</p> Type Description <code>OSError</code> <p>If writing to disk fails.</p> Source code in <code>core/session_store.py</code> <pre><code>def save_summary(self, session_id: str, summary: str) -&gt; None:\n    \"\"\"Persist a summary for a session.\n\n    Args:\n        session_id: Session identifier to update.\n        summary: Summary text to store.\n\n    Raises:\n        OSError: If writing to disk fails.\n    \"\"\"\n    paths = self._paths(session_id)\n    os.makedirs(paths.session_dir, exist_ok=True)\n    with open(paths.summary_path, \"w\", encoding=\"utf-8\") as handle:\n        json.dump({\"summary\": summary, \"updated_at\": _utc_now()}, handle, indent=2)\n</code></pre>"},{"location":"reference/#core.session_store.SessionStore.tag_session","title":"<code>tag_session(session_id: str, tag: str) -&gt; None</code>","text":"<p>Associate a tag with a session ID for quick lookup.</p> <p>Parameters:</p> Name Type Description Default <code>session_id</code> <code>str</code> <p>Session identifier to tag.</p> required <code>tag</code> <code>str</code> <p>Friendly tag name.</p> required Source code in <code>core/session_store.py</code> <pre><code>def tag_session(self, session_id: str, tag: str) -&gt; None:\n    \"\"\"Associate a tag with a session ID for quick lookup.\n\n    Args:\n        session_id: Session identifier to tag.\n        tag: Friendly tag name.\n    \"\"\"\n    index = self._load_index()\n    index.setdefault(\"tags\", {})[tag] = session_id\n    self._save_index(index)\n</code></pre>"},{"location":"reference/#core.task_master","title":"<code>core.task_master</code>","text":"<p>Task planning and orchestration loop for Meeseeks.</p>"},{"location":"reference/#core.task_master.ContextSelection","title":"<code>ContextSelection</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Model output for selecting context events.</p> Source code in <code>core/task_master.py</code> <pre><code>class ContextSelection(BaseModel):\n    \"\"\"Model output for selecting context events.\"\"\"\n    keep_ids: list[int] = Field(default_factory=list)\n    drop_ids: list[int] = Field(default_factory=list)\n</code></pre>"},{"location":"reference/#core.task_master.StepReflection","title":"<code>StepReflection</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Model output for step-level reflection.</p> Source code in <code>core/task_master.py</code> <pre><code>class StepReflection(BaseModel):\n    \"\"\"Model output for step-level reflection.\"\"\"\n    status: Literal[\"ok\", \"retry\", \"revise\"] = Field(default=\"ok\")\n    notes: str | None = None\n    revised_argument: str | None = None\n</code></pre>"},{"location":"reference/#core.task_master.generate_action_plan","title":"<code>generate_action_plan(user_query: str, model_name: str | None = None, tool_registry: ToolRegistry | None = None, session_summary: str | None = None, recent_events: list[EventRecord] | None = None, selected_events: list[EventRecord] | None = None) -&gt; TaskQueue</code>","text":"<p>Use the LangChain pipeline to generate an action plan.</p> <p>Parameters:</p> Name Type Description Default <code>user_query</code> <code>str</code> <p>User request to transform into an action plan.</p> required <code>model_name</code> <code>str | None</code> <p>Optional model override for planning.</p> <code>None</code> <code>tool_registry</code> <code>ToolRegistry | None</code> <p>Optional registry used to list available tools.</p> <code>None</code> <code>session_summary</code> <code>str | None</code> <p>Optional summary to provide prior context.</p> <code>None</code> <code>recent_events</code> <code>list[EventRecord] | None</code> <p>Optional recent events to inject into the prompt.</p> <code>None</code> <code>selected_events</code> <code>list[EventRecord] | None</code> <p>Optional selected events to inject into the prompt.</p> <code>None</code> <p>Returns:</p> Type Description <code>TaskQueue</code> <p>TaskQueue containing the ordered action plan.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If model configuration is invalid.</p> Source code in <code>core/task_master.py</code> <pre><code>def generate_action_plan(\n    user_query: str,\n    model_name: str | None = None,\n    tool_registry: ToolRegistry | None = None,\n    session_summary: str | None = None,\n    recent_events: list[EventRecord] | None = None,\n    selected_events: list[EventRecord] | None = None,\n) -&gt; TaskQueue:\n    \"\"\"Use the LangChain pipeline to generate an action plan.\n\n    Args:\n        user_query: User request to transform into an action plan.\n        model_name: Optional model override for planning.\n        tool_registry: Optional registry used to list available tools.\n        session_summary: Optional summary to provide prior context.\n        recent_events: Optional recent events to inject into the prompt.\n        selected_events: Optional selected events to inject into the prompt.\n\n    Returns:\n        TaskQueue containing the ordered action plan.\n\n    Raises:\n        ValueError: If model configuration is invalid.\n    \"\"\"\n    if tool_registry is None:\n        tool_registry = load_registry()\n\n    user_id = \"meeseeks-task-master\"\n    session_id = f\"action-queue-id-{get_unique_timestamp()}\"\n    trace_name = user_id\n    version = os.getenv(\"VERSION\", \"Not Specified\")\n    release = os.getenv(\"ENVMODE\", \"Not Specified\")\n\n    langfuse_handler = build_langfuse_handler(\n        user_id=user_id,\n        session_id=session_id,\n        trace_name=trace_name,\n        version=version,\n        release=release,\n    )\n\n    model_name = cast(\n        str,\n        model_name\n        or os.getenv(\"ACTION_PLAN_MODEL\")\n        or os.getenv(\"DEFAULT_MODEL\", \"gpt-3.5-turbo\"),\n    )\n\n    model = build_chat_model(\n        model_name=model_name,\n        temperature=0.4,\n        openai_api_base=os.getenv(\"OPENAI_API_BASE\"),\n    )\n\n    parser = PydanticOutputParser(pydantic_object=TaskQueue)  # type: ignore[type-var]\n    logging.debug(\n        \"Generating action plan &lt;model='{}'; user_query='{}'&gt;\", model_name, user_query)\n\n    component_status: list[ComponentStatus] = [resolve_langfuse_status()]\n    if tool_registry is not None:\n        for spec in tool_registry.list_specs(include_disabled=True):\n            component_status.append(\n                ComponentStatus(\n                    name=f\"tool:{spec.tool_id}\",\n                    enabled=spec.enabled,\n                    reason=spec.metadata.get(\"disabled_reason\"),\n                )\n            )\n\n    available_tool_ids = [\n        spec.tool_id for spec in tool_registry.list_specs()\n    ]\n    prompt = ChatPromptTemplate(\n        messages=[\n            SystemMessage(\n                content=_augment_system_prompt(\n                    get_system_prompt(),\n                    tool_registry,\n                    session_summary=session_summary,\n                    recent_events=recent_events,\n                    selected_events=selected_events,\n                    component_status=component_status,\n                )\n            ),\n            HumanMessage(content=\"Turn on strip lights and heater.\"),\n            AIMessage(\n                content=get_task_master_examples(\n                    example_id=0,\n                    available_tools=available_tool_ids,\n                )\n            ),\n            HumanMessage(content=\"What is the weather today?\"),\n            AIMessage(\n                content=get_task_master_examples(\n                    example_id=1,\n                    available_tools=available_tool_ids,\n                )\n            ),\n            HumanMessagePromptTemplate.from_template(\n\n                    \"## Format Instructions\\n{format_instructions}\\n\"\n                    \"## Generate a task queue for the user query\\n{user_query}\"\n\n            ),\n        ],\n        partial_variables={\n            \"format_instructions\": parser.get_format_instructions()\n        },\n        input_variables=[\"user_query\"]\n    )\n\n    estimator = num_tokens_from_string(str(prompt))\n    logging.info(\"Input Prompt Token length is `{}`.\", estimator)\n\n    config: dict[str, object] = {}\n    if langfuse_handler is not None:\n        config[\"callbacks\"] = [langfuse_handler]\n\n    action_plan = (prompt | model | parser).invoke(\n        {\"user_query\": user_query.strip()},\n        config=config or None,\n    )\n\n    action_plan.human_message = user_query\n    logging.info(\"Action plan generated &lt;{}&gt;\", action_plan)\n    return action_plan\n</code></pre>"},{"location":"reference/#core.task_master.orchestrate_session","title":"<code>orchestrate_session(user_query: str, model_name: str | None = None, max_iters: int = 3, initial_task_queue: TaskQueue | None = None, return_state: bool = False, session_id: str | None = None, session_store: SessionStore | None = None, tool_registry: ToolRegistry | None = None, permission_policy: PermissionPolicy | None = None, approval_callback: Callable[[ActionStep], bool] | None = None, hook_manager: HookManager | None = None) -&gt; TaskQueue | tuple[TaskQueue, OrchestrationState]</code>","text":"<p>Orchestrate a session using a plan-act-observe-decide loop.</p> <p>Parameters:</p> Name Type Description Default <code>user_query</code> <code>str</code> <p>User input that initiates the orchestration cycle.</p> required <code>model_name</code> <code>str | None</code> <p>Optional model override for planning.</p> <code>None</code> <code>max_iters</code> <code>int</code> <p>Maximum planning iterations before giving up.</p> <code>3</code> <code>initial_task_queue</code> <code>TaskQueue | None</code> <p>Optional pre-computed task queue.</p> <code>None</code> <code>return_state</code> <code>bool</code> <p>Whether to return orchestration state along with results.</p> <code>False</code> <code>session_id</code> <code>str | None</code> <p>Optional existing session identifier.</p> <code>None</code> <code>session_store</code> <code>SessionStore | None</code> <p>Optional session store for transcript persistence.</p> <code>None</code> <code>tool_registry</code> <code>ToolRegistry | None</code> <p>Optional tool registry for resolution.</p> <code>None</code> <code>permission_policy</code> <code>PermissionPolicy | None</code> <p>Optional permission policy override.</p> <code>None</code> <code>approval_callback</code> <code>Callable[[ActionStep], bool] | None</code> <p>Optional approval callback for ASK decisions.</p> <code>None</code> <code>hook_manager</code> <code>HookManager | None</code> <p>Optional hook manager for lifecycle callbacks.</p> <code>None</code> <p>Returns:</p> Type Description <code>TaskQueue | tuple[TaskQueue, OrchestrationState]</code> <p>TaskQueue alone, or a tuple of TaskQueue and OrchestrationState.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If user_query is invalid.</p> Source code in <code>core/task_master.py</code> <pre><code>def orchestrate_session(\n    user_query: str,\n    model_name: str | None = None,\n    max_iters: int = 3,\n    initial_task_queue: TaskQueue | None = None,\n    return_state: bool = False,\n    session_id: str | None = None,\n    session_store: SessionStore | None = None,\n    tool_registry: ToolRegistry | None = None,\n    permission_policy: PermissionPolicy | None = None,\n    approval_callback: Callable[[ActionStep], bool] | None = None,\n    hook_manager: HookManager | None = None,\n) -&gt; TaskQueue | tuple[TaskQueue, OrchestrationState]:\n    \"\"\"Orchestrate a session using a plan-act-observe-decide loop.\n\n    Args:\n        user_query: User input that initiates the orchestration cycle.\n        model_name: Optional model override for planning.\n        max_iters: Maximum planning iterations before giving up.\n        initial_task_queue: Optional pre-computed task queue.\n        return_state: Whether to return orchestration state along with results.\n        session_id: Optional existing session identifier.\n        session_store: Optional session store for transcript persistence.\n        tool_registry: Optional tool registry for resolution.\n        permission_policy: Optional permission policy override.\n        approval_callback: Optional approval callback for ASK decisions.\n        hook_manager: Optional hook manager for lifecycle callbacks.\n\n    Returns:\n        TaskQueue alone, or a tuple of TaskQueue and OrchestrationState.\n\n    Raises:\n        ValueError: If user_query is invalid.\n    \"\"\"\n    if tool_registry is None:\n        tool_registry = load_registry()\n\n    resolved_model_name = (\n        model_name\n        or os.getenv(\"ACTION_PLAN_MODEL\")\n        or os.getenv(\"DEFAULT_MODEL\", \"gpt-3.5-turbo\")\n    )\n\n    if session_store is None:\n        session_store = SessionStore()\n\n    if session_id is None:\n        session_id = session_store.create_session()\n\n    state = OrchestrationState(goal=user_query, session_id=session_id)\n    state.summary = session_store.load_summary(session_id)\n    if state.tool_results is None:\n        state.tool_results = []\n    if state.open_questions is None:\n        state.open_questions = []\n    if hook_manager is None:\n        hook_manager = default_hook_manager()\n\n    session_store.append_event(\n        session_id, {\"type\": \"user\", \"payload\": {\"text\": user_query}}\n    )\n\n    if _should_update_summary(user_query):\n        state.summary = _update_summary_with_memory(\n            session_store,\n            session_id,\n            user_query.strip(),\n        )\n\n    updated_summary = _maybe_auto_compact(\n        session_store,\n        session_id,\n        resolved_model_name,\n        hook_manager,\n    )\n    if updated_summary:\n        state.summary = updated_summary\n\n    if user_query.strip() == \"/compact\":\n        events = session_store.load_transcript(session_id)\n        summary = summarize_events(events)\n        session_store.save_summary(session_id, summary)\n        state.summary = summary\n        state.done = True\n        state.done_reason = \"compacted\"\n        task_queue = _build_direct_response(\n            f\"Compaction complete. Summary: {summary}\"\n        )\n        if return_state:\n            return task_queue, state\n        return task_queue\n\n    recent_limit = int(os.getenv(\"MEESEEKS_RECENT_EVENT_LIMIT\", \"8\"))\n    events = session_store.load_transcript(session_id)\n    context_events = [\n        event\n        for event in events\n        if event.get(\"type\") in {\"user\", \"assistant\", \"tool_result\"}\n    ]\n    recent_events = context_events[-recent_limit:] if recent_limit &gt; 0 else []\n    candidate_events = (\n        context_events[:-recent_limit] if recent_limit &gt; 0 else context_events\n    )\n    selected_events: list[EventRecord] | None = None\n    budget = get_token_budget(events, state.summary, resolved_model_name)\n    selection_threshold = float(os.getenv(\"MEESEEKS_CONTEXT_SELECT_THRESHOLD\", \"0.8\"))\n    if (\n        os.getenv(\"MEESEEKS_CONTEXT_SELECTION\", \"1\") != \"0\"\n        and candidate_events\n        and budget.utilization &gt;= selection_threshold\n    ):\n        selected_events = _select_context_events(\n            candidate_events,\n            user_query=user_query,\n            model_name=resolved_model_name,\n        )\n\n    if initial_task_queue is None:\n        task_queue = generate_action_plan(\n            user_query=user_query,\n            model_name=resolved_model_name,\n            tool_registry=tool_registry,\n            session_summary=state.summary,\n            recent_events=recent_events,\n            selected_events=selected_events,\n        )\n    else:\n        task_queue = initial_task_queue\n    state.plan = task_queue.action_steps\n    steps: list[ActionStepPayload] = [\n        _serialize_action_step(step) for step in task_queue.action_steps\n    ]\n    session_store.append_event(\n        session_id,\n        {\n            \"type\": \"action_plan\",\n            \"payload\": {\"steps\": steps},\n        },\n    )\n\n    for iteration in range(max_iters):\n        task_queue = run_action_plan(\n            task_queue,\n            tool_registry=tool_registry,\n            event_logger=lambda event: session_store.append_event(session_id, event),\n            permission_policy=permission_policy,\n            approval_callback=approval_callback,\n            hook_manager=hook_manager,\n            model_name=resolved_model_name,\n        )\n        state.tool_results.append(task_queue.task_result or \"\")\n\n        if _action_steps_complete(task_queue):\n            state.done = True\n            state.done_reason = \"completed\"\n            break\n\n        if iteration &lt; max_iters - 1:\n            revised_query = (\n                f\"{user_query}\\n\\nPrevious tool results:\\n{task_queue.task_result or ''}\\n\"\n                \"Please revise the action plan to resolve remaining tasks.\"\n            )\n            events = session_store.load_transcript(session_id)\n            context_events = [\n                event\n                for event in events\n                if event.get(\"type\") in {\"user\", \"assistant\", \"tool_result\"}\n            ]\n            recent_events = context_events[-recent_limit:] if recent_limit &gt; 0 else []\n            candidate_events = (\n                context_events[:-recent_limit] if recent_limit &gt; 0 else context_events\n            )\n            selected_events = None\n            budget = get_token_budget(events, state.summary, resolved_model_name)\n            if (\n                os.getenv(\"MEESEEKS_CONTEXT_SELECTION\", \"1\") != \"0\"\n                and candidate_events\n                and budget.utilization &gt;= selection_threshold\n            ):\n                selected_events = _select_context_events(\n                    candidate_events,\n                    user_query=revised_query,\n                    model_name=resolved_model_name,\n                )\n            task_queue = generate_action_plan(\n                user_query=revised_query,\n                model_name=resolved_model_name,\n                tool_registry=tool_registry,\n                session_summary=state.summary,\n                recent_events=recent_events,\n                selected_events=selected_events,\n            )\n            state.plan = task_queue.action_steps\n            revised_steps: list[ActionStepPayload] = [\n                _serialize_action_step(step) for step in task_queue.action_steps\n            ]\n            session_store.append_event(\n                session_id,\n                {\n                    \"type\": \"action_plan\",\n                    \"payload\": {\"steps\": revised_steps},\n                },\n            )\n\n    if state.done and _should_synthesize_response(task_queue):\n        tool_outputs = _collect_tool_outputs(task_queue)\n        response = _synthesize_response(\n            user_query=user_query,\n            tool_outputs=tool_outputs,\n            model_name=resolved_model_name,\n            session_summary=state.summary,\n            recent_events=recent_events,\n            selected_events=selected_events,\n            tool_registry=tool_registry,\n        )\n        task_queue.task_result = response\n        session_store.append_event(\n            session_id,\n            {\"type\": \"assistant\", \"payload\": {\"text\": response}},\n        )\n\n    if not state.done:\n        state.done_reason = \"max_iterations_reached\"\n\n    session_store.append_event(\n        session_id,\n        {\n            \"type\": \"completion\",\n            \"payload\": {\n                \"done\": state.done,\n                \"done_reason\": state.done_reason,\n                \"task_result\": task_queue.task_result,\n            },\n        },\n    )\n\n    updated_summary = _maybe_auto_compact(\n        session_store,\n        session_id,\n        resolved_model_name,\n        hook_manager,\n    )\n    if updated_summary:\n        state.summary = updated_summary\n\n    if return_state:\n        return task_queue, state\n\n    return task_queue\n</code></pre>"},{"location":"reference/#core.task_master.run_action_plan","title":"<code>run_action_plan(task_queue: TaskQueue, tool_registry: ToolRegistry | None = None, event_logger: Callable[[Event], None] | None = None, permission_policy: PermissionPolicy | None = None, approval_callback: Callable[[ActionStep], bool] | None = None, hook_manager: HookManager | None = None, model_name: str | None = None) -&gt; TaskQueue</code>","text":"<p>Execute the generated action plan with permission checks.</p> <p>Parameters:</p> Name Type Description Default <code>task_queue</code> <code>TaskQueue</code> <p>The action plan to run.</p> required <code>tool_registry</code> <code>ToolRegistry | None</code> <p>Optional registry used to resolve tools.</p> <code>None</code> <code>event_logger</code> <code>Callable[[Event], None] | None</code> <p>Optional callback to emit orchestration events.</p> <code>None</code> <code>permission_policy</code> <code>PermissionPolicy | None</code> <p>Optional policy to decide tool permissions.</p> <code>None</code> <code>approval_callback</code> <code>Callable[[ActionStep], bool] | None</code> <p>Optional human approval callback.</p> <code>None</code> <code>hook_manager</code> <code>HookManager | None</code> <p>Optional hook manager for lifecycle callbacks.</p> <code>None</code> <code>model_name</code> <code>str | None</code> <p>Optional model name for step reflection.</p> <code>None</code> <p>Returns:</p> Type Description <code>TaskQueue</code> <p>Updated TaskQueue with action results.</p> Source code in <code>core/task_master.py</code> <pre><code>def run_action_plan(\n    task_queue: TaskQueue,\n    tool_registry: ToolRegistry | None = None,\n    event_logger: Callable[[Event], None] | None = None,\n    permission_policy: PermissionPolicy | None = None,\n    approval_callback: Callable[[ActionStep], bool] | None = None,\n    hook_manager: HookManager | None = None,\n    model_name: str | None = None,\n) -&gt; TaskQueue:\n    \"\"\"Execute the generated action plan with permission checks.\n\n    Args:\n        task_queue: The action plan to run.\n        tool_registry: Optional registry used to resolve tools.\n        event_logger: Optional callback to emit orchestration events.\n        permission_policy: Optional policy to decide tool permissions.\n        approval_callback: Optional human approval callback.\n        hook_manager: Optional hook manager for lifecycle callbacks.\n        model_name: Optional model name for step reflection.\n\n    Returns:\n        Updated TaskQueue with action results.\n    \"\"\"\n    if tool_registry is None:\n        tool_registry = load_registry()\n    if permission_policy is None:\n        permission_policy = load_permission_policy()\n    if approval_callback is None:\n        approval_callback = approval_callback_from_env()\n    if hook_manager is None:\n        hook_manager = default_hook_manager()\n\n    results: list[str] = []\n\n    for idx, action_step in enumerate(task_queue.action_steps):\n        logging.debug(\"Processing ActionStep: {}\", action_step)\n        decision = permission_policy.decide(action_step)\n        decision = hook_manager.run_permission_request(action_step, decision)\n        decision_logged = False\n        if decision == PermissionDecision.ASK:\n            approved = approval_callback(action_step) if approval_callback else False\n            decision = PermissionDecision.ALLOW if approved else PermissionDecision.DENY\n            if event_logger is not None:\n                event_logger(\n                    {\n                        \"type\": \"permission\",\n                        \"payload\": {\n                            \"action_consumer\": action_step.action_consumer,\n                            \"action_type\": action_step.action_type,\n                            \"action_argument\": action_step.action_argument,\n                            \"decision\": decision.value,\n                        },\n                    }\n                )\n                decision_logged = True\n        if decision == PermissionDecision.DENY:\n            MockSpeaker = get_mock_speaker()\n            message = (\n                \"Permission denied for \"\n                f\"{action_step.action_consumer}:{action_step.action_type}.\"\n            )\n            action_step.result = MockSpeaker(content=message)\n            results.append(message)\n            if event_logger is not None and not decision_logged:\n                event_logger(\n                    {\n                        \"type\": \"permission\",\n                        \"payload\": {\n                            \"action_consumer\": action_step.action_consumer,\n                            \"action_type\": action_step.action_type,\n                            \"action_argument\": action_step.action_argument,\n                            \"decision\": decision.value,\n                        },\n                    }\n                )\n            continue\n\n        action_step = hook_manager.run_pre_tool_use(action_step)\n        task_queue.action_steps[idx] = action_step\n        tool = tool_registry.get(action_step.action_consumer)\n\n        if tool is None:\n            logging.error(\n                \"No tool found for consumer: {}\", action_step.action_consumer\n            )\n            continue\n\n        spec = tool_registry.get_spec(action_step.action_consumer)\n        if spec is not None:\n            schema_error = _coerce_mcp_action_argument(action_step, spec)\n            if schema_error:\n                logging.error(\"Invalid MCP tool input: {}\", schema_error)\n                action_step.result = None\n                if event_logger is not None:\n                    event_logger(\n                        {\n                            \"type\": \"tool_result\",\n                            \"payload\": {\n                                \"action_consumer\": action_step.action_consumer,\n                                \"action_type\": action_step.action_type,\n                                \"action_argument\": action_step.action_argument,\n                                \"result\": None,\n                                \"error\": schema_error,\n                            },\n                        }\n                    )\n                continue\n\n        try:\n            action_result = tool.run(action_step)\n            action_result = hook_manager.run_post_tool_use(action_step, action_result)\n            action_step.result = action_result\n            content = getattr(action_result, \"content\", None)\n            if content is None:\n                content = \"\" if action_result is None else str(action_result)\n\n            reflection = _reflect_on_step(action_step, content, model_name)\n            if reflection is not None and reflection.status != \"ok\":\n                if reflection.revised_argument:\n                    action_step.action_argument = reflection.revised_argument\n                action_step.result = None\n                if event_logger is not None:\n                    event_logger(\n                        {\n                            \"type\": \"step_reflection\",\n                            \"payload\": {\n                                \"action_consumer\": action_step.action_consumer,\n                                \"action_type\": action_step.action_type,\n                                \"action_argument\": action_step.action_argument,\n                                \"status\": reflection.status,\n                                \"notes\": reflection.notes,\n                            },\n                        }\n                    )\n                task_queue.action_steps[idx] = action_step\n                break\n\n            results.append(content)\n            if event_logger is not None:\n                event_logger(\n                    {\n                        \"type\": \"tool_result\",\n                        \"payload\": {\n                            \"action_consumer\": action_step.action_consumer,\n                            \"action_type\": action_step.action_type,\n                            \"action_argument\": action_step.action_argument,\n                            \"result\": content,\n                        },\n                    }\n                )\n        except Exception as e:\n            logging.error(\"Error processing action step: {}\", e)\n            tool_registry.disable(action_step.action_consumer, f\"Runtime error: {e}\")\n            action_step.result = None\n            if event_logger is not None:\n                event_logger(\n                    {\n                        \"type\": \"tool_result\",\n                        \"payload\": {\n                            \"action_consumer\": action_step.action_consumer,\n                            \"action_type\": action_step.action_type,\n                            \"action_argument\": action_step.action_argument,\n                            \"result\": None,\n                            \"error\": str(e),\n                        },\n                    }\n                )\n            MockSpeaker = get_mock_speaker()\n            hook_manager.run_post_tool_use(\n                action_step, MockSpeaker(content=f\"Tool error: {e}\")\n            )\n\n    task_queue.task_result = \" \".join(results).strip()\n\n    return task_queue\n</code></pre>"},{"location":"reference/#core.token_budget","title":"<code>core.token_budget</code>","text":"<p>Token budgeting utilities.</p>"},{"location":"reference/#core.token_budget.TokenBudget","title":"<code>TokenBudget</code>  <code>dataclass</code>","text":"<p>Token accounting snapshot used to decide compaction.</p> <p>Attributes:</p> Name Type Description <code>total_tokens</code> <code>int</code> <p>Total tokens across events and summary.</p> <code>summary_tokens</code> <code>int</code> <p>Tokens attributed to the summary.</p> <code>event_tokens</code> <code>int</code> <p>Tokens attributed to raw events.</p> <code>context_window</code> <code>int</code> <p>Estimated model context window size.</p> <code>remaining_tokens</code> <code>int</code> <p>Remaining tokens before hitting the context window.</p> <code>utilization</code> <code>float</code> <p>Fraction of the context window currently used.</p> <code>threshold</code> <code>float</code> <p>Utilization threshold that triggers compaction.</p> Source code in <code>core/token_budget.py</code> <pre><code>@dataclass(frozen=True)\nclass TokenBudget:\n    \"\"\"Token accounting snapshot used to decide compaction.\n\n    Attributes:\n        total_tokens: Total tokens across events and summary.\n        summary_tokens: Tokens attributed to the summary.\n        event_tokens: Tokens attributed to raw events.\n        context_window: Estimated model context window size.\n        remaining_tokens: Remaining tokens before hitting the context window.\n        utilization: Fraction of the context window currently used.\n        threshold: Utilization threshold that triggers compaction.\n    \"\"\"\n    total_tokens: int\n    summary_tokens: int\n    event_tokens: int\n    context_window: int\n    remaining_tokens: int\n    utilization: float\n    threshold: float\n\n    @property\n    def needs_compact(self) -&gt; bool:\n        \"\"\"Return True when utilization exceeds the configured threshold.\"\"\"\n        return self.utilization &gt;= self.threshold\n</code></pre>"},{"location":"reference/#core.token_budget.TokenBudget.needs_compact","title":"<code>needs_compact: bool</code>  <code>property</code>","text":"<p>Return True when utilization exceeds the configured threshold.</p>"},{"location":"reference/#core.token_budget.estimate_event_tokens","title":"<code>estimate_event_tokens(events: Iterable[EventRecord]) -&gt; int</code>","text":"<p>Estimate total tokens for a sequence of events.</p> <p>Parameters:</p> Name Type Description Default <code>events</code> <code>Iterable[EventRecord]</code> <p>Events to analyze.</p> required <p>Returns:</p> Type Description <code>int</code> <p>Estimated token count.</p> Source code in <code>core/token_budget.py</code> <pre><code>def estimate_event_tokens(events: Iterable[EventRecord]) -&gt; int:\n    \"\"\"Estimate total tokens for a sequence of events.\n\n    Args:\n        events: Events to analyze.\n\n    Returns:\n        Estimated token count.\n    \"\"\"\n    texts = [_event_to_text(event) for event in events]\n    joined = \"\\n\".join(text for text in texts if text)\n    if not joined:\n        return 0\n    return num_tokens_from_string(joined)\n</code></pre>"},{"location":"reference/#core.token_budget.estimate_summary_tokens","title":"<code>estimate_summary_tokens(summary: str | None) -&gt; int</code>","text":"<p>Estimate token usage for the stored summary.</p> <p>Parameters:</p> Name Type Description Default <code>summary</code> <code>str | None</code> <p>Summary text or None.</p> required <p>Returns:</p> Type Description <code>int</code> <p>Estimated token count.</p> Source code in <code>core/token_budget.py</code> <pre><code>def estimate_summary_tokens(summary: str | None) -&gt; int:\n    \"\"\"Estimate token usage for the stored summary.\n\n    Args:\n        summary: Summary text or None.\n\n    Returns:\n        Estimated token count.\n    \"\"\"\n    if not summary:\n        return 0\n    return num_tokens_from_string(summary)\n</code></pre>"},{"location":"reference/#core.token_budget.get_context_window","title":"<code>get_context_window(model_name: str | None) -&gt; int</code>","text":"<p>Resolve the context window for a model name or default.</p> <p>Parameters:</p> Name Type Description Default <code>model_name</code> <code>str | None</code> <p>Optional model name to look up.</p> required <p>Returns:</p> Type Description <code>int</code> <p>Context window size in tokens.</p> Source code in <code>core/token_budget.py</code> <pre><code>def get_context_window(model_name: str | None) -&gt; int:\n    \"\"\"Resolve the context window for a model name or default.\n\n    Args:\n        model_name: Optional model name to look up.\n\n    Returns:\n        Context window size in tokens.\n    \"\"\"\n    default_window = int(os.getenv(\"MESEEKS_DEFAULT_CONTEXT_WINDOW\", \"128000\"))\n    if not model_name:\n        return default_window\n    overrides = _load_context_overrides()\n    if model_name in overrides:\n        return overrides[model_name]\n    parsed = _parse_context_from_model(model_name)\n    if parsed:\n        return parsed\n    return default_window\n</code></pre>"},{"location":"reference/#core.token_budget.get_token_budget","title":"<code>get_token_budget(events: Iterable[EventRecord], summary: str | None, model_name: str | None, threshold: float | None = None) -&gt; TokenBudget</code>","text":"<p>Calculate token utilization and remaining context budget.</p> <p>Parameters:</p> Name Type Description Default <code>events</code> <code>Iterable[EventRecord]</code> <p>Events to estimate.</p> required <code>summary</code> <code>str | None</code> <p>Optional summary text.</p> required <code>model_name</code> <code>str | None</code> <p>Optional model name to resolve context window size.</p> required <code>threshold</code> <code>float | None</code> <p>Optional utilization threshold override.</p> <code>None</code> <p>Returns:</p> Type Description <code>TokenBudget</code> <p>TokenBudget describing current utilization.</p> Source code in <code>core/token_budget.py</code> <pre><code>def get_token_budget(\n    events: Iterable[EventRecord],\n    summary: str | None,\n    model_name: str | None,\n    threshold: float | None = None,\n) -&gt; TokenBudget:\n    \"\"\"Calculate token utilization and remaining context budget.\n\n    Args:\n        events: Events to estimate.\n        summary: Optional summary text.\n        model_name: Optional model name to resolve context window size.\n        threshold: Optional utilization threshold override.\n\n    Returns:\n        TokenBudget describing current utilization.\n    \"\"\"\n    event_tokens = estimate_event_tokens(events)\n    summary_tokens = estimate_summary_tokens(summary)\n    total_tokens = event_tokens + summary_tokens\n    context_window = get_context_window(model_name)\n    remaining_tokens = max(context_window - total_tokens, 0)\n    if threshold is None:\n        threshold = float(os.getenv(\"MESEEKS_AUTO_COMPACT_THRESHOLD\", \"0.8\"))\n    utilization = total_tokens / context_window if context_window else 0.0\n    return TokenBudget(\n        total_tokens=total_tokens,\n        summary_tokens=summary_tokens,\n        event_tokens=event_tokens,\n        context_window=context_window,\n        remaining_tokens=remaining_tokens,\n        utilization=utilization,\n        threshold=threshold,\n    )\n</code></pre>"},{"location":"reference/#core.tool_registry","title":"<code>core.tool_registry</code>","text":"<p>Tool registry and manifest loading for Meeseeks.</p>"},{"location":"reference/#core.tool_registry.ToolRegistry","title":"<code>ToolRegistry</code>","text":"<p>Registry of configured tools and their instantiated runners.</p> Source code in <code>core/tool_registry.py</code> <pre><code>class ToolRegistry:\n    \"\"\"Registry of configured tools and their instantiated runners.\"\"\"\n    def __init__(self) -&gt; None:\n        \"\"\"Initialize an empty registry.\"\"\"\n        self._tools: dict[str, ToolSpec] = {}\n        self._instances: dict[str, ToolRunner] = {}\n\n    def disable(self, tool_id: str, reason: str) -&gt; None:\n        \"\"\"Disable a tool and store a reason for later reporting.\n\n        Args:\n            tool_id: Tool identifier to disable.\n            reason: Human-readable reason for disabling.\n        \"\"\"\n        spec = self._tools.get(tool_id)\n        if spec is None:\n            return\n        metadata = dict(spec.metadata)\n        metadata[\"disabled_reason\"] = reason\n        self._tools[tool_id] = ToolSpec(\n            tool_id=spec.tool_id,\n            name=spec.name,\n            description=spec.description,\n            factory=spec.factory,\n            enabled=False,\n            kind=spec.kind,\n            prompt_path=spec.prompt_path,\n            metadata=metadata,\n        )\n        if tool_id in self._instances:\n            self._instances.pop(tool_id, None)\n        set_available_tools(\n            [\n                current_id\n                for current_id, current_spec in self._tools.items()\n                if current_spec.enabled\n            ]\n        )\n\n    def register(self, spec: ToolSpec) -&gt; None:\n        \"\"\"Register a tool specification and update action validation.\n\n        Args:\n            spec: Tool specification to register.\n        \"\"\"\n        self._tools[spec.tool_id] = spec\n        set_available_tools(\n            [\n                tool_id\n                for tool_id, tool_spec in self._tools.items()\n                if tool_spec.enabled\n            ]\n        )\n\n    def get(self, tool_id: str) -&gt; ToolRunner | None:\n        \"\"\"Return an enabled tool runner, instantiating it if needed.\n\n        Args:\n            tool_id: Tool identifier to look up.\n\n        Returns:\n            ToolRunner instance if enabled; otherwise None.\n        \"\"\"\n        spec = self._tools.get(tool_id)\n        if spec is None or not spec.enabled:\n            return None\n        if tool_id not in self._instances:\n            try:\n                self._instances[tool_id] = spec.factory()\n            except Exception as exc:  # pragma: no cover - defensive\n                reason = f\"Initialization failed: {exc}\"\n                logging.warning(\"Disabling tool {}: {}\", tool_id, reason)\n                self.disable(tool_id, reason)\n                return None\n        return self._instances[tool_id]\n\n    def get_spec(self, tool_id: str) -&gt; ToolSpec | None:\n        \"\"\"Return the tool specification, even if disabled.\"\"\"\n        return self._tools.get(tool_id)\n\n    def list_specs(self, include_disabled: bool = False) -&gt; list[ToolSpec]:\n        \"\"\"List tool specifications, optionally including disabled tools.\n\n        Args:\n            include_disabled: Whether to include disabled tools.\n\n        Returns:\n            List of tool specifications.\n        \"\"\"\n        specs = list(self._tools.values())\n        if include_disabled:\n            return specs\n        return [spec for spec in specs if spec.enabled]\n\n    def tool_catalog(self) -&gt; list[dict[str, str]]:\n        \"\"\"Return a serialized catalog of registered tool metadata.\n\n        Returns:\n            List of dictionaries containing tool IDs, names, and descriptions.\n        \"\"\"\n        return [\n            {\n                \"tool_id\": spec.tool_id,\n                \"name\": spec.name,\n                \"description\": spec.description,\n            }\n            for spec in self.list_specs()\n        ]\n</code></pre>"},{"location":"reference/#core.tool_registry.ToolRegistry.__init__","title":"<code>__init__() -&gt; None</code>","text":"<p>Initialize an empty registry.</p> Source code in <code>core/tool_registry.py</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"Initialize an empty registry.\"\"\"\n    self._tools: dict[str, ToolSpec] = {}\n    self._instances: dict[str, ToolRunner] = {}\n</code></pre>"},{"location":"reference/#core.tool_registry.ToolRegistry.disable","title":"<code>disable(tool_id: str, reason: str) -&gt; None</code>","text":"<p>Disable a tool and store a reason for later reporting.</p> <p>Parameters:</p> Name Type Description Default <code>tool_id</code> <code>str</code> <p>Tool identifier to disable.</p> required <code>reason</code> <code>str</code> <p>Human-readable reason for disabling.</p> required Source code in <code>core/tool_registry.py</code> <pre><code>def disable(self, tool_id: str, reason: str) -&gt; None:\n    \"\"\"Disable a tool and store a reason for later reporting.\n\n    Args:\n        tool_id: Tool identifier to disable.\n        reason: Human-readable reason for disabling.\n    \"\"\"\n    spec = self._tools.get(tool_id)\n    if spec is None:\n        return\n    metadata = dict(spec.metadata)\n    metadata[\"disabled_reason\"] = reason\n    self._tools[tool_id] = ToolSpec(\n        tool_id=spec.tool_id,\n        name=spec.name,\n        description=spec.description,\n        factory=spec.factory,\n        enabled=False,\n        kind=spec.kind,\n        prompt_path=spec.prompt_path,\n        metadata=metadata,\n    )\n    if tool_id in self._instances:\n        self._instances.pop(tool_id, None)\n    set_available_tools(\n        [\n            current_id\n            for current_id, current_spec in self._tools.items()\n            if current_spec.enabled\n        ]\n    )\n</code></pre>"},{"location":"reference/#core.tool_registry.ToolRegistry.get","title":"<code>get(tool_id: str) -&gt; ToolRunner | None</code>","text":"<p>Return an enabled tool runner, instantiating it if needed.</p> <p>Parameters:</p> Name Type Description Default <code>tool_id</code> <code>str</code> <p>Tool identifier to look up.</p> required <p>Returns:</p> Type Description <code>ToolRunner | None</code> <p>ToolRunner instance if enabled; otherwise None.</p> Source code in <code>core/tool_registry.py</code> <pre><code>def get(self, tool_id: str) -&gt; ToolRunner | None:\n    \"\"\"Return an enabled tool runner, instantiating it if needed.\n\n    Args:\n        tool_id: Tool identifier to look up.\n\n    Returns:\n        ToolRunner instance if enabled; otherwise None.\n    \"\"\"\n    spec = self._tools.get(tool_id)\n    if spec is None or not spec.enabled:\n        return None\n    if tool_id not in self._instances:\n        try:\n            self._instances[tool_id] = spec.factory()\n        except Exception as exc:  # pragma: no cover - defensive\n            reason = f\"Initialization failed: {exc}\"\n            logging.warning(\"Disabling tool {}: {}\", tool_id, reason)\n            self.disable(tool_id, reason)\n            return None\n    return self._instances[tool_id]\n</code></pre>"},{"location":"reference/#core.tool_registry.ToolRegistry.get_spec","title":"<code>get_spec(tool_id: str) -&gt; ToolSpec | None</code>","text":"<p>Return the tool specification, even if disabled.</p> Source code in <code>core/tool_registry.py</code> <pre><code>def get_spec(self, tool_id: str) -&gt; ToolSpec | None:\n    \"\"\"Return the tool specification, even if disabled.\"\"\"\n    return self._tools.get(tool_id)\n</code></pre>"},{"location":"reference/#core.tool_registry.ToolRegistry.list_specs","title":"<code>list_specs(include_disabled: bool = False) -&gt; list[ToolSpec]</code>","text":"<p>List tool specifications, optionally including disabled tools.</p> <p>Parameters:</p> Name Type Description Default <code>include_disabled</code> <code>bool</code> <p>Whether to include disabled tools.</p> <code>False</code> <p>Returns:</p> Type Description <code>list[ToolSpec]</code> <p>List of tool specifications.</p> Source code in <code>core/tool_registry.py</code> <pre><code>def list_specs(self, include_disabled: bool = False) -&gt; list[ToolSpec]:\n    \"\"\"List tool specifications, optionally including disabled tools.\n\n    Args:\n        include_disabled: Whether to include disabled tools.\n\n    Returns:\n        List of tool specifications.\n    \"\"\"\n    specs = list(self._tools.values())\n    if include_disabled:\n        return specs\n    return [spec for spec in specs if spec.enabled]\n</code></pre>"},{"location":"reference/#core.tool_registry.ToolRegistry.register","title":"<code>register(spec: ToolSpec) -&gt; None</code>","text":"<p>Register a tool specification and update action validation.</p> <p>Parameters:</p> Name Type Description Default <code>spec</code> <code>ToolSpec</code> <p>Tool specification to register.</p> required Source code in <code>core/tool_registry.py</code> <pre><code>def register(self, spec: ToolSpec) -&gt; None:\n    \"\"\"Register a tool specification and update action validation.\n\n    Args:\n        spec: Tool specification to register.\n    \"\"\"\n    self._tools[spec.tool_id] = spec\n    set_available_tools(\n        [\n            tool_id\n            for tool_id, tool_spec in self._tools.items()\n            if tool_spec.enabled\n        ]\n    )\n</code></pre>"},{"location":"reference/#core.tool_registry.ToolRegistry.tool_catalog","title":"<code>tool_catalog() -&gt; list[dict[str, str]]</code>","text":"<p>Return a serialized catalog of registered tool metadata.</p> <p>Returns:</p> Type Description <code>list[dict[str, str]]</code> <p>List of dictionaries containing tool IDs, names, and descriptions.</p> Source code in <code>core/tool_registry.py</code> <pre><code>def tool_catalog(self) -&gt; list[dict[str, str]]:\n    \"\"\"Return a serialized catalog of registered tool metadata.\n\n    Returns:\n        List of dictionaries containing tool IDs, names, and descriptions.\n    \"\"\"\n    return [\n        {\n            \"tool_id\": spec.tool_id,\n            \"name\": spec.name,\n            \"description\": spec.description,\n        }\n        for spec in self.list_specs()\n    ]\n</code></pre>"},{"location":"reference/#core.tool_registry.ToolRunner","title":"<code>ToolRunner</code>","text":"<p>               Bases: <code>Protocol</code></p> Source code in <code>core/tool_registry.py</code> <pre><code>class ToolRunner(Protocol):\n    def run(self, action_step: ActionStep) -&gt; MockSpeaker:  # pragma: no cover\n        \"\"\"Execute an action step and return a speaker response.\n\n        Args:\n            action_step: Action step payload to execute.\n\n        Returns:\n            MockSpeaker response from the tool.\n        \"\"\"\n</code></pre>"},{"location":"reference/#core.tool_registry.ToolRunner.run","title":"<code>run(action_step: ActionStep) -&gt; MockSpeaker</code>","text":"<p>Execute an action step and return a speaker response.</p> <p>Parameters:</p> Name Type Description Default <code>action_step</code> <code>ActionStep</code> <p>Action step payload to execute.</p> required <p>Returns:</p> Type Description <code>MockSpeaker</code> <p>MockSpeaker response from the tool.</p> Source code in <code>core/tool_registry.py</code> <pre><code>def run(self, action_step: ActionStep) -&gt; MockSpeaker:  # pragma: no cover\n    \"\"\"Execute an action step and return a speaker response.\n\n    Args:\n        action_step: Action step payload to execute.\n\n    Returns:\n        MockSpeaker response from the tool.\n    \"\"\"\n</code></pre>"},{"location":"reference/#core.tool_registry.ToolSpec","title":"<code>ToolSpec</code>  <code>dataclass</code>","text":"<p>Metadata describing a tool available to the assistant.</p> <p>Attributes:</p> Name Type Description <code>tool_id</code> <code>str</code> <p>Unique identifier for the tool.</p> <code>name</code> <code>str</code> <p>Human-friendly tool name.</p> <code>description</code> <code>str</code> <p>Short description of the tool behavior.</p> <code>factory</code> <code>Callable[[], ToolRunner]</code> <p>Callable that instantiates a tool runner.</p> <code>enabled</code> <code>bool</code> <p>Whether the tool is enabled for execution.</p> <code>kind</code> <code>str</code> <p>Tool type, such as \"local\" or \"mcp\".</p> <code>prompt_path</code> <code>str | None</code> <p>Optional prompt fragment path without extension.</p> <code>metadata</code> <code>dict[str, Any]</code> <p>Additional tool metadata for adapters.</p> Source code in <code>core/tool_registry.py</code> <pre><code>@dataclass(frozen=True)\nclass ToolSpec:\n    \"\"\"Metadata describing a tool available to the assistant.\n\n    Attributes:\n        tool_id: Unique identifier for the tool.\n        name: Human-friendly tool name.\n        description: Short description of the tool behavior.\n        factory: Callable that instantiates a tool runner.\n        enabled: Whether the tool is enabled for execution.\n        kind: Tool type, such as \"local\" or \"mcp\".\n        prompt_path: Optional prompt fragment path without extension.\n        metadata: Additional tool metadata for adapters.\n    \"\"\"\n    tool_id: str\n    name: str\n    description: str\n    factory: Callable[[], ToolRunner]\n    enabled: bool = True\n    kind: str = \"local\"\n    prompt_path: str | None = None\n    metadata: dict[str, Any] = field(default_factory=dict)\n</code></pre>"},{"location":"reference/#core.tool_registry.load_registry","title":"<code>load_registry(manifest_path: str | None = None) -&gt; ToolRegistry</code>","text":"<p>Load tool registry from a JSON manifest if available.</p> <p>Manifest format: {   \"tools\": [     {\"tool_id\": \"...\", \"name\": \"...\", \"description\": \"...\", \"module\": \"...\",      \"class\": \"...\", \"enabled\": true, \"kind\": \"local\"},     {\"tool_id\": \"mcp_weather\", \"name\": \"Weather\", \"description\": \"...\",      \"kind\": \"mcp\", \"server\": \"weather\", \"tool\": \"get_weather\"}   ] }</p> <p>Parameters:</p> Name Type Description Default <code>manifest_path</code> <code>str | None</code> <p>Optional path to a tool manifest JSON file.</p> <code>None</code> <p>Returns:</p> Type Description <code>ToolRegistry</code> <p>ToolRegistry populated from the manifest or defaults.</p> Source code in <code>core/tool_registry.py</code> <pre><code>def load_registry(manifest_path: str | None = None) -&gt; ToolRegistry:\n    \"\"\"Load tool registry from a JSON manifest if available.\n\n    Manifest format:\n    {\n      \"tools\": [\n        {\"tool_id\": \"...\", \"name\": \"...\", \"description\": \"...\", \"module\": \"...\",\n         \"class\": \"...\", \"enabled\": true, \"kind\": \"local\"},\n        {\"tool_id\": \"mcp_weather\", \"name\": \"Weather\", \"description\": \"...\",\n         \"kind\": \"mcp\", \"server\": \"weather\", \"tool\": \"get_weather\"}\n      ]\n    }\n\n    Args:\n        manifest_path: Optional path to a tool manifest JSON file.\n\n    Returns:\n        ToolRegistry populated from the manifest or defaults.\n    \"\"\"\n    if manifest_path is None:\n        manifest_path = os.getenv(\"MESEEKS_TOOL_MANIFEST\")\n\n    if not manifest_path:\n        mcp_config_path = os.getenv(\"MESEEKS_MCP_CONFIG\")\n        if mcp_config_path:\n            auto_manifest = _ensure_auto_manifest(mcp_config_path)\n            if auto_manifest:\n                manifest_path = auto_manifest\n\n    if not manifest_path:\n        return _default_registry()\n\n    manifest_path = os.path.abspath(manifest_path)\n    if not os.path.exists(manifest_path):\n        logging.warning(\"Tool manifest not found: {}\", manifest_path)\n        return _default_registry()\n\n    try:\n        with open(manifest_path, encoding=\"utf-8\") as handle:\n            manifest = json.load(handle)\n    except Exception as exc:  # pragma: no cover - defensive\n        logging.error(\"Failed to load tool manifest: {}\", exc)\n        return _default_registry()\n\n    registry = ToolRegistry()\n    for tool in manifest.get(\"tools\", []):\n        kind = tool.get(\"kind\", \"local\")\n        prompt_path = tool.get(\"prompt\")\n        if kind == \"local\":\n            module_path = tool.get(\"module\")\n            class_name = tool.get(\"class\")\n            if not module_path or not class_name:\n                logging.warning(\"Skipping tool with missing module/class: {}\", tool)\n                continue\n            factory = _import_factory(module_path, class_name)\n        else:\n            from tools.integration.mcp import MCPToolRunner\n\n            server_name = tool.get(\"server\")\n            tool_name = tool.get(\"tool\")\n            if not server_name or not tool_name:\n                logging.warning(\"Skipping MCP tool with missing server/tool: {}\", tool)\n                continue\n            def _mcp_factory(\n                server_name: str = server_name,\n                tool_name: str = tool_name,\n            ) -&gt; MCPToolRunner:\n                return MCPToolRunner(server_name=server_name, tool_name=tool_name)\n\n            factory = _mcp_factory\n\n        spec = ToolSpec(\n            tool_id=tool.get(\"tool_id\", \"\"),\n            name=tool.get(\"name\", tool.get(\"tool_id\", \"\")),\n            description=tool.get(\"description\", \"\"),\n            factory=factory,\n            enabled=tool.get(\"enabled\", True),\n            kind=kind,\n            prompt_path=prompt_path,\n            metadata={\n                key: value\n                for key, value in tool.items()\n                if key\n                not in {\n                    \"tool_id\",\n                    \"name\",\n                    \"description\",\n                    \"module\",\n                    \"class\",\n                    \"enabled\",\n                    \"kind\",\n                    \"prompt\",\n                }\n            },\n        )\n        if not spec.tool_id:\n            logging.warning(\"Skipping tool with empty tool_id: {}\", tool)\n            continue\n        registry.register(spec)\n\n    if not registry.list_specs(include_disabled=True):\n        return _default_registry()\n\n    return registry\n</code></pre>"},{"location":"reference/#core.types","title":"<code>core.types</code>","text":"<p>Shared type definitions for core components.</p>"},{"location":"reference/#core.types.ActionPlanPayload","title":"<code>ActionPlanPayload</code>","text":"<p>               Bases: <code>TypedDict</code></p> <p>Payload describing an action plan.</p> Source code in <code>core/types.py</code> <pre><code>class ActionPlanPayload(TypedDict):\n    \"\"\"Payload describing an action plan.\"\"\"\n    steps: list[ActionStepPayload]\n</code></pre>"},{"location":"reference/#core.types.ActionStepPayload","title":"<code>ActionStepPayload</code>","text":"<p>               Bases: <code>TypedDict</code></p> <p>Serialized action step data sent to/from orchestration.</p> Source code in <code>core/types.py</code> <pre><code>class ActionStepPayload(TypedDict):\n    \"\"\"Serialized action step data sent to/from orchestration.\"\"\"\n    action_consumer: str\n    action_type: str\n    action_argument: str | dict[str, Any]\n    title: NotRequired[str]\n    objective: NotRequired[str]\n    execution_checklist: NotRequired[list[str]]\n    expected_output: NotRequired[str]\n</code></pre>"},{"location":"reference/#core.types.AssistantPayload","title":"<code>AssistantPayload</code>","text":"<p>               Bases: <code>TypedDict</code></p> <p>Payload describing an assistant response.</p> Source code in <code>core/types.py</code> <pre><code>class AssistantPayload(TypedDict):\n    \"\"\"Payload describing an assistant response.\"\"\"\n    text: str\n</code></pre>"},{"location":"reference/#core.types.CompletionPayload","title":"<code>CompletionPayload</code>","text":"<p>               Bases: <code>TypedDict</code></p> <p>Payload describing overall completion state.</p> Source code in <code>core/types.py</code> <pre><code>class CompletionPayload(TypedDict):\n    \"\"\"Payload describing overall completion state.\"\"\"\n    done: bool\n    done_reason: str | None\n    task_result: str | None\n</code></pre>"},{"location":"reference/#core.types.Event","title":"<code>Event</code>","text":"<p>               Bases: <code>TypedDict</code></p> <p>Base event payload stored in transcripts.</p> Source code in <code>core/types.py</code> <pre><code>class Event(TypedDict):\n    \"\"\"Base event payload stored in transcripts.\"\"\"\n    type: str\n    payload: EventPayload\n</code></pre>"},{"location":"reference/#core.types.EventRecord","title":"<code>EventRecord</code>","text":"<p>               Bases: <code>Event</code></p> <p>Event payload with a persisted timestamp.</p> Source code in <code>core/types.py</code> <pre><code>class EventRecord(Event):\n    \"\"\"Event payload with a persisted timestamp.\"\"\"\n    ts: str\n</code></pre>"},{"location":"reference/#core.types.PermissionPayload","title":"<code>PermissionPayload</code>","text":"<p>               Bases: <code>TypedDict</code></p> <p>Payload emitted for permission decisions.</p> Source code in <code>core/types.py</code> <pre><code>class PermissionPayload(TypedDict):\n    \"\"\"Payload emitted for permission decisions.\"\"\"\n    action_consumer: str\n    action_type: str\n    action_argument: str\n    decision: str\n</code></pre>"},{"location":"reference/#core.types.ToolResultPayload","title":"<code>ToolResultPayload</code>","text":"<p>               Bases: <code>TypedDict</code></p> <p>Payload describing the outcome of a tool invocation.</p> Source code in <code>core/types.py</code> <pre><code>class ToolResultPayload(TypedDict):\n    \"\"\"Payload describing the outcome of a tool invocation.\"\"\"\n    action_consumer: str\n    action_type: str\n    action_argument: str | dict[str, Any]\n    result: str | None\n    error: NotRequired[str]\n</code></pre>"},{"location":"reference/#core.types.UserPayload","title":"<code>UserPayload</code>","text":"<p>               Bases: <code>TypedDict</code></p> <p>Payload describing a user message.</p> Source code in <code>core/types.py</code> <pre><code>class UserPayload(TypedDict):\n    \"\"\"Payload describing a user message.\"\"\"\n    text: str\n</code></pre>"},{"location":"reference/#tools","title":"Tools","text":""},{"location":"reference/#tools.core.talk_to_user","title":"<code>tools.core.talk_to_user</code>","text":"<p>Echo tool for simple user responses.</p> <p>Talk to User is a basic tool that accepts user input and returns it as output. It serves as a minimal example and can be extended with filters or validators.</p>"},{"location":"reference/#tools.core.talk_to_user.TalkToUser","title":"<code>TalkToUser</code>","text":"<p>               Bases: <code>AbstractTool</code></p> <p>Tool that returns the user's message back as the response.</p> Source code in <code>tools/core/talk_to_user.py</code> <pre><code>class TalkToUser(AbstractTool):\n    \"\"\"Tool that returns the user's message back as the response.\"\"\"\n\n    def __init__(self) -&gt; None:\n        \"\"\"Initialize the tool metadata.\"\"\"\n        super().__init__(\n            name=\"Talk to User\",\n            description=\"Directly talk to the user.\",\n            use_llm=False,\n        )\n\n    def set_state(self, action_step: ActionStep | None = None) -&gt; MockSpeaker:\n        \"\"\"Return the action argument as the response content.\n\n        Args:\n            action_step: Action step containing the response text.\n\n        Returns:\n            MockSpeaker wrapping the response content.\n\n        Raises:\n            ValueError: If action_step is None.\n        \"\"\"\n        if action_step is None:\n            raise ValueError(\"Action step cannot be None.\")\n        content = action_step.action_argument\n        if isinstance(content, dict):\n            content = json.dumps(content, ensure_ascii=True)\n        MockSpeaker = get_mock_speaker()\n        return MockSpeaker(content=content)\n\n    def get_state(self, action_step: ActionStep | None = None) -&gt; MockSpeaker:\n        \"\"\"TalkToUser does not support read operations.\n\n        Args:\n            action_step: Ignored action step.\n\n        Raises:\n            NotImplementedError: Always, because GET is unsupported.\n        \"\"\"\n        raise NotImplementedError(\"This method is not supported by TalkToUser.\")\n</code></pre>"},{"location":"reference/#tools.core.talk_to_user.TalkToUser.__init__","title":"<code>__init__() -&gt; None</code>","text":"<p>Initialize the tool metadata.</p> Source code in <code>tools/core/talk_to_user.py</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"Initialize the tool metadata.\"\"\"\n    super().__init__(\n        name=\"Talk to User\",\n        description=\"Directly talk to the user.\",\n        use_llm=False,\n    )\n</code></pre>"},{"location":"reference/#tools.core.talk_to_user.TalkToUser.get_state","title":"<code>get_state(action_step: ActionStep | None = None) -&gt; MockSpeaker</code>","text":"<p>TalkToUser does not support read operations.</p> <p>Parameters:</p> Name Type Description Default <code>action_step</code> <code>ActionStep | None</code> <p>Ignored action step.</p> <code>None</code> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>Always, because GET is unsupported.</p> Source code in <code>tools/core/talk_to_user.py</code> <pre><code>def get_state(self, action_step: ActionStep | None = None) -&gt; MockSpeaker:\n    \"\"\"TalkToUser does not support read operations.\n\n    Args:\n        action_step: Ignored action step.\n\n    Raises:\n        NotImplementedError: Always, because GET is unsupported.\n    \"\"\"\n    raise NotImplementedError(\"This method is not supported by TalkToUser.\")\n</code></pre>"},{"location":"reference/#tools.core.talk_to_user.TalkToUser.set_state","title":"<code>set_state(action_step: ActionStep | None = None) -&gt; MockSpeaker</code>","text":"<p>Return the action argument as the response content.</p> <p>Parameters:</p> Name Type Description Default <code>action_step</code> <code>ActionStep | None</code> <p>Action step containing the response text.</p> <code>None</code> <p>Returns:</p> Type Description <code>MockSpeaker</code> <p>MockSpeaker wrapping the response content.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If action_step is None.</p> Source code in <code>tools/core/talk_to_user.py</code> <pre><code>def set_state(self, action_step: ActionStep | None = None) -&gt; MockSpeaker:\n    \"\"\"Return the action argument as the response content.\n\n    Args:\n        action_step: Action step containing the response text.\n\n    Returns:\n        MockSpeaker wrapping the response content.\n\n    Raises:\n        ValueError: If action_step is None.\n    \"\"\"\n    if action_step is None:\n        raise ValueError(\"Action step cannot be None.\")\n    content = action_step.action_argument\n    if isinstance(content, dict):\n        content = json.dumps(content, ensure_ascii=True)\n    MockSpeaker = get_mock_speaker()\n    return MockSpeaker(content=content)\n</code></pre>"},{"location":"reference/#tools.integration.homeassistant","title":"<code>tools.integration.homeassistant</code>","text":"<p>Home Assistant integration tools and data models.</p>"},{"location":"reference/#tools.integration.homeassistant.CacheHolder","title":"<code>CacheHolder</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol describing objects with a Home Assistant cache attribute.</p> <p>Attributes:</p> Name Type Description <code>cache</code> <code>HomeAssistantCache</code> <p>Home Assistant cache payload.</p> Source code in <code>tools/integration/homeassistant.py</code> <pre><code>@runtime_checkable\nclass CacheHolder(Protocol):\n    \"\"\"Protocol describing objects with a Home Assistant cache attribute.\n\n    Attributes:\n        cache: Home Assistant cache payload.\n    \"\"\"\n    cache: HomeAssistantCache\n</code></pre>"},{"location":"reference/#tools.integration.homeassistant.HomeAssistant","title":"<code>HomeAssistant</code>","text":"<p>               Bases: <code>AbstractTool</code></p> <p>A service to manage and interact with Home Assistant.</p> Source code in <code>tools/integration/homeassistant.py</code> <pre><code>class HomeAssistant(AbstractTool):\n    \"\"\"A service to manage and interact with Home Assistant.\"\"\"\n\n    def __init__(self) -&gt; None:\n        \"\"\"Initialize the Home Assistant tool with environment defaults.\"\"\"\n        super().__init__(\n            name=\"Home Assistant\",\n            description=\"A service to manage and interact with Home Assistant\"\n        )\n        self.base_url = os.getenv(\"HA_URL\", None)\n        self._api_token = os.getenv(\"HA_TOKEN\", None)\n        self.cache: HomeAssistantCache = {\n            \"entity_ids\": [],\n            \"sensor_ids\": [],\n            \"entities\": [],\n            \"services\": [],\n            \"sensors\": [],\n            \"allowed_domains\": [\n                \"scene\", \"switch\", \"weather\", \"kodi\", \"automation\"]\n        }\n\n        if not self.base_url or not self._api_token:\n            raise ValueError(\n                \"HA_URL and HA_TOKEN must be set in the environment.\")\n\n        self.api_headers: dict[str, str] = {\n            \"Authorization\": f\"Bearer {self._api_token}\",\n            \"Content-Type\": \"application/json\"\n        }\n\n    @cache_monitor\n    def update_services(self) -&gt; bool:\n        \"\"\"Update the list of services from Home Assistant.\n\n        Returns:\n            True when services are fetched successfully.\n        \"\"\"\n        url = f\"{self.base_url}/services\"\n        try:\n            response = requests.get(url, headers=self.api_headers, timeout=30)\n            status_code = getattr(response, \"status_code\", None)\n            if status_code in {401, 403}:\n                logging.error(\n                    \"Home Assistant authorization failed with status {}.\", status_code\n                )\n                raise PermissionError(\"Home Assistant authorization failed.\")\n            response.raise_for_status()\n            self.cache[\"services\"] = response.json()\n            self._save_json(self.cache[\"services\"], \"services.json\")\n            return True\n        except requests.exceptions.RequestException as e:\n            logging.error(\"Error: {}\", e)\n            return False\n\n    @cache_monitor\n    def update_entities(self) -&gt; bool:\n        \"\"\"Update the list of entities from Home Assistant.\n\n        Returns:\n            True when entities are fetched successfully.\n        \"\"\"\n        url = f\"{self.base_url}/states\"\n        try:\n            response = requests.get(url, headers=self.api_headers, timeout=30)\n            status_code = getattr(response, \"status_code\", None)\n            if status_code in {401, 403}:\n                logging.error(\n                    \"Home Assistant authorization failed with status {}.\", status_code\n                )\n                raise PermissionError(\"Home Assistant authorization failed.\")\n            response.raise_for_status()\n            self.cache[\"entities\"] = response.json()\n            return True\n        except requests.exceptions.RequestException as e:\n            logging.error(\"Error: {}\", e)\n            return False\n\n    @cache_monitor\n    def update_entity_ids(self) -&gt; bool:\n        \"\"\"Update the list of entity IDs from Home Assistant.\n\n        Returns:\n            True when entity IDs are populated.\n\n        Raises:\n            ValueError: If no entities are available for ID extraction.\n        \"\"\"\n        # TODO: Always assumes blacklist by default due to cache_monitor.\n        self.update_entities()\n        entities = self.cache[\"entities\"]\n        if not entities:\n            raise ValueError(\"No entities found while updating entity IDs.\")\n        self.cache[\"entity_ids\"] = [entity[\"entity_id\"] for entity in entities]\n        logging.info(\"Entity IDs updated.\")\n        return True\n\n    @cache_monitor\n    def update_cache(self) -&gt; None:\n        \"\"\"Update the entire cache.\n\n        Raises:\n            ValueError: If entity IDs cannot be derived.\n        \"\"\"\n        self.update_entity_ids()\n        self.update_services()\n        self._save_json(self.cache[\"entities\"], \"entities.json\")\n        self._save_json(self.cache[\"sensors\"], \"sensors.json\")\n\n    def call_service(\n        self,\n        domain: str,\n        service: str,\n        entity_id: str,\n        data: dict | None = None,\n    ) -&gt; tuple[bool, list[dict[str, Any]]]:\n        \"\"\"Call a service in Home Assistant.\n\n        Args:\n            domain: Home Assistant domain name (e.g., \"light\").\n            service: Service name within the domain (e.g., \"turn_on\").\n            entity_id: Entity ID to target.\n            data: Optional extra payload for the service call.\n\n        Returns:\n            Tuple of success flag and JSON response payload.\n\n        Raises:\n            ValueError: If the domain is not allowed.\n        \"\"\"\n        if domain not in self.cache[\"allowed_domains\"]:\n            raise ValueError(f\"Domain does not exist or blacklisted: {domain}\")\n\n        url = f\"{self.base_url}/services/{domain}/{service}\"\n        payload = {\"entity_id\": entity_id}\n        if data:\n            payload.update(data)\n\n        try:\n            response = requests.post(\n                url, headers=self.api_headers, json=payload, timeout=30)\n            status_code = getattr(response, \"status_code\", None)\n            if status_code in {401, 403}:\n                logging.error(\n                    \"Home Assistant authorization failed with status {}.\", status_code\n                )\n                raise PermissionError(\"Home Assistant authorization failed.\")\n            response.raise_for_status()\n            logging.info(\"Service &lt;{}.{}&gt; called on entity &lt;{}&gt; returned `{}`.\",\n                         domain, service, entity_id, response.text)\n            return True, response.json()\n        except requests.exceptions.RequestException as e:\n            logging.error(\n                \"Unable to call service &lt;{}.{}&gt; on entity &lt;{}&gt;: {}\", domain, service, entity_id, e)\n            return False, []\n\n    @staticmethod\n    def _create_set_prompt(\n        system_prompt: str,\n        parser: PydanticOutputParser,\n    ) -&gt; ChatPromptTemplate:\n        \"\"\"Create the prompt template for a set-state operation.\n\n        Args:\n            system_prompt: System prompt content.\n            parser: Pydantic output parser for HomeAssistantCall.\n\n        Returns:\n            ChatPromptTemplate configured for set-state tasks.\n        \"\"\"\n        example = HomeAssistantCall(\n            domain=\"scene\", service=\"turn_on\", entity_id=\"scene.lamp_power_on\")\n        prompt = ChatPromptTemplate(\n            messages=[\n                SystemMessage(content=system_prompt),\n                HumanMessage(content=\"Turn on the lamp lights.\"),\n                AIMessage(content=example.json()),\n                HumanMessagePromptTemplate.from_template(\n                    \"The user asked you to `{action_step}`. You must use the information \"\n                    \"provided to pick the right Home Assistant service call values only \"\n                    \"considering the current user query.\\n\\n\"\n                    \"## Format Instructions\\n{format_instructions}\\n\\n\"\n                    \"## Home Assistant Entities and Domain-Services\\n```\\n{context}```\\n\"\n                ),\n            ],\n            partial_variables={\n                \"format_instructions\": parser.get_format_instructions()},\n            input_variables=[\"action_step\"]\n        )\n        return prompt\n\n    @staticmethod\n    def _create_get_prompt(system_prompt: str) -&gt; ChatPromptTemplate:\n        \"\"\"Create the prompt template for a get-state operation.\n\n        Args:\n            system_prompt: System prompt content.\n\n        Returns:\n            ChatPromptTemplate configured for get-state tasks.\n        \"\"\"\n        prompt = ChatPromptTemplate(\n            messages=[\n                SystemMessage(content=system_prompt),\n                HumanMessage(content=\"How is the air quality today?\"),\n                AIMessage(\n                    content=(\n                        \"AccuWeather reported today's air quality in your home as good. \"\n                        \"This level of air quality ensures that the environment is healthy, \"\n                        \"supporting your daily activities and wellbeing without any air \"\n                        \"quality-related risks.\"\n                    )\n                ),\n                HumanMessagePromptTemplate.from_template(\n                    \"The user asked you to `{action_step}`. You must use the sensor \"\n                    \"information to answer the user's query. Keep your answer \"\n                    \"analytical, brief and useful.\\n\\n\"\n                    \"## Home Assistant Sensors\\n```\\n{context}```\\n\"\n                ),\n            ],\n            input_variables=[\"action_step\"]\n        )\n        return prompt\n\n    @staticmethod\n    def _clean_answer(answer: str) -&gt; str:\n        \"\"\"Clean the answer by removing/replacing characters.\n\n        Args:\n            answer: Raw answer string to normalize.\n\n        Returns:\n            Cleaned answer string.\n        \"\"\"\n        replacements = {\n            # Common entities\n            \"RealFeel\": \"Real Feel\",\n            # Confident Abbreviations\n            \"km/h\": \" kilometer per hour\",\n            \"\u00b0C\": \" degrees celsius\",\n            \"%\": \" percent\",\n            \"mm/h\": \" millimeter per hour\",\n            \"Gb/s\": \" gigabits per second\",\n            \"Mb/s\": \" megabits per second\",\n            \"Kb/s\": \" kilobits per second\",\n            \"GHz\": \"Gigahertz\",\n            # Formatting\n            \"\\\"\": \"\"\n        }\n\n        # Replace using the dictionary\n        for old, new in replacements.items():\n            answer = answer.replace(old, new)\n\n        # Remove extra spaces and new lines, condense all multiple spaces\n        #   to a single space\n        answer = re.sub(r'\\s+', ' ', answer).strip()\n\n        return answer\n\n    def _invoke_service_and_set_state(\n        self,\n        chain: SupportsInvoke,\n        rag_documents: list[Document],\n        action_step: ActionStep,\n    ) -&gt; MockSpeaker:\n        \"\"\"Invoke the service and set the state.\n\n        Args:\n            chain: Runnable chain that yields HomeAssistantCall.\n            rag_documents: Context documents for the chain.\n            action_step: Action step describing the request.\n\n        Returns:\n            MockSpeaker with a status message.\n        \"\"\"\n        MockSpeaker = get_mock_speaker()\n\n        try:\n            action_step_curr = str(action_step.action_argument).strip()\n            call_service_values = chain.invoke(\n                {\n                    \"action_step\": action_step_curr,\n                    \"context\": rag_documents,\n                    \"cache\": self.cache\n                },\n            )\n            logging.debug(\n                \"Call Service Values for `{}`: `{}`\",\n                action_step_curr, call_service_values\n            )\n            status_bool, response_json = self.call_service(\n                domain=call_service_values.domain,\n                service=call_service_values.service,\n                entity_id=call_service_values.entity_id,\n            )\n            if status_bool:\n                tmp_return_message = f\"Successfully called service: `{response_json}`\"\n            else:\n                tmp_return_message = f\"Failed to call service: `{response_json}`\"\n        except Exception as err_mesaage:\n            logging.error(\"Error: {}\", err_mesaage)\n            tmp_return_message = f\"I received an error - `{err_mesaage}`\"\n        return MockSpeaker(content=tmp_return_message)\n\n    def set_state(self, action_step: ActionStep | None = None) -&gt; MockSpeaker:\n        \"\"\"Predict and call a service for a given action step.\n\n        Args:\n            action_step: Action step describing the desired change.\n\n        Returns:\n            MockSpeaker with a status message.\n\n        Raises:\n            ValueError: If action_step is None.\n        \"\"\"\n        if action_step is None:\n            raise ValueError(\"Action step cannot be None.\")\n        self.update_cache()\n        rag_documents = self._load_rag_documents([\n            \"entities.json\", \"services.json\"\n        ])\n        system_prompt = ha_render_system_prompt(\n            name=\"homeassistant-set-state\", all_entities=self.cache[\"entity_ids\"])\n\n        parser = PydanticOutputParser(pydantic_object=HomeAssistantCall)  # type: ignore[type-var]\n        prompt = self._create_set_prompt(system_prompt, parser)\n        if self.model is None:\n            raise RuntimeError(\"LLM client not initialized for Home Assistant.\")\n        model = self.model\n        chain: Any = prompt | model | parser\n\n        logging.info(\"Invoking `set` action chain using `{}` for `{}`.\",\n                     self.model_name, action_step)\n        # TODO: Interpret the response from call service.\n        return self._invoke_service_and_set_state(\n            chain, rag_documents, action_step)\n\n    def get_state(self, action_step: ActionStep | None = None) -&gt; MockSpeaker:\n        \"\"\"Generate response for a given action step based on sensors.\n\n        Args:\n            action_step: Action step describing the desired query.\n\n        Returns:\n            MockSpeaker with the generated response.\n\n        Raises:\n            ValueError: If action_step is None.\n        \"\"\"\n        if action_step is None:\n            raise ValueError(\"Action step cannot be None.\")\n        self.update_cache()\n        rag_documents = self._load_rag_documents([\"sensors.json\"])\n\n        system_prompt = ha_render_system_prompt(name=\"homeassistant-get-state\")\n\n        prompt = self._create_get_prompt(system_prompt)\n        if self.model is None:\n            raise RuntimeError(\"LLM client not initialized for Home Assistant.\")\n        model = self.model\n        chain: Any = prompt | model\n\n        logging.info(\"Invoking `get` action chain using `{}`.\",\n                     self.model_name)\n        message = chain.invoke(\n            {\n                \"action_step\": str(action_step.action_argument).strip(),\n                \"context\": rag_documents,\n            },\n        )\n        cleaned_message = self._clean_answer(str(message.content))\n        MockSpeaker = get_mock_speaker()\n        return MockSpeaker(content=cleaned_message)\n</code></pre>"},{"location":"reference/#tools.integration.homeassistant.HomeAssistant.__init__","title":"<code>__init__() -&gt; None</code>","text":"<p>Initialize the Home Assistant tool with environment defaults.</p> Source code in <code>tools/integration/homeassistant.py</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"Initialize the Home Assistant tool with environment defaults.\"\"\"\n    super().__init__(\n        name=\"Home Assistant\",\n        description=\"A service to manage and interact with Home Assistant\"\n    )\n    self.base_url = os.getenv(\"HA_URL\", None)\n    self._api_token = os.getenv(\"HA_TOKEN\", None)\n    self.cache: HomeAssistantCache = {\n        \"entity_ids\": [],\n        \"sensor_ids\": [],\n        \"entities\": [],\n        \"services\": [],\n        \"sensors\": [],\n        \"allowed_domains\": [\n            \"scene\", \"switch\", \"weather\", \"kodi\", \"automation\"]\n    }\n\n    if not self.base_url or not self._api_token:\n        raise ValueError(\n            \"HA_URL and HA_TOKEN must be set in the environment.\")\n\n    self.api_headers: dict[str, str] = {\n        \"Authorization\": f\"Bearer {self._api_token}\",\n        \"Content-Type\": \"application/json\"\n    }\n</code></pre>"},{"location":"reference/#tools.integration.homeassistant.HomeAssistant.call_service","title":"<code>call_service(domain: str, service: str, entity_id: str, data: dict | None = None) -&gt; tuple[bool, list[dict[str, Any]]]</code>","text":"<p>Call a service in Home Assistant.</p> <p>Parameters:</p> Name Type Description Default <code>domain</code> <code>str</code> <p>Home Assistant domain name (e.g., \"light\").</p> required <code>service</code> <code>str</code> <p>Service name within the domain (e.g., \"turn_on\").</p> required <code>entity_id</code> <code>str</code> <p>Entity ID to target.</p> required <code>data</code> <code>dict | None</code> <p>Optional extra payload for the service call.</p> <code>None</code> <p>Returns:</p> Type Description <code>tuple[bool, list[dict[str, Any]]]</code> <p>Tuple of success flag and JSON response payload.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the domain is not allowed.</p> Source code in <code>tools/integration/homeassistant.py</code> <pre><code>def call_service(\n    self,\n    domain: str,\n    service: str,\n    entity_id: str,\n    data: dict | None = None,\n) -&gt; tuple[bool, list[dict[str, Any]]]:\n    \"\"\"Call a service in Home Assistant.\n\n    Args:\n        domain: Home Assistant domain name (e.g., \"light\").\n        service: Service name within the domain (e.g., \"turn_on\").\n        entity_id: Entity ID to target.\n        data: Optional extra payload for the service call.\n\n    Returns:\n        Tuple of success flag and JSON response payload.\n\n    Raises:\n        ValueError: If the domain is not allowed.\n    \"\"\"\n    if domain not in self.cache[\"allowed_domains\"]:\n        raise ValueError(f\"Domain does not exist or blacklisted: {domain}\")\n\n    url = f\"{self.base_url}/services/{domain}/{service}\"\n    payload = {\"entity_id\": entity_id}\n    if data:\n        payload.update(data)\n\n    try:\n        response = requests.post(\n            url, headers=self.api_headers, json=payload, timeout=30)\n        status_code = getattr(response, \"status_code\", None)\n        if status_code in {401, 403}:\n            logging.error(\n                \"Home Assistant authorization failed with status {}.\", status_code\n            )\n            raise PermissionError(\"Home Assistant authorization failed.\")\n        response.raise_for_status()\n        logging.info(\"Service &lt;{}.{}&gt; called on entity &lt;{}&gt; returned `{}`.\",\n                     domain, service, entity_id, response.text)\n        return True, response.json()\n    except requests.exceptions.RequestException as e:\n        logging.error(\n            \"Unable to call service &lt;{}.{}&gt; on entity &lt;{}&gt;: {}\", domain, service, entity_id, e)\n        return False, []\n</code></pre>"},{"location":"reference/#tools.integration.homeassistant.HomeAssistant.get_state","title":"<code>get_state(action_step: ActionStep | None = None) -&gt; MockSpeaker</code>","text":"<p>Generate response for a given action step based on sensors.</p> <p>Parameters:</p> Name Type Description Default <code>action_step</code> <code>ActionStep | None</code> <p>Action step describing the desired query.</p> <code>None</code> <p>Returns:</p> Type Description <code>MockSpeaker</code> <p>MockSpeaker with the generated response.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If action_step is None.</p> Source code in <code>tools/integration/homeassistant.py</code> <pre><code>def get_state(self, action_step: ActionStep | None = None) -&gt; MockSpeaker:\n    \"\"\"Generate response for a given action step based on sensors.\n\n    Args:\n        action_step: Action step describing the desired query.\n\n    Returns:\n        MockSpeaker with the generated response.\n\n    Raises:\n        ValueError: If action_step is None.\n    \"\"\"\n    if action_step is None:\n        raise ValueError(\"Action step cannot be None.\")\n    self.update_cache()\n    rag_documents = self._load_rag_documents([\"sensors.json\"])\n\n    system_prompt = ha_render_system_prompt(name=\"homeassistant-get-state\")\n\n    prompt = self._create_get_prompt(system_prompt)\n    if self.model is None:\n        raise RuntimeError(\"LLM client not initialized for Home Assistant.\")\n    model = self.model\n    chain: Any = prompt | model\n\n    logging.info(\"Invoking `get` action chain using `{}`.\",\n                 self.model_name)\n    message = chain.invoke(\n        {\n            \"action_step\": str(action_step.action_argument).strip(),\n            \"context\": rag_documents,\n        },\n    )\n    cleaned_message = self._clean_answer(str(message.content))\n    MockSpeaker = get_mock_speaker()\n    return MockSpeaker(content=cleaned_message)\n</code></pre>"},{"location":"reference/#tools.integration.homeassistant.HomeAssistant.set_state","title":"<code>set_state(action_step: ActionStep | None = None) -&gt; MockSpeaker</code>","text":"<p>Predict and call a service for a given action step.</p> <p>Parameters:</p> Name Type Description Default <code>action_step</code> <code>ActionStep | None</code> <p>Action step describing the desired change.</p> <code>None</code> <p>Returns:</p> Type Description <code>MockSpeaker</code> <p>MockSpeaker with a status message.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If action_step is None.</p> Source code in <code>tools/integration/homeassistant.py</code> <pre><code>def set_state(self, action_step: ActionStep | None = None) -&gt; MockSpeaker:\n    \"\"\"Predict and call a service for a given action step.\n\n    Args:\n        action_step: Action step describing the desired change.\n\n    Returns:\n        MockSpeaker with a status message.\n\n    Raises:\n        ValueError: If action_step is None.\n    \"\"\"\n    if action_step is None:\n        raise ValueError(\"Action step cannot be None.\")\n    self.update_cache()\n    rag_documents = self._load_rag_documents([\n        \"entities.json\", \"services.json\"\n    ])\n    system_prompt = ha_render_system_prompt(\n        name=\"homeassistant-set-state\", all_entities=self.cache[\"entity_ids\"])\n\n    parser = PydanticOutputParser(pydantic_object=HomeAssistantCall)  # type: ignore[type-var]\n    prompt = self._create_set_prompt(system_prompt, parser)\n    if self.model is None:\n        raise RuntimeError(\"LLM client not initialized for Home Assistant.\")\n    model = self.model\n    chain: Any = prompt | model | parser\n\n    logging.info(\"Invoking `set` action chain using `{}` for `{}`.\",\n                 self.model_name, action_step)\n    # TODO: Interpret the response from call service.\n    return self._invoke_service_and_set_state(\n        chain, rag_documents, action_step)\n</code></pre>"},{"location":"reference/#tools.integration.homeassistant.HomeAssistant.update_cache","title":"<code>update_cache() -&gt; None</code>","text":"<p>Update the entire cache.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If entity IDs cannot be derived.</p> Source code in <code>tools/integration/homeassistant.py</code> <pre><code>@cache_monitor\ndef update_cache(self) -&gt; None:\n    \"\"\"Update the entire cache.\n\n    Raises:\n        ValueError: If entity IDs cannot be derived.\n    \"\"\"\n    self.update_entity_ids()\n    self.update_services()\n    self._save_json(self.cache[\"entities\"], \"entities.json\")\n    self._save_json(self.cache[\"sensors\"], \"sensors.json\")\n</code></pre>"},{"location":"reference/#tools.integration.homeassistant.HomeAssistant.update_entities","title":"<code>update_entities() -&gt; bool</code>","text":"<p>Update the list of entities from Home Assistant.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True when entities are fetched successfully.</p> Source code in <code>tools/integration/homeassistant.py</code> <pre><code>@cache_monitor\ndef update_entities(self) -&gt; bool:\n    \"\"\"Update the list of entities from Home Assistant.\n\n    Returns:\n        True when entities are fetched successfully.\n    \"\"\"\n    url = f\"{self.base_url}/states\"\n    try:\n        response = requests.get(url, headers=self.api_headers, timeout=30)\n        status_code = getattr(response, \"status_code\", None)\n        if status_code in {401, 403}:\n            logging.error(\n                \"Home Assistant authorization failed with status {}.\", status_code\n            )\n            raise PermissionError(\"Home Assistant authorization failed.\")\n        response.raise_for_status()\n        self.cache[\"entities\"] = response.json()\n        return True\n    except requests.exceptions.RequestException as e:\n        logging.error(\"Error: {}\", e)\n        return False\n</code></pre>"},{"location":"reference/#tools.integration.homeassistant.HomeAssistant.update_entity_ids","title":"<code>update_entity_ids() -&gt; bool</code>","text":"<p>Update the list of entity IDs from Home Assistant.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True when entity IDs are populated.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If no entities are available for ID extraction.</p> Source code in <code>tools/integration/homeassistant.py</code> <pre><code>@cache_monitor\ndef update_entity_ids(self) -&gt; bool:\n    \"\"\"Update the list of entity IDs from Home Assistant.\n\n    Returns:\n        True when entity IDs are populated.\n\n    Raises:\n        ValueError: If no entities are available for ID extraction.\n    \"\"\"\n    # TODO: Always assumes blacklist by default due to cache_monitor.\n    self.update_entities()\n    entities = self.cache[\"entities\"]\n    if not entities:\n        raise ValueError(\"No entities found while updating entity IDs.\")\n    self.cache[\"entity_ids\"] = [entity[\"entity_id\"] for entity in entities]\n    logging.info(\"Entity IDs updated.\")\n    return True\n</code></pre>"},{"location":"reference/#tools.integration.homeassistant.HomeAssistant.update_services","title":"<code>update_services() -&gt; bool</code>","text":"<p>Update the list of services from Home Assistant.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True when services are fetched successfully.</p> Source code in <code>tools/integration/homeassistant.py</code> <pre><code>@cache_monitor\ndef update_services(self) -&gt; bool:\n    \"\"\"Update the list of services from Home Assistant.\n\n    Returns:\n        True when services are fetched successfully.\n    \"\"\"\n    url = f\"{self.base_url}/services\"\n    try:\n        response = requests.get(url, headers=self.api_headers, timeout=30)\n        status_code = getattr(response, \"status_code\", None)\n        if status_code in {401, 403}:\n            logging.error(\n                \"Home Assistant authorization failed with status {}.\", status_code\n            )\n            raise PermissionError(\"Home Assistant authorization failed.\")\n        response.raise_for_status()\n        self.cache[\"services\"] = response.json()\n        self._save_json(self.cache[\"services\"], \"services.json\")\n        return True\n    except requests.exceptions.RequestException as e:\n        logging.error(\"Error: {}\", e)\n        return False\n</code></pre>"},{"location":"reference/#tools.integration.homeassistant.HomeAssistantCache","title":"<code>HomeAssistantCache</code>","text":"<p>               Bases: <code>TypedDict</code></p> <p>Cached Home Assistant entity and service metadata.</p> Source code in <code>tools/integration/homeassistant.py</code> <pre><code>class HomeAssistantCache(TypedDict):\n    \"\"\"Cached Home Assistant entity and service metadata.\"\"\"\n    entity_ids: list[str]\n    sensor_ids: list[str]\n    entities: list[dict[str, Any]]\n    services: list[dict[str, Any]]\n    sensors: list[dict[str, Any]]\n    allowed_domains: list[str]\n    sensor: NotRequired[list[dict[str, Any]]]\n</code></pre>"},{"location":"reference/#tools.integration.homeassistant.HomeAssistantCall","title":"<code>HomeAssistantCall</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Structured Home Assistant service call extracted from the model output.</p> Source code in <code>tools/integration/homeassistant.py</code> <pre><code>class HomeAssistantCall(BaseModel):\n    \"\"\"Structured Home Assistant service call extracted from the model output.\"\"\"\n    cache: CacheHolder | None = Field(alias=\"_ha_cache\", default=None)\n    domain: str = Field(\n        description=(\n            \"The category of the service to call, such as 'light', 'switch', or 'scene'.\"\n        )\n    )\n    service: str = Field(\n        description=(\n            \"The specific action to perform within the domain, such as 'turn_on', \"\n            \"'turn_off', or 'set_temperature'.\"\n        )\n    )\n    entity_id: str = Field(\n        description=(\n            \"The ID of the specific device or entity within the domain to apply the \"\n            \"service to, such as 'scene.heater'.\"\n        )\n    )\n\n    @validator(\"entity_id\", allow_reuse=True)\n    # pylint: disable=E0213,W0613\n    def validate_entity_id(\n        cls, entity_id: str, values: dict[str, Any], **kwargs: Any\n    ) -&gt; str:\n        \"\"\"Validate the entity_id against the cache when available.\n\n        Args:\n            cls: Pydantic model class.\n            entity_id: Candidate entity identifier.\n            values: Parsed model values.\n            **kwargs: Additional validator arguments.\n\n        Returns:\n            Validated entity identifier.\n\n        Raises:\n            ValueError: If the entity ID is not found in the cache.\n        \"\"\"\n        # ! BUG: The entity_id may not be validated correctly as the cache\n        # !     is not passed to the validator.\n        ha_cache = values.get(\"ha_cache\")\n        if ha_cache and entity_id not in ha_cache.cache[\"entity_ids\"]:\n            raise ValueError(\n                f\"Entity ID '{entity_id}' is not in the Home Assistant cache.\")\n        return entity_id\n\n    @validator(\"domain\", allow_reuse=True)\n    # pylint: disable=E0213,W0613\n    def validate_domain(\n        cls, domain: str, values: dict[str, Any], **kwargs: Any\n    ) -&gt; str:\n        \"\"\"Validate the domain against the cache when available.\n\n        Args:\n            cls: Pydantic model class.\n            domain: Domain string to validate.\n            values: Parsed model values.\n            **kwargs: Additional validator arguments.\n\n        Returns:\n            Validated domain string.\n\n        Raises:\n            ValueError: If the domain is not found in the cache.\n        \"\"\"\n        # ! BUG: The entity_id may not be validated correctly as the cache\n        # !     is not passed to the validator.\n        ha_cache = values.get(\"ha_cache\")\n        if ha_cache and domain not in ha_cache.cache[\"allowed_domains\"]:\n            raise ValueError(\n                f\"Domain '{domain}' is not in the Home Assistant cache.\")\n        return domain\n\n    class Config:\n        \"\"\"Pydantic configuration for HomeAssistantCall.\"\"\"\n        arbitrary_types_allowed = True\n</code></pre>"},{"location":"reference/#tools.integration.homeassistant.HomeAssistantCall.Config","title":"<code>Config</code>","text":"<p>Pydantic configuration for HomeAssistantCall.</p> Source code in <code>tools/integration/homeassistant.py</code> <pre><code>class Config:\n    \"\"\"Pydantic configuration for HomeAssistantCall.\"\"\"\n    arbitrary_types_allowed = True\n</code></pre>"},{"location":"reference/#tools.integration.homeassistant.HomeAssistantCall.validate_domain","title":"<code>validate_domain(domain: str, values: dict[str, Any], **kwargs: Any) -&gt; str</code>","text":"<p>Validate the domain against the cache when available.</p> <p>Parameters:</p> Name Type Description Default <code>cls</code> <p>Pydantic model class.</p> required <code>domain</code> <code>str</code> <p>Domain string to validate.</p> required <code>values</code> <code>dict[str, Any]</code> <p>Parsed model values.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional validator arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>str</code> <p>Validated domain string.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the domain is not found in the cache.</p> Source code in <code>tools/integration/homeassistant.py</code> <pre><code>@validator(\"domain\", allow_reuse=True)\n# pylint: disable=E0213,W0613\ndef validate_domain(\n    cls, domain: str, values: dict[str, Any], **kwargs: Any\n) -&gt; str:\n    \"\"\"Validate the domain against the cache when available.\n\n    Args:\n        cls: Pydantic model class.\n        domain: Domain string to validate.\n        values: Parsed model values.\n        **kwargs: Additional validator arguments.\n\n    Returns:\n        Validated domain string.\n\n    Raises:\n        ValueError: If the domain is not found in the cache.\n    \"\"\"\n    # ! BUG: The entity_id may not be validated correctly as the cache\n    # !     is not passed to the validator.\n    ha_cache = values.get(\"ha_cache\")\n    if ha_cache and domain not in ha_cache.cache[\"allowed_domains\"]:\n        raise ValueError(\n            f\"Domain '{domain}' is not in the Home Assistant cache.\")\n    return domain\n</code></pre>"},{"location":"reference/#tools.integration.homeassistant.HomeAssistantCall.validate_entity_id","title":"<code>validate_entity_id(entity_id: str, values: dict[str, Any], **kwargs: Any) -&gt; str</code>","text":"<p>Validate the entity_id against the cache when available.</p> <p>Parameters:</p> Name Type Description Default <code>cls</code> <p>Pydantic model class.</p> required <code>entity_id</code> <code>str</code> <p>Candidate entity identifier.</p> required <code>values</code> <code>dict[str, Any]</code> <p>Parsed model values.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional validator arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>str</code> <p>Validated entity identifier.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the entity ID is not found in the cache.</p> Source code in <code>tools/integration/homeassistant.py</code> <pre><code>@validator(\"entity_id\", allow_reuse=True)\n# pylint: disable=E0213,W0613\ndef validate_entity_id(\n    cls, entity_id: str, values: dict[str, Any], **kwargs: Any\n) -&gt; str:\n    \"\"\"Validate the entity_id against the cache when available.\n\n    Args:\n        cls: Pydantic model class.\n        entity_id: Candidate entity identifier.\n        values: Parsed model values.\n        **kwargs: Additional validator arguments.\n\n    Returns:\n        Validated entity identifier.\n\n    Raises:\n        ValueError: If the entity ID is not found in the cache.\n    \"\"\"\n    # ! BUG: The entity_id may not be validated correctly as the cache\n    # !     is not passed to the validator.\n    ha_cache = values.get(\"ha_cache\")\n    if ha_cache and entity_id not in ha_cache.cache[\"entity_ids\"]:\n        raise ValueError(\n            f\"Entity ID '{entity_id}' is not in the Home Assistant cache.\")\n    return entity_id\n</code></pre>"},{"location":"reference/#tools.integration.homeassistant.SupportsInvoke","title":"<code>SupportsInvoke</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for runnable chains that return HomeAssistantCall.</p> Source code in <code>tools/integration/homeassistant.py</code> <pre><code>class SupportsInvoke(Protocol):\n    \"\"\"Protocol for runnable chains that return HomeAssistantCall.\"\"\"\n    def invoke(self, input_data: dict[str, Any]) -&gt; HomeAssistantCall:\n        \"\"\"Invoke the chain with structured input.\n\n        Args:\n            input_data: Input payload for the chain.\n\n        Returns:\n            Parsed HomeAssistantCall.\n        \"\"\"\n        ...\n</code></pre>"},{"location":"reference/#tools.integration.homeassistant.SupportsInvoke.invoke","title":"<code>invoke(input_data: dict[str, Any]) -&gt; HomeAssistantCall</code>","text":"<p>Invoke the chain with structured input.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>dict[str, Any]</code> <p>Input payload for the chain.</p> required <p>Returns:</p> Type Description <code>HomeAssistantCall</code> <p>Parsed HomeAssistantCall.</p> Source code in <code>tools/integration/homeassistant.py</code> <pre><code>def invoke(self, input_data: dict[str, Any]) -&gt; HomeAssistantCall:\n    \"\"\"Invoke the chain with structured input.\n\n    Args:\n        input_data: Input payload for the chain.\n\n    Returns:\n        Parsed HomeAssistantCall.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/#tools.integration.homeassistant.cache_monitor","title":"<code>cache_monitor(func: Callable[Concatenate[SelfT, P], R]) -&gt; Callable[Concatenate[SelfT, P], R]</code>","text":"<p>Decorator to monitor and update the cache.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>Callable[Concatenate[SelfT, P], R]</code> <p>Method that updates a portion of the cache.</p> required <p>Returns:</p> Type Description <code>Callable[Concatenate[SelfT, P], R]</code> <p>Wrapped function that normalizes cache contents after execution.</p> Source code in <code>tools/integration/homeassistant.py</code> <pre><code>def cache_monitor(\n    func: Callable[Concatenate[SelfT, P], R]\n) -&gt; Callable[Concatenate[SelfT, P], R]:\n    \"\"\"Decorator to monitor and update the cache.\n\n    Args:\n        func: Method that updates a portion of the cache.\n\n    Returns:\n        Wrapped function that normalizes cache contents after execution.\n    \"\"\"\n    def sort_by_entity_id(dict_list: list[dict[str, Any]]) -&gt; list[dict[str, Any]]:\n        \"\"\"Sort a list of entities by the entity_id field.\n\n        Args:\n            dict_list: List of entity dictionaries.\n\n        Returns:\n            Sorted list of entities.\n        \"\"\"\n        return sorted(dict_list, key=lambda x: x[\"entity_id\"])\n\n    def clean_entities(\n        self: CacheHolder,\n        forbidden_prefixes: list[str],\n        forbidden_substrings: list[str],\n    ) -&gt; HomeAssistantCache:\n        \"\"\"Filter and normalize entities while populating sensors.\n\n        Args:\n            self: Cache holder to mutate.\n            forbidden_prefixes: Entity ID prefixes to exclude.\n            forbidden_substrings: Entity ID substrings to exclude.\n\n        Returns:\n            Updated HomeAssistantCache payload.\n        \"\"\"\n        for idx, entity in enumerate(self.cache[\"entities\"]):\n            if \"context\" in entity:\n                self.cache[\"entities\"][idx].pop(\"context\")\n                self.cache[\"entities\"][idx].pop(\"last_changed\")\n                self.cache[\"entities\"][idx].pop(\"last_reported\")\n                self.cache[\"entities\"][idx].pop(\"last_updated\")\n\n            if \"attributes\" in entity:\n                self.cache[\"entities\"][idx][\"attributes\"].pop(\"icon\", None)\n                self.cache[\"entities\"][idx][\"attributes\"].pop(\n                    \"monitor_cert_days_remaining\", None)\n                self.cache[\"entities\"][idx][\"attributes\"].pop(\n                    \"monitor_cert_is_valid\", None)\n                self.cache[\"entities\"][idx][\"attributes\"].pop(\n                    \"monitor_hostname\", None)\n                self.cache[\"entities\"][idx][\"attributes\"].pop(\n                    \"monitor_port\", None)\n\n            if any(entity[\"entity_id\"].startswith(prefix) for prefix in forbidden_prefixes):\n                self.cache[\"entities\"].remove(entity)\n\n            if any(substring in entity[\"entity_id\"] for substring in forbidden_substrings):\n                self.cache[\"entities\"].remove(entity)\n\n            if entity[\"entity_id\"].startswith(\"scene.\"):\n                self.cache[\"entities\"][idx].pop(\"state\", None)\n\n            if entity[\"entity_id\"].startswith(\"sensor.\") or entity[\"entity_id\"].startswith(\n                \"binary_sensor.\"\n            ):\n                self.cache[\"sensors\"].append(entity)\n                self.cache[\"entities\"].pop(idx)\n\n        self.cache[\"entities\"] = sort_by_entity_id(self.cache[\"entities\"])\n        self.cache[\"sensors\"] = sort_by_entity_id(self.cache[\"sensors\"])\n        return self.cache\n\n    def wrapper(self: SelfT, *args: P.args, **kwargs: P.kwargs) -&gt; R:\n        \"\"\"Invoke the wrapped function and normalize cache content.\n\n        Args:\n            self: Cache holder instance.\n            *args: Positional arguments forwarded to the wrapped function.\n            **kwargs: Keyword arguments forwarded to the wrapped function.\n\n        Returns:\n            Result of the wrapped function.\n        \"\"\"\n        result = func(self, *args, **kwargs)\n\n        forbidden_prefixes = [\n            \"alarm_control_panel.\",\n            \"automation.\",\n            \"binary_sensor.remote_ui\",\n            \"camera.\",\n            \"climate\",\n            \"conversation\",\n            \"device_tracker.kraken_raspberry_pi_5\",\n            \"media_player.axios\",\n            \"media_player.axios_2\",\n            \"media_player.chrome\",\n            \"media_player.fire_tv_192_168_1_12\",\n            \"person.\",\n            \"remote.\",\n            \"script.higher\",\n            \"sensor.hacs\",\n            \"sensor.hacs\",\n            \"sensor.kraken_raspberry_pi_5_\",\n            \"sensor.sonarr_commands\",\n            \"sensor.sun\",\n            \"sensor.uptimekuma_\",\n            \"stt.\",\n            \"sun.\",\n            \"switch.\",\n            \"switch.adam\",\n            \"switch.bedroom_camera_camera_motion_detection\",\n            \"tts.\",\n            \"update.\",\n            \"zone.home\",\n        ]\n        forbidden_substrings = [\"blink_kk_bedroom\"]\n        self.cache[\"sensor\"] = []\n        # Clean entities\n        self.cache = clean_entities(\n            self, forbidden_prefixes, forbidden_substrings)\n\n        # Clean services\n        self.cache[\"services\"] = [\n            service\n            for service in self.cache[\"services\"]\n            if service[\"domain\"] in self.cache[\"allowed_domains\"]\n        ]\n\n        # Retrieve entity and sensor IDs\n        self.cache[\"entity_ids\"] = sorted(self.cache[\"entity_ids\"])\n        self.cache[\"sensor_ids\"] = sorted(self.cache[\"sensor_ids\"])\n\n        logging.info(\n            (\n                \"`{}` modified cache to &lt;(len) Entity IDs: {}; (len) Entities: {}; \"\n                \"(len) Sensors: {}; (len) Services: {};&gt;\"\n            ),\n            func.__name__,\n            len(self.cache[\"entity_ids\"]),\n            len(self.cache[\"entities\"]),\n            len(self.cache[\"sensors\"]),\n            len(self.cache[\"services\"]),\n        )\n\n        return result\n    return wrapper\n</code></pre>"},{"location":"reference/#tools.integration.homeassistant.test_homeassistant","title":"<code>test_homeassistant() -&gt; HomeAssistant</code>","text":"<p>Test the HomeAssistant class.</p> <p>Returns:</p> Type Description <code>HomeAssistant</code> <p>Initialized HomeAssistant instance after a test call.</p> Source code in <code>tools/integration/homeassistant.py</code> <pre><code>def test_homeassistant() -&gt; HomeAssistant:\n    \"\"\"Test the HomeAssistant class.\n\n    Returns:\n        Initialized HomeAssistant instance after a test call.\n    \"\"\"\n    ha = HomeAssistant()\n    ha.update_cache()\n    ha.call_service(\"scene\", \"turn_on\", \"scene.strip_lights_white\")\n    return ha\n</code></pre>"},{"location":"reference/#tools.integration.mcp","title":"<code>tools.integration.mcp</code>","text":"<p>MCP tool runner for integrating MCP servers into Meeseeks.</p>"},{"location":"reference/#tools.integration.mcp.MCPToolRunner","title":"<code>MCPToolRunner</code>","text":"<p>Wrapper to invoke MCP tools via langchain-mcp-adapters.</p> Source code in <code>tools/integration/mcp.py</code> <pre><code>class MCPToolRunner:\n    \"\"\"Wrapper to invoke MCP tools via langchain-mcp-adapters.\"\"\"\n\n    def __init__(self, server_name: str, tool_name: str) -&gt; None:\n        \"\"\"Initialize the MCP tool runner for a specific server tool.\n\n        Args:\n            server_name: MCP server name from configuration.\n            tool_name: Tool name to invoke on the server.\n        \"\"\"\n        self.server_name = server_name\n        self.tool_name = tool_name\n\n    async def _invoke_async(self, input_payload: str | dict[str, Any]) -&gt; str:\n        \"\"\"Invoke an MCP tool asynchronously and return its output.\n\n        Args:\n            input_payload: Input payload to send to the MCP tool.\n\n        Returns:\n            Stringified tool response.\n\n        Raises:\n            RuntimeError: If MCP adapters are not installed.\n            ValueError: If the server or tool is not configured.\n        \"\"\"\n        try:\n            from langchain_mcp_adapters.client import MultiServerMCPClient\n        except Exception as exc:  # pragma: no cover - runtime dependency\n            raise RuntimeError(\n                \"langchain-mcp-adapters is required for MCP tools.\"\n            ) from exc\n\n        config = _load_mcp_config()\n        servers = config.get(\"servers\", {})\n        if not servers or self.server_name not in servers:\n            raise ValueError(\n                f\"MCP server '{self.server_name}' not found in config.\"\n            )\n\n        client = MultiServerMCPClient({self.server_name: servers[self.server_name]})\n        tools = await client.get_tools(server_name=self.server_name)\n        tool_map = {tool.name: tool for tool in tools}\n        tool = tool_map.get(self.tool_name)\n        if tool is None:\n            raise ValueError(\n                f\"Tool '{self.tool_name}' not found on MCP server '{self.server_name}'.\"\n            )\n        result = await tool.ainvoke(\n            _prepare_mcp_input(tool, input_payload)\n        )\n        return str(result)\n\n    def run(self, action_step: ActionStep) -&gt; MockSpeaker:\n        \"\"\"Execute the MCP tool using the action step argument.\n\n        Args:\n            action_step: Action step containing the prompt argument.\n\n        Returns:\n            MockSpeaker with the tool response content.\n\n        Raises:\n            ValueError: If action_step is None.\n        \"\"\"\n        if action_step is None:\n            raise ValueError(\"Action step cannot be None.\")\n        MockSpeakerType = get_mock_speaker()\n        result = asyncio.run(self._invoke_async(action_step.action_argument))\n        return MockSpeakerType(content=result)\n</code></pre>"},{"location":"reference/#tools.integration.mcp.MCPToolRunner.__init__","title":"<code>__init__(server_name: str, tool_name: str) -&gt; None</code>","text":"<p>Initialize the MCP tool runner for a specific server tool.</p> <p>Parameters:</p> Name Type Description Default <code>server_name</code> <code>str</code> <p>MCP server name from configuration.</p> required <code>tool_name</code> <code>str</code> <p>Tool name to invoke on the server.</p> required Source code in <code>tools/integration/mcp.py</code> <pre><code>def __init__(self, server_name: str, tool_name: str) -&gt; None:\n    \"\"\"Initialize the MCP tool runner for a specific server tool.\n\n    Args:\n        server_name: MCP server name from configuration.\n        tool_name: Tool name to invoke on the server.\n    \"\"\"\n    self.server_name = server_name\n    self.tool_name = tool_name\n</code></pre>"},{"location":"reference/#tools.integration.mcp.MCPToolRunner.run","title":"<code>run(action_step: ActionStep) -&gt; MockSpeaker</code>","text":"<p>Execute the MCP tool using the action step argument.</p> <p>Parameters:</p> Name Type Description Default <code>action_step</code> <code>ActionStep</code> <p>Action step containing the prompt argument.</p> required <p>Returns:</p> Type Description <code>MockSpeaker</code> <p>MockSpeaker with the tool response content.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If action_step is None.</p> Source code in <code>tools/integration/mcp.py</code> <pre><code>def run(self, action_step: ActionStep) -&gt; MockSpeaker:\n    \"\"\"Execute the MCP tool using the action step argument.\n\n    Args:\n        action_step: Action step containing the prompt argument.\n\n    Returns:\n        MockSpeaker with the tool response content.\n\n    Raises:\n        ValueError: If action_step is None.\n    \"\"\"\n    if action_step is None:\n        raise ValueError(\"Action step cannot be None.\")\n    MockSpeakerType = get_mock_speaker()\n    result = asyncio.run(self._invoke_async(action_step.action_argument))\n    return MockSpeakerType(content=result)\n</code></pre>"},{"location":"reference/#tools.integration.mcp.discover_mcp_tool_details","title":"<code>discover_mcp_tool_details(config: dict[str, Any]) -&gt; dict[str, list[dict[str, Any]]]</code>","text":"<p>Discover MCP tool names and schemas per server from configuration.</p> Source code in <code>tools/integration/mcp.py</code> <pre><code>def discover_mcp_tool_details(config: dict[str, Any]) -&gt; dict[str, list[dict[str, Any]]]:\n    \"\"\"Discover MCP tool names and schemas per server from configuration.\"\"\"\n    return _run_async(_discover_mcp_tool_details_async(_normalize_mcp_config(config)))\n</code></pre>"},{"location":"reference/#tools.integration.mcp.discover_mcp_tools","title":"<code>discover_mcp_tools(config: dict[str, Any]) -&gt; dict[str, list[str]]</code>","text":"<p>Discover MCP tool names per server from configuration.</p> Source code in <code>tools/integration/mcp.py</code> <pre><code>def discover_mcp_tools(config: dict[str, Any]) -&gt; dict[str, list[str]]:\n    \"\"\"Discover MCP tool names per server from configuration.\"\"\"\n    details = discover_mcp_tool_details(config)\n    return {\n        server_name: [tool[\"name\"] for tool in tools if tool.get(\"name\")]\n        for server_name, tools in details.items()\n    }\n</code></pre>"},{"location":"reference/#tools.integration.mcp.mark_tool_auto_approved","title":"<code>mark_tool_auto_approved(config: dict[str, Any], server_name: str, tool_name: str) -&gt; dict[str, Any]</code>","text":"<p>Record a tool as auto-approved in the MCP config.</p> Source code in <code>tools/integration/mcp.py</code> <pre><code>def mark_tool_auto_approved(\n    config: dict[str, Any],\n    server_name: str,\n    tool_name: str,\n) -&gt; dict[str, Any]:\n    \"\"\"Record a tool as auto-approved in the MCP config.\"\"\"\n    servers = config.setdefault(\"servers\", {})\n    server_config = servers.setdefault(server_name, {})\n    allowlist = server_config.setdefault(\"auto_approve_tools\", [])\n    if tool_name not in allowlist:\n        allowlist.append(tool_name)\n        server_config[\"auto_approve_tools\"] = sorted(set(allowlist))\n    return config\n</code></pre>"},{"location":"reference/#tools.integration.mcp.save_mcp_config","title":"<code>save_mcp_config(config: dict[str, Any], path: str | None = None) -&gt; None</code>","text":"<p>Persist an MCP configuration payload to disk.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict[str, Any]</code> <p>MCP configuration payload to write.</p> required <code>path</code> <code>str | None</code> <p>Optional explicit file path (defaults to MESEEKS_MCP_CONFIG).</p> <code>None</code> Source code in <code>tools/integration/mcp.py</code> <pre><code>def save_mcp_config(config: dict[str, Any], path: str | None = None) -&gt; None:\n    \"\"\"Persist an MCP configuration payload to disk.\n\n    Args:\n        config: MCP configuration payload to write.\n        path: Optional explicit file path (defaults to MESEEKS_MCP_CONFIG).\n    \"\"\"\n    config_path = path or os.getenv(\"MESEEKS_MCP_CONFIG\")\n    if not config_path:\n        raise ValueError(\"MESEEKS_MCP_CONFIG is not set.\")\n    config_path = os.path.abspath(config_path)\n    with open(config_path, \"w\", encoding=\"utf-8\") as handle:\n        json.dump(config, handle, indent=2)\n        handle.write(\"\\n\")\n</code></pre>"},{"location":"reference/#tools.integration.mcp.tool_auto_approved","title":"<code>tool_auto_approved(config: dict[str, Any], server_name: str, tool_name: str) -&gt; bool</code>","text":"<p>Return True when a tool is marked as auto-approved.</p> Source code in <code>tools/integration/mcp.py</code> <pre><code>def tool_auto_approved(\n    config: dict[str, Any],\n    server_name: str,\n    tool_name: str,\n) -&gt; bool:\n    \"\"\"Return True when a tool is marked as auto-approved.\"\"\"\n    server_config = config.get(\"servers\", {}).get(server_name, {})\n    if server_config.get(\"auto_approve_all\"):\n        return True\n    allowlist = server_config.get(\"auto_approve_tools\", [])\n    return tool_name in allowlist\n</code></pre>"},{"location":"reference/#home-assistant-integration","title":"Home Assistant Integration","text":""},{"location":"reference/#meeseeks_ha_conversation.api","title":"<code>meeseeks_ha_conversation.api</code>","text":"<p>Meeseeks API client.</p>"},{"location":"reference/#meeseeks_ha_conversation.api.MeeseeksApiClient","title":"<code>MeeseeksApiClient</code>","text":"<p>Meeseeks API Client.</p> Source code in <code>meeseeks_ha_conversation/api.py</code> <pre><code>class MeeseeksApiClient:\n    \"\"\"Meeseeks API Client.\"\"\"\n\n    def __init__(\n        self,\n        base_url: str,\n        timeout: int,\n        session: aiohttp.ClientSession,\n    ) -&gt; None:\n        \"\"\"Initialize the API client.\n\n        Args:\n            base_url: Base URL for the Meeseeks API.\n            timeout: Request timeout in seconds.\n            session: Shared aiohttp client session.\n        \"\"\"\n        self._base_url = base_url.rstrip(\"/\")\n        self._api_key = 'msk-strong-password'\n        self.timeout = timeout\n        self._session = session\n\n    async def async_get_heartbeat(self) -&gt; bool:\n        \"\"\"Get heartbeat from the API.\n\n        Returns:\n            True when the service is considered healthy.\n        \"\"\"\n        # TODO: Implement a heartbeat check\n        return True\n\n    async def async_get_models(self) -&gt; str:\n        \"\"\"Get models from the API.\n\n        Returns:\n            JSON-serialized model list.\n        \"\"\"\n        # TODO: This is monkey-patched for now\n        response_data: ModelsResponse = {\n            \"models\": [\n                {\n                    \"name\": \"meeseeks\",\n                    \"modified_at\": \"2023-11-01T00:00:00.000000000-04:00\",\n                    \"size\": 0,\n                    \"digest\": None\n                }\n            ]\n        }\n        return json.dumps(response_data)\n\n    async def async_generate(\n        self, data: dict[str, Any] | None = None\n    ) -&gt; MeeseeksQueryResponse:\n        \"\"\"Generate a completion from the API.\n\n        Args:\n            data: Request payload including prompt and optional session ID.\n\n        Returns:\n            Parsed query response payload.\n\n        Raises:\n            ValueError: If prompt data is missing.\n            ApiJsonError: If the API returns unexpected data.\n        \"\"\"\n        if not data or \"prompt\" not in data:\n            raise ValueError(\"Missing prompt in request data.\")\n        url_query = f\"{self._base_url}/api/query\"\n        data_custom = {\n            'query': str(data[\"prompt\"]).strip(),\n        }\n        session_id = data.get(\"session_id\") if isinstance(data, dict) else None\n        if session_id:\n            data_custom[\"session_id\"] = session_id\n        # Pass headers as None to use the default headers\n        result = await self._meeseeks_api_wrapper(\n            method=\"post\",\n            url=url_query,\n            data=data_custom,\n            headers=None,\n        )\n        if isinstance(result, str):\n            raise ApiJsonError(\"Unexpected text response from Meeseeks API.\")\n        return result\n\n    async def _meeseeks_api_wrapper(\n        self,\n        method: str,\n        url: str,\n        data: dict[str, Any] | None = None,\n        headers: dict[str, str] | None = None,\n        decode_json: bool = True,\n    ) -&gt; MeeseeksQueryResponse | str:\n        \"\"\"Perform an HTTP request to the Meeseeks API.\n\n        Args:\n            method: HTTP method to use.\n            url: Fully qualified request URL.\n            data: Optional JSON payload to send.\n            headers: Optional HTTP headers override.\n            decode_json: Whether to parse JSON responses.\n\n        Returns:\n            Parsed response payload or raw text depending on decode_json.\n\n        Raises:\n            ApiJsonError: If the API returns an error payload.\n            aiohttp.ClientResponseError: For non-2xx responses.\n        \"\"\"\n        if headers is None:\n            headers = {\n                'accept': 'application/json',\n                'X-API-KEY': self._api_key,\n                'Content-Type': 'application/json',\n            }\n        async with async_timeout.timeout(self.timeout):\n            response = await self._session.request(\n                method=method,\n                url=url,\n                headers=headers,\n                json=data,\n            )\n            response.raise_for_status()\n\n            if decode_json:\n                raw_data: dict[str, Any] = await response.json()\n                if response.status == 404:\n                    raise ApiJsonError(raw_data.get(\"error\", \"Unknown error\"))\n                task_result = str(raw_data.get(\"task_result\", \"\"))\n                response_data: MeeseeksQueryResponse = {\n                    \"task_result\": task_result,\n                    \"response\": str(raw_data.get(\"response\", task_result)),\n                    \"context\": str(raw_data.get(\"context\", task_result)),\n                    \"session_id\": raw_data.get(\"session_id\"),\n                }\n                LOGGER.debug(\"Response data: %s\", response_data)\n                return response_data\n            else:\n                LOGGER.debug(\"Fallback to text response\")\n                return await response.text()\n</code></pre>"},{"location":"reference/#meeseeks_ha_conversation.api.MeeseeksApiClient.__init__","title":"<code>__init__(base_url: str, timeout: int, session: aiohttp.ClientSession) -&gt; None</code>","text":"<p>Initialize the API client.</p> <p>Parameters:</p> Name Type Description Default <code>base_url</code> <code>str</code> <p>Base URL for the Meeseeks API.</p> required <code>timeout</code> <code>int</code> <p>Request timeout in seconds.</p> required <code>session</code> <code>ClientSession</code> <p>Shared aiohttp client session.</p> required Source code in <code>meeseeks_ha_conversation/api.py</code> <pre><code>def __init__(\n    self,\n    base_url: str,\n    timeout: int,\n    session: aiohttp.ClientSession,\n) -&gt; None:\n    \"\"\"Initialize the API client.\n\n    Args:\n        base_url: Base URL for the Meeseeks API.\n        timeout: Request timeout in seconds.\n        session: Shared aiohttp client session.\n    \"\"\"\n    self._base_url = base_url.rstrip(\"/\")\n    self._api_key = 'msk-strong-password'\n    self.timeout = timeout\n    self._session = session\n</code></pre>"},{"location":"reference/#meeseeks_ha_conversation.api.MeeseeksApiClient.async_generate","title":"<code>async_generate(data: dict[str, Any] | None = None) -&gt; MeeseeksQueryResponse</code>  <code>async</code>","text":"<p>Generate a completion from the API.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict[str, Any] | None</code> <p>Request payload including prompt and optional session ID.</p> <code>None</code> <p>Returns:</p> Type Description <code>MeeseeksQueryResponse</code> <p>Parsed query response payload.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If prompt data is missing.</p> <code>ApiJsonError</code> <p>If the API returns unexpected data.</p> Source code in <code>meeseeks_ha_conversation/api.py</code> <pre><code>async def async_generate(\n    self, data: dict[str, Any] | None = None\n) -&gt; MeeseeksQueryResponse:\n    \"\"\"Generate a completion from the API.\n\n    Args:\n        data: Request payload including prompt and optional session ID.\n\n    Returns:\n        Parsed query response payload.\n\n    Raises:\n        ValueError: If prompt data is missing.\n        ApiJsonError: If the API returns unexpected data.\n    \"\"\"\n    if not data or \"prompt\" not in data:\n        raise ValueError(\"Missing prompt in request data.\")\n    url_query = f\"{self._base_url}/api/query\"\n    data_custom = {\n        'query': str(data[\"prompt\"]).strip(),\n    }\n    session_id = data.get(\"session_id\") if isinstance(data, dict) else None\n    if session_id:\n        data_custom[\"session_id\"] = session_id\n    # Pass headers as None to use the default headers\n    result = await self._meeseeks_api_wrapper(\n        method=\"post\",\n        url=url_query,\n        data=data_custom,\n        headers=None,\n    )\n    if isinstance(result, str):\n        raise ApiJsonError(\"Unexpected text response from Meeseeks API.\")\n    return result\n</code></pre>"},{"location":"reference/#meeseeks_ha_conversation.api.MeeseeksApiClient.async_get_heartbeat","title":"<code>async_get_heartbeat() -&gt; bool</code>  <code>async</code>","text":"<p>Get heartbeat from the API.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True when the service is considered healthy.</p> Source code in <code>meeseeks_ha_conversation/api.py</code> <pre><code>async def async_get_heartbeat(self) -&gt; bool:\n    \"\"\"Get heartbeat from the API.\n\n    Returns:\n        True when the service is considered healthy.\n    \"\"\"\n    # TODO: Implement a heartbeat check\n    return True\n</code></pre>"},{"location":"reference/#meeseeks_ha_conversation.api.MeeseeksApiClient.async_get_models","title":"<code>async_get_models() -&gt; str</code>  <code>async</code>","text":"<p>Get models from the API.</p> <p>Returns:</p> Type Description <code>str</code> <p>JSON-serialized model list.</p> Source code in <code>meeseeks_ha_conversation/api.py</code> <pre><code>async def async_get_models(self) -&gt; str:\n    \"\"\"Get models from the API.\n\n    Returns:\n        JSON-serialized model list.\n    \"\"\"\n    # TODO: This is monkey-patched for now\n    response_data: ModelsResponse = {\n        \"models\": [\n            {\n                \"name\": \"meeseeks\",\n                \"modified_at\": \"2023-11-01T00:00:00.000000000-04:00\",\n                \"size\": 0,\n                \"digest\": None\n            }\n        ]\n    }\n    return json.dumps(response_data)\n</code></pre>"},{"location":"reference/#meeseeks_ha_conversation.api.MeeseeksQueryResponse","title":"<code>MeeseeksQueryResponse</code>","text":"<p>               Bases: <code>TypedDict</code></p> <p>Schema for the main query response.</p> Source code in <code>meeseeks_ha_conversation/api.py</code> <pre><code>class MeeseeksQueryResponse(TypedDict):\n    \"\"\"Schema for the main query response.\"\"\"\n    task_result: str\n    response: str\n    context: str\n    session_id: str | None\n</code></pre>"},{"location":"reference/#meeseeks_ha_conversation.api.ModelsResponse","title":"<code>ModelsResponse</code>","text":"<p>               Bases: <code>TypedDict</code></p> <p>Schema for the models list endpoint response.</p> Source code in <code>meeseeks_ha_conversation/api.py</code> <pre><code>class ModelsResponse(TypedDict):\n    \"\"\"Schema for the models list endpoint response.\"\"\"\n    models: list[dict[str, Any]]\n</code></pre>"},{"location":"reference/#meeseeks_ha_conversation.config_flow","title":"<code>meeseeks_ha_conversation.config_flow</code>","text":"<p>Adds config flow for Meeseeks.</p>"},{"location":"reference/#meeseeks_ha_conversation.config_flow.MeeseeksConfigFlow","title":"<code>MeeseeksConfigFlow</code>","text":"<p>               Bases: <code>ConfigFlow</code></p> <p>Handle a config flow for Meeseeks Conversation. Handles UI wizard.</p> Source code in <code>meeseeks_ha_conversation/config_flow.py</code> <pre><code>class MeeseeksConfigFlow(config_entries.ConfigFlow, domain=DOMAIN):  # type: ignore[call-arg]\n    \"\"\"Handle a config flow for Meeseeks Conversation. Handles UI wizard.\"\"\"\n\n    VERSION = 1\n    client: MeeseeksApiClient\n\n    async def async_step_user(\n        self, user_input: dict[str, Any] | None = None\n    ) -&gt; FlowResult:\n        \"\"\"Handle the initial config flow step.\n\n        Args:\n            user_input: Submitted form data, if available.\n\n        Returns:\n            FlowResult for the configuration step.\n        \"\"\"\n        if user_input is None:\n            return self.async_show_form(\n                step_id=\"user\", data_schema=STEP_USER_DATA_SCHEMA\n            )\n\n        # Search for duplicates with the same CONF_BASE_URL value.\n        for existing_entry in self._async_current_entries(include_ignore=False):\n            if existing_entry.data.get(CONF_BASE_URL) == user_input[CONF_BASE_URL]:\n                return self.async_abort(reason=\"already_configured\")\n\n        errors: dict[str, str] = {}\n        try:\n            self.client = MeeseeksApiClient(\n                base_url=cv.url_no_path(user_input[CONF_BASE_URL]),\n                timeout=user_input[CONF_TIMEOUT],\n                session=async_create_clientsession(self.hass),\n            )\n            response = await self.client.async_get_heartbeat()\n            if not response:\n                raise vol.Invalid(\"Invalid Meeseeks server\")\n        # except vol.Invalid:\n        #     errors[\"base\"] = \"invalid_url\"\n        # except ApiTimeoutError:\n        #     errors[\"base\"] = \"timeout_connect\"\n        # except ApiCommError:\n        #     errors[\"base\"] = \"cannot_connect\"\n        # except ApiClientError as exception:\n        #     LOGGER.exception(\"Unexpected exception: %s\", exception)\n        #     errors[\"base\"] = \"unknown\"\n        except Exception as exception:\n            LOGGER.exception(\"Unexpected exception: %s\", exception)\n            errors[\"base\"] = \"unknown\"\n        else:\n            return self.async_create_entry(\n                title=f\"Meeseeks - {user_input[CONF_BASE_URL]}\",\n                data={\n                    CONF_BASE_URL: user_input[CONF_BASE_URL]\n                },\n                options={\n                    CONF_TIMEOUT: user_input[CONF_TIMEOUT]\n                }\n            )\n\n        return self.async_show_form(\n            step_id=\"user\", data_schema=STEP_USER_DATA_SCHEMA, errors=errors\n        )\n\n    @staticmethod\n    def async_get_options_flow(\n        config_entry: config_entries.ConfigEntry,\n    ) -&gt; config_entries.OptionsFlow:\n        \"\"\"Create the options flow.\n\n        Args:\n            config_entry: Existing config entry to edit.\n\n        Returns:\n            Options flow handler.\n        \"\"\"\n        return MeeseeksOptionsFlow(config_entry)\n</code></pre>"},{"location":"reference/#meeseeks_ha_conversation.config_flow.MeeseeksConfigFlow.async_get_options_flow","title":"<code>async_get_options_flow(config_entry: config_entries.ConfigEntry) -&gt; config_entries.OptionsFlow</code>  <code>staticmethod</code>","text":"<p>Create the options flow.</p> <p>Parameters:</p> Name Type Description Default <code>config_entry</code> <code>ConfigEntry</code> <p>Existing config entry to edit.</p> required <p>Returns:</p> Type Description <code>OptionsFlow</code> <p>Options flow handler.</p> Source code in <code>meeseeks_ha_conversation/config_flow.py</code> <pre><code>@staticmethod\ndef async_get_options_flow(\n    config_entry: config_entries.ConfigEntry,\n) -&gt; config_entries.OptionsFlow:\n    \"\"\"Create the options flow.\n\n    Args:\n        config_entry: Existing config entry to edit.\n\n    Returns:\n        Options flow handler.\n    \"\"\"\n    return MeeseeksOptionsFlow(config_entry)\n</code></pre>"},{"location":"reference/#meeseeks_ha_conversation.config_flow.MeeseeksConfigFlow.async_step_user","title":"<code>async_step_user(user_input: dict[str, Any] | None = None) -&gt; FlowResult</code>  <code>async</code>","text":"<p>Handle the initial config flow step.</p> <p>Parameters:</p> Name Type Description Default <code>user_input</code> <code>dict[str, Any] | None</code> <p>Submitted form data, if available.</p> <code>None</code> <p>Returns:</p> Type Description <code>FlowResult</code> <p>FlowResult for the configuration step.</p> Source code in <code>meeseeks_ha_conversation/config_flow.py</code> <pre><code>async def async_step_user(\n    self, user_input: dict[str, Any] | None = None\n) -&gt; FlowResult:\n    \"\"\"Handle the initial config flow step.\n\n    Args:\n        user_input: Submitted form data, if available.\n\n    Returns:\n        FlowResult for the configuration step.\n    \"\"\"\n    if user_input is None:\n        return self.async_show_form(\n            step_id=\"user\", data_schema=STEP_USER_DATA_SCHEMA\n        )\n\n    # Search for duplicates with the same CONF_BASE_URL value.\n    for existing_entry in self._async_current_entries(include_ignore=False):\n        if existing_entry.data.get(CONF_BASE_URL) == user_input[CONF_BASE_URL]:\n            return self.async_abort(reason=\"already_configured\")\n\n    errors: dict[str, str] = {}\n    try:\n        self.client = MeeseeksApiClient(\n            base_url=cv.url_no_path(user_input[CONF_BASE_URL]),\n            timeout=user_input[CONF_TIMEOUT],\n            session=async_create_clientsession(self.hass),\n        )\n        response = await self.client.async_get_heartbeat()\n        if not response:\n            raise vol.Invalid(\"Invalid Meeseeks server\")\n    # except vol.Invalid:\n    #     errors[\"base\"] = \"invalid_url\"\n    # except ApiTimeoutError:\n    #     errors[\"base\"] = \"timeout_connect\"\n    # except ApiCommError:\n    #     errors[\"base\"] = \"cannot_connect\"\n    # except ApiClientError as exception:\n    #     LOGGER.exception(\"Unexpected exception: %s\", exception)\n    #     errors[\"base\"] = \"unknown\"\n    except Exception as exception:\n        LOGGER.exception(\"Unexpected exception: %s\", exception)\n        errors[\"base\"] = \"unknown\"\n    else:\n        return self.async_create_entry(\n            title=f\"Meeseeks - {user_input[CONF_BASE_URL]}\",\n            data={\n                CONF_BASE_URL: user_input[CONF_BASE_URL]\n            },\n            options={\n                CONF_TIMEOUT: user_input[CONF_TIMEOUT]\n            }\n        )\n\n    return self.async_show_form(\n        step_id=\"user\", data_schema=STEP_USER_DATA_SCHEMA, errors=errors\n    )\n</code></pre>"},{"location":"reference/#meeseeks_ha_conversation.config_flow.MeeseeksOptionsFlow","title":"<code>MeeseeksOptionsFlow</code>","text":"<p>               Bases: <code>OptionsFlow</code></p> <p>Meeseeks config flow options handler.</p> Source code in <code>meeseeks_ha_conversation/config_flow.py</code> <pre><code>class MeeseeksOptionsFlow(config_entries.OptionsFlow):\n    \"\"\"Meeseeks config flow options handler.\"\"\"\n\n    def __init__(self, config_entry: config_entries.ConfigEntry) -&gt; None:\n        \"\"\"Initialize options flow.\n\n        Args:\n            config_entry: Config entry to manage.\n        \"\"\"\n        self.config_entry = config_entry\n        self.options = dict(config_entry.options)\n\n    async def async_step_init(\n        self, user_input: dict[str, Any] | None = None\n    ) -&gt; FlowResult:\n        \"\"\"Show the options menu.\n\n        Args:\n            user_input: Submitted form data, if available.\n\n        Returns:\n            FlowResult for the options menu.\n        \"\"\"\n        return self.async_show_menu(\n            step_id=\"init\",\n            menu_options=MENU_OPTIONS\n        )\n\n    async def async_step_all_set(\n        self, user_input: dict[str, Any] | None = None\n    ) -&gt; FlowResult:\n        \"\"\"Handle the \"all_set\" options step.\n\n        Args:\n            user_input: Submitted form data, if available.\n\n        Returns:\n            FlowResult for the options menu.\n        \"\"\"\n        return self.async_show_menu(\n            step_id=\"init\",\n            menu_options=MENU_OPTIONS\n        )\n\n    async def async_step_general_config(\n        self, user_input: dict[str, Any] | None = None\n    ) -&gt; FlowResult:\n        \"\"\"Handle the general configuration step.\n\n        Args:\n            user_input: Submitted form data, if available.\n\n        Returns:\n            FlowResult for the options menu.\n        \"\"\"\n        return self.async_show_menu(\n            step_id=\"init\",\n            menu_options=MENU_OPTIONS\n        )\n\n    async def async_step_prompt_system(\n        self, user_input: dict[str, Any] | None = None\n    ) -&gt; FlowResult:\n        \"\"\"Handle the prompt system configuration step.\n\n        Args:\n            user_input: Submitted form data, if available.\n\n        Returns:\n            FlowResult for the options menu.\n        \"\"\"\n        return self.async_show_menu(\n            step_id=\"init\",\n            menu_options=MENU_OPTIONS\n        )\n\n    async def async_step_model_config(\n        self, user_input: dict[str, Any] | None = None\n    ) -&gt; FlowResult:\n        \"\"\"Handle the model configuration step.\n\n        Args:\n            user_input: Submitted form data, if available.\n\n        Returns:\n            FlowResult for the options menu.\n        \"\"\"\n        return self.async_show_menu(\n            step_id=\"init\",\n            menu_options=MENU_OPTIONS\n        )\n</code></pre>"},{"location":"reference/#meeseeks_ha_conversation.config_flow.MeeseeksOptionsFlow.__init__","title":"<code>__init__(config_entry: config_entries.ConfigEntry) -&gt; None</code>","text":"<p>Initialize options flow.</p> <p>Parameters:</p> Name Type Description Default <code>config_entry</code> <code>ConfigEntry</code> <p>Config entry to manage.</p> required Source code in <code>meeseeks_ha_conversation/config_flow.py</code> <pre><code>def __init__(self, config_entry: config_entries.ConfigEntry) -&gt; None:\n    \"\"\"Initialize options flow.\n\n    Args:\n        config_entry: Config entry to manage.\n    \"\"\"\n    self.config_entry = config_entry\n    self.options = dict(config_entry.options)\n</code></pre>"},{"location":"reference/#meeseeks_ha_conversation.config_flow.MeeseeksOptionsFlow.async_step_all_set","title":"<code>async_step_all_set(user_input: dict[str, Any] | None = None) -&gt; FlowResult</code>  <code>async</code>","text":"<p>Handle the \"all_set\" options step.</p> <p>Parameters:</p> Name Type Description Default <code>user_input</code> <code>dict[str, Any] | None</code> <p>Submitted form data, if available.</p> <code>None</code> <p>Returns:</p> Type Description <code>FlowResult</code> <p>FlowResult for the options menu.</p> Source code in <code>meeseeks_ha_conversation/config_flow.py</code> <pre><code>async def async_step_all_set(\n    self, user_input: dict[str, Any] | None = None\n) -&gt; FlowResult:\n    \"\"\"Handle the \"all_set\" options step.\n\n    Args:\n        user_input: Submitted form data, if available.\n\n    Returns:\n        FlowResult for the options menu.\n    \"\"\"\n    return self.async_show_menu(\n        step_id=\"init\",\n        menu_options=MENU_OPTIONS\n    )\n</code></pre>"},{"location":"reference/#meeseeks_ha_conversation.config_flow.MeeseeksOptionsFlow.async_step_general_config","title":"<code>async_step_general_config(user_input: dict[str, Any] | None = None) -&gt; FlowResult</code>  <code>async</code>","text":"<p>Handle the general configuration step.</p> <p>Parameters:</p> Name Type Description Default <code>user_input</code> <code>dict[str, Any] | None</code> <p>Submitted form data, if available.</p> <code>None</code> <p>Returns:</p> Type Description <code>FlowResult</code> <p>FlowResult for the options menu.</p> Source code in <code>meeseeks_ha_conversation/config_flow.py</code> <pre><code>async def async_step_general_config(\n    self, user_input: dict[str, Any] | None = None\n) -&gt; FlowResult:\n    \"\"\"Handle the general configuration step.\n\n    Args:\n        user_input: Submitted form data, if available.\n\n    Returns:\n        FlowResult for the options menu.\n    \"\"\"\n    return self.async_show_menu(\n        step_id=\"init\",\n        menu_options=MENU_OPTIONS\n    )\n</code></pre>"},{"location":"reference/#meeseeks_ha_conversation.config_flow.MeeseeksOptionsFlow.async_step_init","title":"<code>async_step_init(user_input: dict[str, Any] | None = None) -&gt; FlowResult</code>  <code>async</code>","text":"<p>Show the options menu.</p> <p>Parameters:</p> Name Type Description Default <code>user_input</code> <code>dict[str, Any] | None</code> <p>Submitted form data, if available.</p> <code>None</code> <p>Returns:</p> Type Description <code>FlowResult</code> <p>FlowResult for the options menu.</p> Source code in <code>meeseeks_ha_conversation/config_flow.py</code> <pre><code>async def async_step_init(\n    self, user_input: dict[str, Any] | None = None\n) -&gt; FlowResult:\n    \"\"\"Show the options menu.\n\n    Args:\n        user_input: Submitted form data, if available.\n\n    Returns:\n        FlowResult for the options menu.\n    \"\"\"\n    return self.async_show_menu(\n        step_id=\"init\",\n        menu_options=MENU_OPTIONS\n    )\n</code></pre>"},{"location":"reference/#meeseeks_ha_conversation.config_flow.MeeseeksOptionsFlow.async_step_model_config","title":"<code>async_step_model_config(user_input: dict[str, Any] | None = None) -&gt; FlowResult</code>  <code>async</code>","text":"<p>Handle the model configuration step.</p> <p>Parameters:</p> Name Type Description Default <code>user_input</code> <code>dict[str, Any] | None</code> <p>Submitted form data, if available.</p> <code>None</code> <p>Returns:</p> Type Description <code>FlowResult</code> <p>FlowResult for the options menu.</p> Source code in <code>meeseeks_ha_conversation/config_flow.py</code> <pre><code>async def async_step_model_config(\n    self, user_input: dict[str, Any] | None = None\n) -&gt; FlowResult:\n    \"\"\"Handle the model configuration step.\n\n    Args:\n        user_input: Submitted form data, if available.\n\n    Returns:\n        FlowResult for the options menu.\n    \"\"\"\n    return self.async_show_menu(\n        step_id=\"init\",\n        menu_options=MENU_OPTIONS\n    )\n</code></pre>"},{"location":"reference/#meeseeks_ha_conversation.config_flow.MeeseeksOptionsFlow.async_step_prompt_system","title":"<code>async_step_prompt_system(user_input: dict[str, Any] | None = None) -&gt; FlowResult</code>  <code>async</code>","text":"<p>Handle the prompt system configuration step.</p> <p>Parameters:</p> Name Type Description Default <code>user_input</code> <code>dict[str, Any] | None</code> <p>Submitted form data, if available.</p> <code>None</code> <p>Returns:</p> Type Description <code>FlowResult</code> <p>FlowResult for the options menu.</p> Source code in <code>meeseeks_ha_conversation/config_flow.py</code> <pre><code>async def async_step_prompt_system(\n    self, user_input: dict[str, Any] | None = None\n) -&gt; FlowResult:\n    \"\"\"Handle the prompt system configuration step.\n\n    Args:\n        user_input: Submitted form data, if available.\n\n    Returns:\n        FlowResult for the options menu.\n    \"\"\"\n    return self.async_show_menu(\n        step_id=\"init\",\n        menu_options=MENU_OPTIONS\n    )\n</code></pre>"},{"location":"reference/#meeseeks_ha_conversation.const","title":"<code>meeseeks_ha_conversation.const</code>","text":"<p>Constants for meeseeks_conversation.</p>"},{"location":"reference/#meeseeks_ha_conversation.coordinator","title":"<code>meeseeks_ha_conversation.coordinator</code>","text":"<p>DataUpdateCoordinator for meeseeks_conversation.</p>"},{"location":"reference/#meeseeks_ha_conversation.coordinator.MeeseeksDataUpdateCoordinator","title":"<code>MeeseeksDataUpdateCoordinator</code>","text":"<p>               Bases: <code>DataUpdateCoordinator</code></p> <p>Class to manage fetching data from the API.</p> Source code in <code>meeseeks_ha_conversation/coordinator.py</code> <pre><code>class MeeseeksDataUpdateCoordinator(DataUpdateCoordinator):\n    \"\"\"Class to manage fetching data from the API.\"\"\"\n\n    config_entry: ConfigEntry\n\n    def __init__(\n        self,\n        hass: HomeAssistant,\n        client: MeeseeksApiClient,\n    ) -&gt; None:\n        \"\"\"Initialize the coordinator.\n\n        Args:\n            hass: Home Assistant core instance.\n            client: API client for Meeseeks.\n        \"\"\"\n        self.client = client\n        super().__init__(\n            hass=hass,\n            logger=LOGGER,\n            name=DOMAIN,\n            update_interval=timedelta(minutes=5),\n        )\n\n    async def _async_update_data(self) -&gt; bool:\n        \"\"\"Update data via library.\n\n        Returns:\n            True when the heartbeat check succeeds.\n\n        Raises:\n            UpdateFailed: If the API heartbeat fails.\n        \"\"\"\n        try:\n            return await self.client.async_get_heartbeat()\n        except ApiClientError as exception:\n            raise UpdateFailed(exception) from exception\n</code></pre>"},{"location":"reference/#meeseeks_ha_conversation.coordinator.MeeseeksDataUpdateCoordinator.__init__","title":"<code>__init__(hass: HomeAssistant, client: MeeseeksApiClient) -&gt; None</code>","text":"<p>Initialize the coordinator.</p> <p>Parameters:</p> Name Type Description Default <code>hass</code> <code>HomeAssistant</code> <p>Home Assistant core instance.</p> required <code>client</code> <code>MeeseeksApiClient</code> <p>API client for Meeseeks.</p> required Source code in <code>meeseeks_ha_conversation/coordinator.py</code> <pre><code>def __init__(\n    self,\n    hass: HomeAssistant,\n    client: MeeseeksApiClient,\n) -&gt; None:\n    \"\"\"Initialize the coordinator.\n\n    Args:\n        hass: Home Assistant core instance.\n        client: API client for Meeseeks.\n    \"\"\"\n    self.client = client\n    super().__init__(\n        hass=hass,\n        logger=LOGGER,\n        name=DOMAIN,\n        update_interval=timedelta(minutes=5),\n    )\n</code></pre>"},{"location":"reference/#meeseeks_ha_conversation.exceptions","title":"<code>meeseeks_ha_conversation.exceptions</code>","text":"<p>The exceptions used by Extended OpenAI Conversation.</p>"},{"location":"reference/#meeseeks_ha_conversation.exceptions.ApiClientError","title":"<code>ApiClientError</code>","text":"<p>               Bases: <code>HomeAssistantError</code></p> <p>Exception to indicate a general API error.</p> Source code in <code>meeseeks_ha_conversation/exceptions.py</code> <pre><code>class ApiClientError(HomeAssistantError):\n    \"\"\"Exception to indicate a general API error.\"\"\"\n</code></pre>"},{"location":"reference/#meeseeks_ha_conversation.exceptions.ApiCommError","title":"<code>ApiCommError</code>","text":"<p>               Bases: <code>ApiClientError</code></p> <p>Exception to indicate a communication error.</p> Source code in <code>meeseeks_ha_conversation/exceptions.py</code> <pre><code>class ApiCommError(ApiClientError):\n    \"\"\"Exception to indicate a communication error.\"\"\"\n</code></pre>"},{"location":"reference/#meeseeks_ha_conversation.exceptions.ApiJsonError","title":"<code>ApiJsonError</code>","text":"<p>               Bases: <code>ApiClientError</code></p> <p>Exception to indicate an error with json response.</p> Source code in <code>meeseeks_ha_conversation/exceptions.py</code> <pre><code>class ApiJsonError(ApiClientError):\n    \"\"\"Exception to indicate an error with json response.\"\"\"\n</code></pre>"},{"location":"reference/#meeseeks_ha_conversation.exceptions.ApiTimeoutError","title":"<code>ApiTimeoutError</code>","text":"<p>               Bases: <code>ApiClientError</code></p> <p>Exception to indicate a timeout error.</p> Source code in <code>meeseeks_ha_conversation/exceptions.py</code> <pre><code>class ApiTimeoutError(ApiClientError):\n    \"\"\"Exception to indicate a timeout error.\"\"\"\n</code></pre>"},{"location":"reference/#meeseeks_ha_conversation.helpers","title":"<code>meeseeks_ha_conversation.helpers</code>","text":"<p>Helper functions for Meeseeks.</p>"},{"location":"reference/#meeseeks_ha_conversation.helpers.ExposedEntity","title":"<code>ExposedEntity</code>","text":"<p>               Bases: <code>TypedDict</code></p> <p>Typed representation of a Home Assistant entity exposed to conversation.</p> Source code in <code>meeseeks_ha_conversation/helpers.py</code> <pre><code>class ExposedEntity(TypedDict):\n    \"\"\"Typed representation of a Home Assistant entity exposed to conversation.\"\"\"\n    entity_id: str\n    name: str\n    state: str\n    aliases: list[str]\n</code></pre>"},{"location":"reference/#meeseeks_ha_conversation.helpers.get_exposed_entities","title":"<code>get_exposed_entities(hass: HomeAssistant) -&gt; list[ExposedEntity]</code>","text":"<p>Return exposed entities.</p> <p>Parameters:</p> Name Type Description Default <code>hass</code> <code>HomeAssistant</code> <p>Home Assistant core instance.</p> required <p>Returns:</p> Type Description <code>list[ExposedEntity]</code> <p>List of exposed entities and their metadata.</p> Source code in <code>meeseeks_ha_conversation/helpers.py</code> <pre><code>def get_exposed_entities(hass: HomeAssistant) -&gt; list[ExposedEntity]:\n    \"\"\"Return exposed entities.\n\n    Args:\n        hass: Home Assistant core instance.\n\n    Returns:\n        List of exposed entities and their metadata.\n    \"\"\"\n    hass_entity = entity_registry.async_get(hass)\n    exposed_entities: list[ExposedEntity] = []\n\n    for state in hass.states.async_all():\n        if async_should_expose(hass, CONVERSATION_DOMAIN, state.entity_id):\n            entity = hass_entity.async_get(state.entity_id)\n            exposed_entities.append({\n                \"entity_id\": state.entity_id,\n                \"name\": state.name,\n                \"state\": state.state,\n                \"aliases\": entity.aliases if entity else [],\n            })\n\n    return exposed_entities\n</code></pre>"}]}