{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Meeseeks Docs","text":"<p>Meeseeks is a personal assistant that breaks a request into small actions, runs the right tools, and replies with a clean summary. This doc gives a quick product view and how the parts fit together.</p>"},{"location":"#features-quick-view","title":"Features (quick view)","text":"<ul> <li>Plan -&gt; act -&gt; observe loop to keep work grounded in tool results.</li> <li>Multiple interfaces (chat UI, REST API, Home Assistant, terminal CLI) backed by one core engine.</li> <li>Tool registry for local tools plus optional MCP tools.</li> <li>Session transcripts with lightweight compaction for long runs.</li> <li>Context-aware memory (recent turns + summary) with optional context selection near budget.</li> <li>Step-level reflection after tool execution to validate outcomes.</li> <li>Permission gate with approval callbacks plus lightweight hooks around tool execution.</li> <li>Optional components (Langfuse, Home Assistant) auto-disable when not configured or when failures occur.</li> </ul>"},{"location":"#subprojects-and-how-they-fit","title":"Subprojects and how they fit","text":"<ul> <li><code>core/</code>: orchestration loop, schemas, session storage, compaction, tool registry.</li> <li><code>tools/</code>: tool implementations and integrations.</li> <li><code>meeseeks-api/</code>: Flask API that exposes the assistant over HTTP.</li> <li><code>meeseeks-chat/</code>: Streamlit UI for interactive chat.</li> <li><code>meeseeks-cli/</code>: Terminal CLI for interactive sessions.</li> <li><code>meeseeks_ha_conversation/</code>: Home Assistant integration that routes voice requests to the API.</li> <li><code>prompts/</code>: planner prompt and examples.</li> </ul>"},{"location":"#architecture-in-a-glance","title":"Architecture in a glance","text":"<ul> <li>The UI or API sends a user request into the core orchestrator.</li> <li>The orchestrator builds a short action plan, runs tools, and replans if needed.</li> <li>Tool results and summaries are stored in a session transcript for continuity.</li> </ul> <pre><code>flowchart LR\n  User --&gt; Chat\n  User --&gt; API\n  HA --&gt; API\n  User --&gt; CLI\n  Chat --&gt; Core\n  API --&gt; Core\n  CLI --&gt; Core\n  Core --&gt; Tools\n  Tools --&gt; HomeAssistant\n  Tools --&gt; MCP\n  Core --&gt; SessionStore\n</code></pre>"},{"location":"#installation-local","title":"Installation (local)","text":"<ul> <li>Prereqs: Python 3.11+, Poetry.</li> <li>Install deps: <code>poetry install</code>.</li> <li>Copy <code>.env.example</code> to <code>.env</code> and set the required values.</li> <li>Run the API: <code>python meeseeks-api/backend.py</code>.</li> <li>Run the chat UI: <code>streamlit run meeseeks-chat/chat_master.py</code>.</li> <li>Run the CLI: <code>python meeseeks-cli/cli_master.py</code>.</li> </ul>"},{"location":"#cli-quick-commands","title":"CLI quick commands","text":"<ul> <li><code>/help</code> show commands</li> <li><code>/models</code> pick a model from your API</li> <li><code>/mcp</code> list MCP servers/tools (use <code>/mcp select</code> to filter)</li> <li><code>/mcp init</code> scaffold an MCP config file</li> <li><code>/summarize</code> compact the session</li> <li><code>/new</code> start a fresh session</li> <li><code>/automatic</code> auto-approve tool actions for the session</li> <li><code>/quit</code> exit the CLI</li> </ul>"},{"location":"#deployment-docker","title":"Deployment (Docker)","text":"<ul> <li>Dockerfiles are provided for the API and chat UI.</li> <li>Provide the same environment values as local install.</li> <li>Persist data if you want session transcripts (<code>MESEEKS_SESSION_DIR</code>).</li> <li>Expose the API for Home Assistant or other clients to call.</li> </ul>"},{"location":"#configuration-notes","title":"Configuration notes","text":"<ul> <li>Tool catalog can be driven by a JSON manifest via <code>MESEEKS_TOOL_MANIFEST</code> (optional override; disables auto-discovery).</li> <li>MCP tools use:</li> <li><code>MESEEKS_MCP_CONFIG</code>: server connection info (see <code>configs/mcp.example.json</code>).</li> <li>A manifest is auto-generated on load (cached under <code>~/.meeseeks/</code>) unless you override it.</li> </ul>"},{"location":"#add-mcp-servers-direct","title":"Add MCP servers (direct)","text":"<ol> <li>Copy <code>configs/mcp.example.json</code> and set your server URL + headers.</li> <li>Set <code>MESEEKS_MCP_CONFIG=./configs/your-mcp.json</code> in <code>.env</code>.</li> <li>Start the app once; the tool manifest is auto-discovered and cached.</li> <li>Optional: add <code>auto_approve_tools</code> per server to allowlist tools (the CLI writes this if you pick \u201cYes, always\u201d).</li> </ol> <p>Advanced override: - If you want a custom tool list, set <code>MESEEKS_TOOL_MANIFEST</code> to your own JSON.</p> <p>Notes: - If you override the manifest, include <code>talk_to_user_tool</code> or you will lose the default reply tool. - MCP tool names must match the server\u2019s advertised tool list.</p>"},{"location":"#optional-components","title":"Optional components","text":"<ul> <li>Langfuse observability: set <code>LANGFUSE_PUBLIC_KEY</code> + <code>LANGFUSE_SECRET_KEY</code> (or disable via <code>LANGFUSE_ENABLED=0</code>).</li> <li>Home Assistant tools: set <code>HA_URL</code> + <code>HA_TOKEN</code> (or disable via <code>MESEEKS_HOME_ASSISTANT_ENABLED=0</code>).</li> <li>Optional components auto-disable on init/runtime/auth errors with logs.</li> </ul>"},{"location":"getting-started/","title":"Getting Started","text":""},{"location":"getting-started/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.11+</li> <li>Poetry (or pip + a virtual environment)</li> </ul>"},{"location":"getting-started/#install-documentation-dependencies","title":"Install documentation dependencies","text":"<pre><code>pip install -r requirements-docs.txt\n</code></pre>"},{"location":"getting-started/#run-the-docs-locally","title":"Run the docs locally","text":"<pre><code>export PYTHONPATH=\"$PWD\"\nmkdocs serve\n</code></pre> <p>The documentation will be available at http://127.0.0.1:8000/.</p>"},{"location":"getting-started/#build-the-docs","title":"Build the docs","text":"<pre><code>export PYTHONPATH=\"$PWD\"\nmkdocs build\n</code></pre>"},{"location":"reference/","title":"API Reference","text":""},{"location":"reference/#core-utilities","title":"Core utilities","text":"<p>Common helpers shared across the assistant runtime.</p>"},{"location":"reference/#core.common.MockSpeaker","title":"<code>MockSpeaker</code>","text":"<p>               Bases: <code>NamedTuple</code></p> <p>Simple mock response container used across tools and tests.</p> <p>Attributes:</p> Name Type Description <code>content</code> <code>str</code> <p>Text content returned by a tool.</p> Source code in <code>core/common.py</code> <pre><code>class MockSpeaker(NamedTuple):\n    \"\"\"Simple mock response container used across tools and tests.\n\n    Attributes:\n        content: Text content returned by a tool.\n    \"\"\"\n    content: str\n</code></pre>"},{"location":"reference/#core.common.get_logger","title":"<code>get_logger(name=None)</code>","text":"<p>Get the logger for the module.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str | None</code> <p>Name of the logger, defaults to name.</p> <code>None</code> <p>Returns:</p> Type Description <p>Logger configured with colored output.</p> Source code in <code>core/common.py</code> <pre><code>def get_logger(name: str | None = None):\n    \"\"\"Get the logger for the module.\n\n    Args:\n        name: Name of the logger, defaults to __name__.\n\n    Returns:\n        Logger configured with colored output.\n    \"\"\"\n    _configure_logging()\n    if not name:\n        name = __name__\n    return loguru_logger.bind(name=name)\n</code></pre>"},{"location":"reference/#core.common.get_mock_speaker","title":"<code>get_mock_speaker()</code>","text":"<p>Return a mock speaker for testing.</p> <p>Returns:</p> Type Description <code>type[MockSpeaker]</code> <p>MockSpeaker class for constructing responses.</p> Source code in <code>core/common.py</code> <pre><code>def get_mock_speaker() -&gt; type[MockSpeaker]:\n    \"\"\"Return a mock speaker for testing.\n\n    Returns:\n        MockSpeaker class for constructing responses.\n    \"\"\"\n    return MockSpeaker\n</code></pre>"},{"location":"reference/#core.common.get_system_prompt","title":"<code>get_system_prompt(name='action-planner')</code>","text":"<p>Get the system prompt for the task queue.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Prompt file name without extension.</p> <code>'action-planner'</code> <p>Returns:</p> Type Description <code>str</code> <p>System prompt string.</p> <p>Raises:</p> Type Description <code>OSError</code> <p>If the prompt file cannot be read.</p> Source code in <code>core/common.py</code> <pre><code>def get_system_prompt(name: str = \"action-planner\") -&gt; str:\n    \"\"\"Get the system prompt for the task queue.\n\n    Args:\n        name: Prompt file name without extension.\n\n    Returns:\n        System prompt string.\n\n    Raises:\n        OSError: If the prompt file cannot be read.\n    \"\"\"\n    logging = get_logger(name=\"core.common.get_system_prompt\")\n    system_prompt_path = os.path.join(\n        os.path.dirname(__file__), \"..\", \"prompts\", f\"{name}.txt\")\n    with open(system_prompt_path, encoding=\"utf-8\") as system_prompt_file:\n        system_prompt = system_prompt_file.read()\n    logging.debug(\"Getting system prompt from `{}`\", system_prompt_path)\n    del logging\n    return system_prompt.strip()\n</code></pre>"},{"location":"reference/#core.common.get_unique_timestamp","title":"<code>get_unique_timestamp()</code>","text":"<p>Get a unique timestamp for the task queue.</p> <p>Returns:</p> Type Description <code>int</code> <p>Integer timestamp suitable for unique IDs.</p> Source code in <code>core/common.py</code> <pre><code>def get_unique_timestamp() -&gt; int:\n    \"\"\"Get a unique timestamp for the task queue.\n\n    Returns:\n        Integer timestamp suitable for unique IDs.\n    \"\"\"\n    # Get the number of seconds since epoch (Jan 1, 1970) as a float\n    current_timestamp = int(time.time())\n    # Convert it to string for uniqueness and consistency\n    unique_timestamp = str(current_timestamp)\n    # Return the integer version of this string timestamp\n    return int(''.join(str(x) for x in map(int, unique_timestamp)))\n</code></pre>"},{"location":"reference/#core.common.ha_render_system_prompt","title":"<code>ha_render_system_prompt(all_entities=None, env='prompts', name='homeassistant-set-state')</code>","text":"<p>Render the Home Assistant Jinja2 system prompt.</p> <p>Parameters:</p> Name Type Description Default <code>all_entities</code> <code>Any | None</code> <p>Optional entity list for template substitution.</p> <code>None</code> <code>env</code> <code>str</code> <p>Template root directory name.</p> <code>'prompts'</code> <code>name</code> <code>str</code> <p>Template file name without extension.</p> <code>'homeassistant-set-state'</code> <p>Returns:</p> Type Description <code>str</code> <p>Rendered system prompt string.</p> Source code in <code>core/common.py</code> <pre><code>def ha_render_system_prompt(\n    all_entities: Any | None = None,\n    env: str = \"prompts\",\n    name: str = \"homeassistant-set-state\",\n) -&gt; str:\n    \"\"\"Render the Home Assistant Jinja2 system prompt.\n\n    Args:\n        all_entities: Optional entity list for template substitution.\n        env: Template root directory name.\n        name: Template file name without extension.\n\n    Returns:\n        Rendered system prompt string.\n    \"\"\"\n    if all_entities is not None:\n        all_entities = str(all_entities).strip()\n    logging = get_logger(name=\"core.common.render_system_prompt\")\n\n    template_root = os.path.join(__name__, \"..\", \"..\", \"prompts\")\n    template_root = os.path.abspath(template_root)\n    logging.debug(\"Compiling {} from {}.\", name, template_root)\n    # TODO: Catch and log TemplateNotFound when necessary.\n    template_env = Environment(loader=FileSystemLoader(template_root))\n    template = template_env.get_template(f\"{name}.txt\")\n    logging.debug(\"Render system prompt for `{}`\", name)\n    del logging\n\n    return template.render(ALL_ENTITIES=all_entities)\n</code></pre>"},{"location":"reference/#core.common.num_tokens_from_string","title":"<code>num_tokens_from_string(string, encoding_name='cl100k_base')</code>","text":"<p>Get the number of tokens in a string using a specific model.</p> <p>Parameters:</p> Name Type Description Default <code>string</code> <code>str</code> <p>Text to tokenize.</p> required <code>encoding_name</code> <code>str</code> <p>Encoding name used for tokenization.</p> <code>'cl100k_base'</code> <p>Returns:</p> Type Description <code>int</code> <p>Number of tokens for the string.</p> Source code in <code>core/common.py</code> <pre><code>def num_tokens_from_string(\n        string: str, encoding_name: str = \"cl100k_base\") -&gt; int:\n    \"\"\"Get the number of tokens in a string using a specific model.\n\n    Args:\n        string: Text to tokenize.\n        encoding_name: Encoding name used for tokenization.\n\n    Returns:\n        Number of tokens for the string.\n    \"\"\"\n    # TODO: Add support for dynamic model selection\n    encoding = tiktoken.get_encoding(encoding_name)\n    num_tokens = len(encoding.encode(string))\n    return num_tokens\n</code></pre>"}]}